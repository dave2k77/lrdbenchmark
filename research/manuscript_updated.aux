\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{mandelbrot1968,beran1994}
\citation{cont2001}
\citation{willinger1995}
\citation{ivanov1999}
\citation{pelletier2001}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The Broader Landscape of Time Series Analysis}{1}{subsection.1.1}\protected@file@percent }
\citation{mandelbrot1968}
\citation{mandelbrot1971}
\citation{abry2000}
\citation{kantelhardt2002}
\citation{taqqu2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}The Critical Need for standardised Benchmarking}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Our Unique Contributions}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Impact on the Field}{3}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Paper Organization}{3}{subsection.1.5}\protected@file@percent }
\citation{taqqu2003}
\citation{liu2019}
\citation{cont2001}
\citation{ivanov1999}
\citation{pelletier2001}
\citation{willinger1995}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Related Work}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Long-Range Dependence: Theoretical Foundations}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Evolution of LRD Estimation Methods}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Existing Benchmarking Studies and Their Limitations}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}The Need for a Comprehensive Benchmarking Framework}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Related Work and Applications}{4}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\texttt  {lrdbenchmark} Framework Architecture}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Data Models}{5}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Fractional Brownian Motion (FBM)}{5}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Fractional Gaussian Noise (FGN)}{5}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}ARFIMA Process}{5}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Multifractal Random Walk (MRW)}{5}{subsubsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Estimator Implementation}{6}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Experimental Design}{6}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Alpha-Stable Data Generation}{7}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Performance Metrics}{7}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Combined Error and Scoring Definitions}{7}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Robustness Score}{7}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Reproducibility Checklist}{8}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{8}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overall Performance Summary}{8}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Comprehensive Leaderboard Analysis}{8}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Category-Wise Performance Analysis}{8}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comprehensive estimator leaderboard showing (a) top 15 overall performers, (b) average performance by category, (c) performance vs robustness scatter plot, (d) accuracy vs speed trade-off, (e) score distributions by metric, and (f) ranking stability analysis. Neural networks dominate the top positions while classical methods show excellent speed characteristics.}}{9}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:comprehensive_leaderboard}{{1}{9}{Comprehensive estimator leaderboard showing (a) top 15 overall performers, (b) average performance by category, (c) performance vs robustness scatter plot, (d) accuracy vs speed trade-off, (e) score distributions by metric, and (f) ranking stability analysis. Neural networks dominate the top positions while classical methods show excellent speed characteristics}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Category-wise performance comparison showing (a) mean absolute error by category, (b) execution time comparison, (c) overall score comparison, (d) robustness comparison, (e) performance vs speed scatter plot, (f) performance radar chart, (g) estimator count by category, and (h) best individual performers. Neural networks demonstrate superior performance across most metrics.}}{10}{figure.caption.4}\protected@file@percent }
\newlabel{fig:category_comparison}{{2}{10}{Category-wise performance comparison showing (a) mean absolute error by category, (b) execution time comparison, (c) overall score comparison, (d) robustness comparison, (e) performance vs speed scatter plot, (f) performance radar chart, (g) estimator count by category, and (h) best individual performers. Neural networks demonstrate superior performance across most metrics}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Neural Networks Performance}{11}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Neural Network Performance Summary}}{11}{table.caption.5}\protected@file@percent }
\newlabel{tab:neural_performance}{{1}{11}{Neural Network Performance Summary}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Machine Learning Performance}{11}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Machine Learning Performance Summary}}{11}{table.caption.6}\protected@file@percent }
\newlabel{tab:ml_performance}{{2}{11}{Machine Learning Performance Summary}{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Classical Methods Performance Summary}}{12}{table.caption.7}\protected@file@percent }
\newlabel{tab:classical_performance}{{3}{12}{Classical Methods Performance Summary}{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Classical Methods Performance}{12}{subsubsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Comprehensive Cross-Category Performance Comparison}{12}{subsection.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Comprehensive Cross-Category Performance Comparison}}{12}{table.caption.8}\protected@file@percent }
\newlabel{tab:comprehensive_comparison}{{4}{12}{Comprehensive Cross-Category Performance Comparison}{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Statistical Significance Testing and Rigorous Analysis}{13}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Comprehensive Statistical Framework}{13}{subsubsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Confidence Intervals and Effect Sizes}{13}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Statistical Significance Testing}{13}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Power Analysis}{14}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Contamination Robustness Analysis}{14}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Contamination Scenarios}{14}{subsubsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.2}Robustness Results}{14}{subsubsection.4.6.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Contamination Robustness Summary}}{14}{table.caption.12}\protected@file@percent }
\newlabel{tab:robustness_summary}{{5}{14}{Contamination Robustness Summary}{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Speed-Accuracy Trade-offs}{14}{subsection.4.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Speed-Accuracy Trade-off Analysis}}{14}{table.caption.13}\protected@file@percent }
\newlabel{tab:speed_accuracy_tradeoff}{{6}{14}{Speed-Accuracy Trade-off Analysis}{table.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Real-World Validation and Practical Applicability}{15}{subsection.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Heavy-Tail Robustness and Alpha-Stable Data Performance}{15}{subsection.4.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.1}Heavy-Tail Performance Results}{15}{subsubsection.4.9.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Heavy-Tail Performance Comparison by Category}}{15}{table.caption.14}\protected@file@percent }
\newlabel{tab:heavy_tail_performance}{{7}{15}{Heavy-Tail Performance Comparison by Category}{table.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{Machine Learning Dominance on Heavy-Tail Data}{15}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Neural Network Performance Characteristics}{15}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Classical Method Reliability}{16}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.2}Adaptive Preprocessing Effectiveness}{16}{subsubsection.4.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.3}Practical Implications for Heavy-Tail Data}{16}{subsubsection.4.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.4}Heavy-Tail Performance Visualisations}{16}{subsubsection.4.9.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Heavy-tail performance analysis showing (a) mean absolute error by category with error bars, (b) individual estimator performance across all categories, (c) performance across alpha-stable parameters (α=0.8-2.0), and (d) robustness and success rate analysis. Machine learning estimators demonstrate superior performance on heavy-tail data, while neural networks show consistent high performance across all alpha parameters.}}{17}{figure.caption.18}\protected@file@percent }
\newlabel{fig:heavy_tail_performance}{{3}{17}{Heavy-tail performance analysis showing (a) mean absolute error by category with error bars, (b) individual estimator performance across all categories, (c) performance across alpha-stable parameters (α=0.8-2.0), and (d) robustness and success rate analysis. Machine learning estimators demonstrate superior performance on heavy-tail data, while neural networks show consistent high performance across all alpha parameters}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Alpha-stable data characteristics showing (a) distribution shapes across different alpha parameters, (b) tail behaviour comparison on log-log scale, (c) extreme value ratios by alpha parameter, and (d) estimator robustness to heavy-tail data. The analysis reveals how decreasing alpha values increase heavy-tail behaviour and extreme value frequency.}}{18}{figure.caption.19}\protected@file@percent }
\newlabel{fig:alpha_stable_characteristics}{{4}{18}{Alpha-stable data characteristics showing (a) distribution shapes across different alpha parameters, (b) tail behaviour comparison on log-log scale, (c) extreme value ratios by alpha parameter, and (d) estimator robustness to heavy-tail data. The analysis reveals how decreasing alpha values increase heavy-tail behaviour and extreme value frequency}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Preprocessing effectiveness analysis showing (a) performance improvement by alpha parameter and category, (b) preprocessing method effectiveness scores, (c) data characteristics driving preprocessing selection, and (d) estimator-specific preprocessing benefits. The intelligent preprocessing system automatically selects appropriate methods based on data characteristics.}}{19}{figure.caption.20}\protected@file@percent }
\newlabel{fig:preprocessing_effectiveness}{{5}{19}{Preprocessing effectiveness analysis showing (a) performance improvement by alpha parameter and category, (b) preprocessing method effectiveness scores, (c) data characteristics driving preprocessing selection, and (d) estimator-specific preprocessing benefits. The intelligent preprocessing system automatically selects appropriate methods based on data characteristics}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.5}Comprehensive Leaderboard with Heavy-Tail Performance}{20}{subsubsection.4.9.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Comprehensive Leaderboard Including Heavy-Tail Performance}}{20}{table.caption.21}\protected@file@percent }
\newlabel{tab:comprehensive_leaderboard_heavy_tail}{{8}{20}{Comprehensive Leaderboard Including Heavy-Tail Performance}{table.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.6}Detailed Heavy-Tail Performance Tables}{20}{subsubsection.4.9.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Individual Estimator Heavy-Tail Performance}}{20}{table.caption.22}\protected@file@percent }
\newlabel{tab:individual_heavy_tail_performance}{{9}{20}{Individual Estimator Heavy-Tail Performance}{table.caption.22}{}}
\citation{lecun2015}
\citation{vaswani2017}
\citation{srivastava2014}
\citation{breiman2001,friedman2001}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Alpha-Stable Parameter Analysis}}{21}{table.caption.23}\protected@file@percent }
\newlabel{tab:alpha_stable_parameter_analysis}{{10}{21}{Alpha-Stable Parameter Analysis}{table.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Preprocessing Method Effectiveness}}{21}{table.caption.24}\protected@file@percent }
\newlabel{tab:preprocessing_effectiveness}{{11}{21}{Preprocessing Method Effectiveness}{table.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{21}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Theoretical Explanation of Observed Performance Patterns}{21}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Why Neural Networks Excel}{21}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Machine Learning Performance Characteristics}{21}{subsubsection.5.1.2}\protected@file@percent }
\citation{beran1994,taqqu2003}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Classical Method Strengths and Limitations}{22}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Practical Guidance for Method Selection}{22}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Method Selection Decision Framework}}{22}{table.caption.25}\protected@file@percent }
\newlabel{tab:method_selection}{{12}{22}{Method Selection Decision Framework}{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Comprehensive Limitations Analysis}{22}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Methodological Limitations}{22}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Data Model Limitations}{23}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Threats to Validity}{23}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Implications for the Field}{23}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}Methodological Implications}{23}{subsubsection.5.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Practical Implications}{23}{subsubsection.5.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{24}{section.6}\protected@file@percent }
\bibdata{references}
\bibcite{abry2000}{{1}{2000}{{Abry and Veitch}}{{}}}
\bibcite{beran1994}{{2}{1994}{{Beran}}{{}}}
\bibcite{breiman2001}{{3}{2001}{{Breiman}}{{}}}
\bibcite{cont2001}{{4}{2001}{{Cont}}{{}}}
\bibcite{friedman2001}{{5}{2001}{{Friedman}}{{}}}
\bibcite{ivanov1999}{{6}{1999}{{Ivanov et~al.}}{{Ivanov, Amaral, Goldberger, Havlin, Rosenblum, Struzik, and Stanley}}}
\bibcite{kantelhardt2002}{{7}{2002}{{Kantelhardt et~al.}}{{Kantelhardt, Zschiegner, Koscielny-Bunde, Havlin, Bunde, and Stanley}}}
\bibcite{lecun2015}{{8}{2015}{{LeCun et~al.}}{{LeCun, Bengio, and Hinton}}}
\bibcite{liu2019}{{9}{2019}{{Liu et~al.}}{{Liu, Chen, and Wang}}}
\bibcite{mandelbrot1971}{{10}{1971}{{Mandelbrot}}{{}}}
\bibcite{mandelbrot1968}{{11}{1968}{{Mandelbrot and Van~Ness}}{{}}}
\bibcite{pelletier2001}{{12}{2001}{{Pelletier and Turcotte}}{{}}}
\bibcite{srivastava2014}{{13}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov}}}
\bibcite{taqqu2003}{{14}{2003}{{Taqqu}}{{}}}
\bibcite{vaswani2017}{{15}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{willinger1995}{{16}{1995}{{Willinger et~al.}}{{Willinger, Taqqu, Sherman, and Wilson}}}
\gdef \@abspage@last{26}
