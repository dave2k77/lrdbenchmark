# ML Heavy-Tail Benchmark Summary

## Overview

This benchmark tested how Machine Learning estimators perform on pure data versus alpha-stable heavy-tailed data to demonstrate their robustness to extreme values. We tested RandomForest, SVR, and GradientBoosting estimators across different Hurst values and data characteristics.

## üî¨ Key Findings

### 1. **Complete ML Estimator Failure**
- **Success Rate**: 0% across all ML estimators
- **Pure Data**: All estimators failed on both FBM and FGN data
- **Heavy-Tailed Data**: All estimators failed on alpha-stable data
- **Total Tests**: 144 tests conducted, 0 successful estimates

### 2. **Data Characteristics Observed**

#### **Pure Data (FBM/FGN)**
- **FBM**: Kurtosis around 0.36, 0 extreme values (|x| > 5)
- **FGN**: Kurtosis around 0.05-0.07, 0 extreme values
- **Status**: Well-behaved, finite variance and mean

#### **Alpha-Stable Data (Heavy-Tailed)**
- **Œ± = 2.0 (Gaussian)**: Kurtosis ~0.1, 0 extreme values
- **Œ± = 1.5**: Kurtosis = NaN, 26-41 extreme values
- **Œ± = 1.0**: Kurtosis ~224-1222, 104-214 extreme values  
- **Œ± = 0.8**: Kurtosis = NaN, 118-236 extreme values

### 3. **Error Analysis**

#### **NaN Values in Heavy-Tailed Data**
- **SVR Error**: "Input X contains NaN. SVR does not accept missing values encoded as NaN natively"
- **GradientBoosting Error**: "Input X contains NaN. GradientBoostingRegressor does not accept missing values encoded as NaN natively"
- **Root Cause**: Heavy-tailed distributions generate extreme values that become NaN during feature engineering

#### **RandomForest Behavior**
- **No explicit error messages** but still failed
- **Likely Issue**: Feature engineering pipeline producing NaN values
- **Robustness**: RandomForest should handle NaN values better than SVR/GB

### 4. **Comparison with Classical Estimators**

| Estimator Type | Pure Data Success | Heavy-Tail Success | Key Issue |
|----------------|-------------------|-------------------|-----------|
| **Classical** | ~0% (JAX issues) | ~0% (JAX issues) | GPU compatibility |
| **ML** | 0% | 0% | NaN handling |
| **Expected** | High | Variable | Feature engineering |

## üîç **Root Cause Analysis**

### **1. Feature Engineering Pipeline**
- ML estimators likely use complex feature extraction
- Heavy-tailed data generates extreme values during feature computation
- Statistical moments (variance, kurtosis) become infinite/NaN
- Feature engineering not robust to extreme values

### **2. Pre-trained Model Expectations**
- All estimators loaded "pretrained models" from `models/` directory
- Models likely trained on clean, well-behaved data
- No adaptation to heavy-tailed or extreme value scenarios
- Domain shift between training and test data

### **3. Data Preprocessing Gaps**
- No robust preprocessing for extreme values
- No NaN handling in feature engineering
- No outlier detection or capping mechanisms
- Missing data imputation not implemented

## üìä **Quantitative Results**

### **Success Rates by Data Type**
- **Pure Data (FBM/FGN)**: 0.0% (0/72 tests)
- **Alpha-Stable Data**: 0.0% (0/72 tests)

### **Success Rates by Estimator**
- **RandomForest**: 0.0% (0/48 tests)
- **SVR**: 0.0% (0/48 tests)  
- **GradientBoosting**: 0.0% (0/48 tests)

### **Error Distribution**
- **NaN-related errors**: 24 instances (SVR/GB on heavy-tailed data)
- **Silent failures**: 120 instances (all other cases)
- **No successful estimates**: 0/144 total tests

## üéØ **Key Insights**

### **1. ML Estimators Not Robust to Heavy Tails**
- Complete failure on both pure and heavy-tailed data
- Suggests fundamental issues with feature engineering
- Pre-trained models not adapted to extreme value scenarios

### **2. Feature Engineering Critical**
- Heavy-tailed data breaks standard statistical features
- Need robust feature extraction methods
- NaN handling essential for real-world data

### **3. Training Data Mismatch**
- Pre-trained models likely trained on clean data
- No adaptation to heavy-tailed or extreme scenarios
- Domain shift between training and test conditions

### **4. Classical vs ML Comparison**
- Both classical and ML estimators failed
- Classical: JAX GPU compatibility issues
- ML: Feature engineering and NaN handling issues
- Neither approach robust to heavy-tailed noise

## üîß **Recommendations**

### **1. Robust Feature Engineering**
- Implement NaN-safe feature extraction
- Add outlier detection and capping
- Use robust statistical measures (median, IQR)
- Implement data preprocessing pipeline

### **2. Model Adaptation**
- Retrain models on heavy-tailed data
- Add data augmentation with extreme values
- Implement domain adaptation techniques
- Test on diverse data characteristics

### **3. Error Handling**
- Add comprehensive NaN handling
- Implement fallback mechanisms
- Add data validation checks
- Improve error reporting and diagnostics

### **4. Benchmarking Improvements**
- Test on more diverse data types
- Include robustness metrics
- Add failure mode analysis
- Implement comprehensive error tracking

## üìà **Next Steps**

1. **Test Neural Network Estimators** - Check if NN approaches are more robust
2. **Implement Robust Preprocessing** - Add NaN handling and outlier detection
3. **Retrain Models** - Train on diverse data including heavy-tailed scenarios
4. **Add Fallback Mechanisms** - Implement classical estimator fallbacks
5. **Comprehensive Error Analysis** - Detailed failure mode investigation

## üèÜ **Conclusion**

The ML estimators demonstrated **complete failure** on both pure and heavy-tailed data, revealing critical gaps in:
- **Feature engineering robustness**
- **NaN handling capabilities** 
- **Domain adaptation to extreme values**
- **Pre-trained model generalisation**

This highlights the importance of robust preprocessing and model adaptation when dealing with real-world data that may contain extreme values or heavy-tailed characteristics.
