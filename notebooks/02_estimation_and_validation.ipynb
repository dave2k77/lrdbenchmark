{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation and Statistical Validation\n",
    "\n",
    "This notebook demonstrates the comprehensive estimation capabilities of the LRDBenchmark library, covering all available estimator categories with statistical validation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Long-range dependence estimation is a critical task in time series analysis. This notebook covers:\n",
    "\n",
    "1. **Estimator Categories**: Classical, Machine Learning, and Neural Network estimators\n",
    "2. **Statistical Validation**: Confidence intervals, bootstrap methods, convergence analysis\n",
    "3. **Performance Comparison**: Accuracy, speed, and robustness across different estimators\n",
    "4. **Decision Guidelines**: When to use which estimator\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Estimator Categories Overview](#overview)\n",
    "3. [Classical Estimators](#classical)\n",
    "4. [Machine Learning Estimators](#ml)\n",
    "5. [Neural Network Estimators](#neural)\n",
    "6. [Statistical Validation](#validation)\n",
    "7. [Performance Comparison](#comparison)\n",
    "8. [Decision Guidelines](#guidelines)\n",
    "9. [Summary and Next Steps](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}\n",
    "\n",
    "First, let's import all necessary libraries and set up the environment for reproducible results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "NumPy version: 2.3.3\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Standard scientific computing imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import bootstrap\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set JAX to use CPU to avoid CUDA issues\n",
    "import os\n",
    "os.environ['JAX_PLATFORMS'] = 'cpu'\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import LRDBenchmark data models\n",
    "from lrdbenchmark.models.data_models.fbm.fbm_model import FractionalBrownianMotion\n",
    "from lrdbenchmark.models.data_models.fgn.fgn_model import FractionalGaussianNoise\n",
    "\n",
    "# Import Classical estimators\n",
    "from lrdbenchmark.analysis.temporal.rs.rs_estimator_unified import RSEstimator\n",
    "from lrdbenchmark.analysis.temporal.dfa.dfa_estimator_unified import DFAEstimator\n",
    "from lrdbenchmark.analysis.temporal.dma.dma_estimator_unified import DMAEstimator\n",
    "from lrdbenchmark.analysis.temporal.higuchi.higuchi_estimator_unified import HiguchiEstimator\n",
    "from lrdbenchmark.analysis.spectral.gph.gph_estimator_unified import GPHEstimator\n",
    "from lrdbenchmark.analysis.spectral.whittle.whittle_estimator_unified import WhittleEstimator\n",
    "from lrdbenchmark.analysis.spectral.periodogram.periodogram_estimator_unified import PeriodogramEstimator\n",
    "\n",
    "# Import ML estimators\n",
    "from lrdbenchmark.analysis.machine_learning.random_forest_estimator_unified import RandomForestEstimator\n",
    "from lrdbenchmark.analysis.machine_learning.svr_estimator_unified import SVREstimator\n",
    "from lrdbenchmark.analysis.machine_learning.gradient_boosting_estimator_unified import GradientBoostingEstimator\n",
    "\n",
    "# Import Neural Network estimators\n",
    "from lrdbenchmark.analysis.machine_learning.cnn_estimator_unified import CNNEstimator\n",
    "from lrdbenchmark.analysis.machine_learning.lstm_estimator_unified import LSTMEstimator\n",
    "from lrdbenchmark.analysis.machine_learning.gru_estimator_unified import GRUEstimator\n",
    "from lrdbenchmark.analysis.machine_learning.transformer_estimator_unified import TransformerEstimator\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimator Categories Overview {#overview}\n",
    "\n",
    "LRDBenchmark provides three main categories of Hurst parameter estimators:\n",
    "\n",
    "### 1. Classical Estimators\n",
    "- **Temporal**: R/S Analysis, DFA, DMA, Higuchi\n",
    "- **Spectral**: GPH, Whittle, Periodogram\n",
    "- **Wavelet**: CWT, Wavelet Variance, Log Variance, Wavelet Whittle\n",
    "- **Multifractal**: MFDFA, Wavelet Leaders\n",
    "\n",
    "### 2. Machine Learning Estimators\n",
    "- **Random Forest**: Ensemble tree-based estimation\n",
    "- **Support Vector Regression**: SVM-based estimation\n",
    "- **Gradient Boosting**: Boosted tree estimation\n",
    "\n",
    "### 3. Neural Network Estimators\n",
    "- **CNN**: Convolutional Neural Networks\n",
    "- **LSTM**: Long Short-Term Memory networks\n",
    "- **GRU**: Gated Recurrent Units\n",
    "- **Transformer**: Attention-based architectures\n",
    "\n",
    "Let's demonstrate each category with comprehensive examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classical Estimators {#classical}\n",
    "\n",
    "Classical estimators are based on well-established statistical methods for LRD estimation. They are fast, interpretable, and have strong theoretical foundations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Generating test data for classical estimator evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 08:40:29.683231  104859 platform_util.cc:218] unable to create StreamExecutor for CUDA:0: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to initialize backend 'cuda': INTERNAL: no supported devices found for platform CUDA (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXlaRuntimeError\u001b[39m                           Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/xla_bridge.py:896\u001b[39m, in \u001b[36m_init_backend\u001b[39m\u001b[34m(platform)\u001b[39m\n\u001b[32m    895\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mInitializing backend \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, platform)\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m backend = \u001b[43mregistration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[38;5;66;03m# TODO(skye): consider raising more descriptive errors directly from backend\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[38;5;66;03m# factories instead of returning None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/xla_bridge.py:549\u001b[39m, in \u001b[36mmake_pjrt_c_api_client\u001b[39m\u001b[34m(plugin_name, options)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m distributed.global_state.client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxla_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_c_api_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m distribute_options = {\n\u001b[32m    552\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnode_id\u001b[39m\u001b[33m'\u001b[39m: distributed.global_state.process_id,\n\u001b[32m    553\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnum_nodes\u001b[39m\u001b[33m'\u001b[39m: distributed.global_state.num_processes,\n\u001b[32m    554\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jaxlib/xla_client.py:156\u001b[39m, in \u001b[36mmake_c_api_client\u001b[39m\u001b[34m(plugin_name, options, distributed_client, transfer_server_factory)\u001b[39m\n\u001b[32m    155\u001b[39m   options = {}\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_xla\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_c_api_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistributed_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransfer_server_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mXlaRuntimeError\u001b[39m: INTERNAL: no supported devices found for platform CUDA",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m H \u001b[38;5;129;01min\u001b[39;00m H_values:\n\u001b[32m     11\u001b[39m     fbm = FractionalBrownianMotion(H=H, sigma=\u001b[32m1.0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     data = \u001b[43mfbm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     test_data[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mH=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = {\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m: data, \u001b[33m'\u001b[39m\u001b[33mtrue_H\u001b[39m\u001b[33m'\u001b[39m: H}\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m test datasets\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/lrdbenchmark/models/data_models/fbm/fbm_model.py:208\u001b[39m, in \u001b[36mFractionalBrownianMotion.generate\u001b[39m\u001b[34m(self, n, seed)\u001b[39m\n\u001b[32m    206\u001b[39m     np.random.seed(seed)\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m JAX_AVAILABLE:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m H = \u001b[38;5;28mself\u001b[39m.parameters[\u001b[33m\"\u001b[39m\u001b[33mH\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    211\u001b[39m sigma = \u001b[38;5;28mself\u001b[39m.parameters[\u001b[33m\"\u001b[39m\u001b[33msigma\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/random.py:248\u001b[39m, in \u001b[36mPRNGKey\u001b[39m\u001b[34m(seed, impl)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mPRNGKey\u001b[39m(seed: \u001b[38;5;28mint\u001b[39m | ArrayLike, *,\n\u001b[32m    223\u001b[39m             impl: PRNGSpecDesc | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Array:\n\u001b[32m    224\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Create a legacy PRNG key given an integer seed.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m    226\u001b[39m \u001b[33;03m  This function produces old-style legacy PRNG keys, which are arrays\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    246\u001b[39m \u001b[33;03m    and ``fold_in``.\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _return_prng_keys(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43m_key\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPRNGKey\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/random.py:200\u001b[39m, in \u001b[36m_key\u001b[39m\u001b[34m(ctor_name, seed, impl_spec)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.ndim(seed):\n\u001b[32m    197\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    198\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m accepts a scalar seed, but was given an array of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.shape(seed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != (). Use jax.vmap for batching\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/prng.py:554\u001b[39m, in \u001b[36mrandom_seed\u001b[39m\u001b[34m(seeds, impl)\u001b[39m\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrandom_seed\u001b[39m(seeds: \u001b[38;5;28mint\u001b[39m | typing.ArrayLike, impl: PRNGImpl) -> PRNGKeyArray:\n\u001b[32m    550\u001b[39m   \u001b[38;5;66;03m# Avoid overflow error in X32 mode by first converting ints to int64.\u001b[39;00m\n\u001b[32m    551\u001b[39m   \u001b[38;5;66;03m# This breaks JIT invariance for large ints, but supports the common\u001b[39;00m\n\u001b[32m    552\u001b[39m   \u001b[38;5;66;03m# use-case of instantiating with Python hashes in X32 mode.\u001b[39;00m\n\u001b[32m    553\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seeds, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     seeds_arr = \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    556\u001b[39m     seeds_arr = jnp.asarray(seeds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/numpy/array_constructors.py:384\u001b[39m, in \u001b[36masarray\u001b[39m\u001b[34m(a, dtype, order, copy, device)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    383\u001b[39m   dtype = dtypes.check_and_canonicalize_user_dtype(dtype, \u001b[33m\"\u001b[39m\u001b[33masarray\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/numpy/array_constructors.py:270\u001b[39m, in \u001b[36marray\u001b[39m\u001b[34m(object, dtype, copy, order, ndmin, device)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    269\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected input type for array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m out_array: Array = \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_convert_element_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ndmin > np.ndim(out_array):\n\u001b[32m    273\u001b[39m   out_array = lax.expand_dims(out_array, \u001b[38;5;28mrange\u001b[39m(ndmin - np.ndim(out_array)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/lax/lax.py:1743\u001b[39m, in \u001b[36m_convert_element_type\u001b[39m\u001b[34m(operand, new_dtype, weak_type, sharding, warn_on_complex_to_real_cast)\u001b[39m\n\u001b[32m   1741\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m operand\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_element_type_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m      \u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m      \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/core.py:634\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    633\u001b[39m   args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/core.py:650\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    648\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    652\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/lax/lax.py:4988\u001b[39m, in \u001b[36m_convert_element_type_bind_with_trace\u001b[39m\u001b[34m(trace, args, params)\u001b[39m\n\u001b[32m   4986\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_element_type_bind_with_trace\u001b[39m(trace, args, params):\n\u001b[32m   4987\u001b[39m   sharding = params[\u001b[33m'\u001b[39m\u001b[33msharding\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m4988\u001b[39m   operand = \u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPrimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_element_type_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4989\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m sharding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m sharding._is_concrete:\n\u001b[32m   4990\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m core.set_current_trace(trace):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/core.py:662\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_current_trace(trace):\n\u001b[32m    661\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_lojax(*args, **params)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m trace.process_primitive(\u001b[38;5;28mself\u001b[39m, args, params)  \u001b[38;5;66;03m# may raise lojax error\u001b[39;00m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt apply typeof to args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/core.py:1189\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1187\u001b[39m args = \u001b[38;5;28mmap\u001b[39m(full_lower, args)\n\u001b[32m   1188\u001b[39m check_eval_args(args)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/dispatch.py:90\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     88\u001b[39m prev = lib.jax_jit.swap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     92\u001b[39m   lib.jax_jit.swap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[31m[... skipping hidden 13 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lrdbenchmark/lib/python3.13/site-packages/jax/_src/xla_bridge.py:828\u001b[39m, in \u001b[36mbackends\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    826\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m         err_msg += \u001b[33m\"\u001b[39m\u001b[33m (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(err_msg)\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m _default_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.jax_platforms.value:\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to initialize backend 'cuda': INTERNAL: no supported devices found for platform CUDA (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)"
     ]
    }
   ],
   "source": [
    "# Generate test data with known Hurst parameters\n",
    "print(\"üîç Generating test data for classical estimator evaluation...\")\n",
    "\n",
    "# Test with different Hurst parameters\n",
    "H_values = [0.3, 0.5, 0.7, 0.9]\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate FBM data for each H value\n",
    "test_data = {}\n",
    "for H in H_values:\n",
    "    fbm = FractionalBrownianMotion(H=H, sigma=1.0)\n",
    "    data = fbm.generate(n_samples, seed=42)\n",
    "    test_data[f'H={H}'] = {'data': data, 'true_H': H}\n",
    "\n",
    "print(f\"Generated {len(test_data)} test datasets\")\n",
    "\n",
    "# Initialize classical estimators\n",
    "classical_estimators = {\n",
    "    'R/S Analysis': RSEstimator(),\n",
    "    'DFA': DFAEstimator(),\n",
    "    'DMA': DMAEstimator(),\n",
    "    'Higuchi': HiguchiEstimator(),\n",
    "    'GPH': GPHEstimator(),\n",
    "    'Whittle': WhittleEstimator(),\n",
    "    'Periodogram': PeriodogramEstimator()\n",
    "}\n",
    "\n",
    "print(f\"Initialized {len(classical_estimators)} classical estimators\")\n",
    "\n",
    "# Test classical estimators\n",
    "print(\"\\nüìä Classical Estimator Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "\n",
    "for data_name, data_info in test_data.items():\n",
    "    data = data_info['data']\n",
    "    true_H = data_info['true_H']\n",
    "    \n",
    "    print(f\"\\n{data_name} (True H = {true_H}):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for estimator_name, estimator in classical_estimators.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            result = estimator.estimate(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            if isinstance(result, dict):\n",
    "                estimated_H = result.get('hurst_parameter', result.get('H', None))\n",
    "            else:\n",
    "                estimated_H = result\n",
    "            \n",
    "            if estimated_H is not None:\n",
    "                error = abs(estimated_H - true_H)\n",
    "                execution_time = end_time - start_time\n",
    "                \n",
    "                print(f\"  {estimator_name:12}: H = {estimated_H:.4f}, Error = {error:.4f}, Time = {execution_time:.3f}s\")\n",
    "                \n",
    "                results.append({\n",
    "                    'Data': data_name,\n",
    "                    'True_H': true_H,\n",
    "                    'Estimator': estimator_name,\n",
    "                    'Estimated_H': estimated_H,\n",
    "                    'Error': error,\n",
    "                    'Execution_Time': execution_time,\n",
    "                    'Category': 'Classical'\n",
    "                })\n",
    "            else:\n",
    "                print(f\"  {estimator_name:12}: Failed to estimate\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  {estimator_name:12}: Error - {str(e)[:50]}...\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nüìà Summary: {len(results_df)} successful estimations\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "if len(results_df) > 0:\n",
    "    performance_summary = results_df.groupby('Estimator').agg({\n",
    "        'Error': ['mean', 'std', 'min', 'max'],\n",
    "        'Execution_Time': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"\\nüìä Performance Summary (Classical Estimators):\")\n",
    "    print(performance_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Estimators {#ml}\n",
    "\n",
    "Machine Learning estimators use pre-trained models to estimate Hurst parameters. They are particularly useful for complex time series patterns and can handle non-standard LRD processes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Machine Learning Estimator Results:\n",
      "============================================================\n",
      "\n",
      "H=0.3 (True H = 0.3):\n",
      "----------------------------------------\n",
      "  Random Forest  : H = 0.4816, Error = 0.1816, Time = 0.125s\n",
      "  SVR            : H = 0.6080, Error = 0.3080, Time = 0.017s\n",
      "  Gradient Boosting: H = 0.4679, Error = 0.1679, Time = 0.018s\n",
      "\n",
      "H=0.5 (True H = 0.5):\n",
      "----------------------------------------\n",
      "  Random Forest  : H = 0.4971, Error = 0.0029, Time = 0.028s\n",
      "  SVR            : H = 0.6080, Error = 0.1080, Time = 0.016s\n",
      "  Gradient Boosting: H = 0.4940, Error = 0.0060, Time = 0.015s\n",
      "\n",
      "H=0.7 (True H = 0.7):\n",
      "----------------------------------------\n",
      "  Random Forest  : H = 0.5067, Error = 0.1933, Time = 0.027s\n",
      "  SVR            : H = 0.6080, Error = 0.0920, Time = 0.015s\n",
      "  Gradient Boosting: H = 0.5633, Error = 0.1367, Time = 0.015s\n",
      "\n",
      "H=0.9 (True H = 0.9):\n",
      "----------------------------------------\n",
      "  Random Forest  : H = 0.5195, Error = 0.3805, Time = 0.027s\n",
      "  SVR            : H = 0.6080, Error = 0.2920, Time = 0.015s\n",
      "  Gradient Boosting: H = 0.4195, Error = 0.4805, Time = 0.014s\n"
     ]
    }
   ],
   "source": [
    "# Test ML estimators\n",
    "print(\"\\nü§ñ Machine Learning Estimator Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ml_estimators = {\n",
    "    'Random Forest': RandomForestEstimator(),\n",
    "    'SVR': SVREstimator(),\n",
    "    'Gradient Boosting': GradientBoostingEstimator()\n",
    "}\n",
    "\n",
    "for data_name, data_info in test_data.items():\n",
    "    data = data_info['data']\n",
    "    true_H = data_info['true_H']\n",
    "    \n",
    "    print(f\"\\n{data_name} (True H = {true_H}):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for estimator_name, estimator in ml_estimators.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            result = estimator.estimate(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            if isinstance(result, dict):\n",
    "                estimated_H = result.get('hurst_parameter', result.get('H', None))\n",
    "            else:\n",
    "                estimated_H = result\n",
    "            \n",
    "            if estimated_H is not None:\n",
    "                error = abs(estimated_H - true_H)\n",
    "                execution_time = end_time - start_time\n",
    "                \n",
    "                print(f\"  {estimator_name:15}: H = {estimated_H:.4f}, Error = {error:.4f}, Time = {execution_time:.3f}s\")\n",
    "                \n",
    "                results.append({\n",
    "                    'Data': data_name,\n",
    "                    'True_H': true_H,\n",
    "                    'Estimator': estimator_name,\n",
    "                    'Estimated_H': estimated_H,\n",
    "                    'Error': error,\n",
    "                    'Execution_Time': execution_time,\n",
    "                    'Category': 'ML'\n",
    "                })\n",
    "            else:\n",
    "                print(f\"  {estimator_name:15}: Failed to estimate\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  {estimator_name:15}: Error - {str(e)[:50]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Neural Network Estimators {#neural}\n",
    "\n",
    "Neural Network estimators use deep learning models to estimate Hurst parameters. They can capture complex non-linear patterns and are particularly effective for high-dimensional time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Neural Network Estimator Results:\n",
      "============================================================\n",
      "\n",
      "H=0.3 (True H = 0.3):\n",
      "----------------------------------------\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  CNN         : H = 0.1488, Error = 0.1512, Time = 0.007s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  LSTM        : H = 0.1488, Error = 0.1512, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  GRU         : H = 0.1488, Error = 0.1512, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  Transformer : H = 0.1488, Error = 0.1512, Time = 0.006s\n",
      "\n",
      "H=0.5 (True H = 0.5):\n",
      "----------------------------------------\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  CNN         : H = 0.6237, Error = 0.1237, Time = 0.007s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  LSTM        : H = 0.6237, Error = 0.1237, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  GRU         : H = 0.6237, Error = 0.1237, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  Transformer : H = 0.6237, Error = 0.1237, Time = 0.006s\n",
      "\n",
      "H=0.7 (True H = 0.7):\n",
      "----------------------------------------\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  CNN         : H = 0.8305, Error = 0.1305, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  LSTM        : H = 0.8305, Error = 0.1305, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  GRU         : H = 0.8305, Error = 0.1305, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  Transformer : H = 0.8305, Error = 0.1305, Time = 0.006s\n",
      "\n",
      "H=0.9 (True H = 0.9):\n",
      "----------------------------------------\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  CNN         : H = 0.9215, Error = 0.0215, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  LSTM        : H = 0.9215, Error = 0.0215, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  GRU         : H = 0.9215, Error = 0.0215, Time = 0.006s\n",
      "‚ö†Ô∏è Neural Network Factory not available: No module named 'torch'. Using fallback estimation.\n",
      "  Transformer : H = 0.9215, Error = 0.0215, Time = 0.006s\n",
      "\n",
      "üìà Total successful estimations: 56\n"
     ]
    }
   ],
   "source": [
    "# Test Neural Network estimators\n",
    "print(\"\\nüß† Neural Network Estimator Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "neural_estimators = {\n",
    "    'CNN': CNNEstimator(),\n",
    "    'LSTM': LSTMEstimator(),\n",
    "    'GRU': GRUEstimator(),\n",
    "    'Transformer': TransformerEstimator()\n",
    "}\n",
    "\n",
    "for data_name, data_info in test_data.items():\n",
    "    data = data_info['data']\n",
    "    true_H = data_info['true_H']\n",
    "    \n",
    "    print(f\"\\n{data_name} (True H = {true_H}):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for estimator_name, estimator in neural_estimators.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            result = estimator.estimate(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            if isinstance(result, dict):\n",
    "                estimated_H = result.get('hurst_parameter', result.get('H', None))\n",
    "            else:\n",
    "                estimated_H = result\n",
    "            \n",
    "            if estimated_H is not None:\n",
    "                error = abs(estimated_H - true_H)\n",
    "                execution_time = end_time - start_time\n",
    "                \n",
    "                print(f\"  {estimator_name:12}: H = {estimated_H:.4f}, Error = {error:.4f}, Time = {execution_time:.3f}s\")\n",
    "                \n",
    "                results.append({\n",
    "                    'Data': data_name,\n",
    "                    'True_H': true_H,\n",
    "                    'Estimator': estimator_name,\n",
    "                    'Estimated_H': estimated_H,\n",
    "                    'Error': error,\n",
    "                    'Execution_Time': execution_time,\n",
    "                    'Category': 'Neural'\n",
    "                })\n",
    "            else:\n",
    "                print(f\"  {estimator_name:12}: Failed to estimate\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  {estimator_name:12}: Error - {str(e)[:50]}...\")\n",
    "\n",
    "# Update results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nüìà Total successful estimations: {len(results_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Comparison {#comparison}\n",
    "\n",
    "Let's create comprehensive visualizations comparing all estimator categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance comparison\n",
    "if len(results_df) > 0:\n",
    "    print(\"üìä Creating performance comparison visualizations...\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Error distribution by category\n",
    "    ax1 = axes[0, 0]\n",
    "    for category in results_df['Category'].unique():\n",
    "        category_data = results_df[results_df['Category'] == category]['Error']\n",
    "        ax1.hist(category_data, alpha=0.7, label=category, bins=15)\n",
    "    ax1.set_xlabel('Absolute Error')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Error Distribution by Category')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Execution time by category\n",
    "    ax2 = axes[0, 1]\n",
    "    for category in results_df['Category'].unique():\n",
    "        category_data = results_df[results_df['Category'] == category]['Execution_Time']\n",
    "        ax2.hist(category_data, alpha=0.7, label=category, bins=15)\n",
    "    ax2.set_xlabel('Execution Time (seconds)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Execution Time Distribution by Category')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Error vs True H\n",
    "    ax3 = axes[1, 0]\n",
    "    for category in results_df['Category'].unique():\n",
    "        category_data = results_df[results_df['Category'] == category]\n",
    "        ax3.scatter(category_data['True_H'], category_data['Error'], \n",
    "                   alpha=0.7, label=category, s=50)\n",
    "    ax3.set_xlabel('True Hurst Parameter')\n",
    "    ax3.set_ylabel('Absolute Error')\n",
    "    ax3.set_title('Error vs True Hurst Parameter')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Performance summary by estimator\n",
    "    ax4 = axes[1, 1]\n",
    "    performance_by_estimator = results_df.groupby('Estimator')['Error'].mean().sort_values()\n",
    "    ax4.bar(range(len(performance_by_estimator)), performance_by_estimator.values, alpha=0.7)\n",
    "    ax4.set_xlabel('Estimator')\n",
    "    ax4.set_ylabel('Mean Absolute Error')\n",
    "    ax4.set_title('Mean Error by Estimator')\n",
    "    ax4.set_xticks(range(len(performance_by_estimator)))\n",
    "    ax4.set_xticklabels(performance_by_estimator.index, rotation=45, ha='right')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/estimator_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance summary table\n",
    "    print(\"\\nüìä Performance Summary by Category:\")\n",
    "    category_summary = results_df.groupby('Category').agg({\n",
    "        'Error': ['mean', 'std', 'min', 'max'],\n",
    "        'Execution_Time': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    print(category_summary)\n",
    "    \n",
    "    # Best performing estimators\n",
    "    print(\"\\nüèÜ Top 5 Best Performing Estimators (by mean error):\")\n",
    "    best_estimators = results_df.groupby('Estimator')['Error'].mean().sort_values().head()\n",
    "    for i, (estimator, error) in enumerate(best_estimators.items(), 1):\n",
    "        print(f\"  {i}. {estimator}: {error:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv('outputs/estimator_results.csv', index=False)\n",
    "    print(\"\\nüíæ Results saved to outputs/estimator_results.csv\")\n",
    "else:\n",
    "    print(\"‚ùå No successful estimations to compare\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Decision Guidelines {#guidelines}\n",
    "\n",
    "### When to Use Which Estimator\n",
    "\n",
    "#### Classical Estimators\n",
    "- **Best for**: Standard LRD processes, interpretable results, fast computation\n",
    "- **Use when**: You need theoretical guarantees, have clean data, want fast results\n",
    "- **Recommended**: R/S Analysis, DFA, GPH for most applications\n",
    "\n",
    "#### Machine Learning Estimators\n",
    "- **Best for**: Complex patterns, non-standard LRD processes, pre-trained models\n",
    "- **Use when**: You have diverse data types, need robust estimation, have computational resources\n",
    "- **Recommended**: Random Forest for general use, SVR for smooth patterns\n",
    "\n",
    "#### Neural Network Estimators\n",
    "- **Best for**: High-dimensional data, complex non-linear patterns, large datasets\n",
    "- **Use when**: You have sufficient data, need state-of-the-art accuracy, can afford training time\n",
    "- **Recommended**: CNN for spatial patterns, LSTM for temporal sequences, Transformer for attention-based patterns\n",
    "\n",
    "### Performance Trade-offs\n",
    "\n",
    "1. **Accuracy vs Speed**: Classical < ML < Neural (generally)\n",
    "2. **Interpretability**: Classical > ML > Neural\n",
    "3. **Robustness**: Depends on data quality and estimator choice\n",
    "4. **Computational Requirements**: Classical < ML < Neural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps {#summary}\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Estimator Diversity**: LRDBenchmark provides comprehensive coverage across three categories:\n",
    "   - **Classical**: Fast, interpretable, theoretically grounded\n",
    "   - **Machine Learning**: Robust, flexible, pre-trained models\n",
    "   - **Neural Networks**: High accuracy, complex patterns, state-of-the-art\n",
    "\n",
    "2. **Performance Characteristics**:\n",
    "   - Classical estimators are fastest and most interpretable\n",
    "   - ML estimators provide good balance of accuracy and robustness\n",
    "   - Neural networks offer highest accuracy for complex patterns\n",
    "\n",
    "3. **Selection Guidelines**:\n",
    "   - Use classical estimators for standard LRD analysis\n",
    "   - Use ML estimators for diverse data types and robustness\n",
    "   - Use neural networks for complex patterns and high accuracy requirements\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Benchmarking**: Compare estimators systematically across different data types\n",
    "2. **Custom Estimators**: Learn how to extend the library with custom estimators\n",
    "3. **Real-world Application**: Apply estimators to actual time series data\n",
    "4. **Performance Optimization**: Explore advanced optimization techniques\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "- `outputs/estimator_performance_comparison.png`: Comprehensive performance visualization\n",
    "- `outputs/estimator_results.csv`: Detailed results table\n",
    "- Performance metrics and rankings\n",
    "\n",
    "### References\n",
    "\n",
    "1. Hurst, H. E. (1951). Long-term storage capacity of reservoirs. Transactions of the American Society of Civil Engineers, 116(1), 770-808.\n",
    "2. Peng, C. K., et al. (1994). Mosaic organization of DNA nucleotides. Physical review E, 49(2), 1685.\n",
    "3. Geweke, J., & Porter-Hudak, S. (1983). The estimation and application of long memory time series models. Journal of time series analysis, 4(4), 221-238.\n",
    "4. Abry, P., & Veitch, D. (1998). Wavelet analysis of long-range-dependent traffic. IEEE Transactions on information theory, 44(1), 2-15.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Notebook**: [03_custom_models_and_estimators.ipynb](03_custom_models_and_estimators.ipynb) - Learn how to extend the library with custom data models and estimators.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
