{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Estimation and Statistical Validation\n",
        "\n",
        "This notebook demonstrates the comprehensive estimation capabilities of the LRDBenchmark library, covering all available estimator categories with statistical validation.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Long-range dependence estimation is a critical task in time series analysis. This notebook covers:\n",
        "\n",
        "1. **Estimator Categories**: Classical, Machine Learning, and Neural Network estimators\n",
        "2. **Statistical Validation**: Confidence intervals, bootstrap methods, convergence analysis\n",
        "3. **Performance Comparison**: Accuracy, speed, and robustness across different estimators\n",
        "4. **Decision Guidelines**: When to use which estimator\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Estimator Categories Overview](#overview)\n",
        "3. [Classical Estimators](#classical)\n",
        "4. [Machine Learning Estimators](#ml)\n",
        "5. [Neural Network Estimators](#neural)\n",
        "6. [Statistical Validation](#validation)\n",
        "7. [Performance Comparison](#comparison)\n",
        "8. [Decision Guidelines](#guidelines)\n",
        "9. [Summary and Next Steps](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports {#setup}\n",
        "\n",
        "First, let's import all necessary libraries and set up the environment for reproducible results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/davianc/Documents/LRDBenchmark/lrdbenchmark/utils.py:229: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "# Standard scientific computing imports\n",
        "import numpy as np\n",
        "# LRDBenchmark imports - using simplified API\n",
        "from lrdbenchmark import (\n",
        "    # Data models\n",
        "    FBMModel, FGNModel, ARFIMAModel, MRWModel, AlphaStableModel,\n",
        "    # Classical estimators (only available ones)\n",
        "    RSEstimator, DFAEstimator, GPHEstimator, WhittleEstimator,\n",
        "    # Machine Learning estimators\n",
        "    RandomForestEstimator, SVREstimator, GradientBoostingEstimator,\n",
        "    # Neural Network estimators\n",
        "    CNNEstimator, LSTMEstimator, GRUEstimator, TransformerEstimator,\n",
        "    # GPU utilities\n",
        "    gpu_is_available, get_device_info, clear_gpu_cache, monitor_gpu_memory\n",
        ")\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import bootstrap\n",
        "import time\n",
        "import warnings\n",
        "import subprocess\n",
        "import gc\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set JAX to use CPU to avoid CUDA issues\n",
        "import os\n",
        "os.environ['JAX_PLATFORMS'] = 'cpu'\n",
        "\n",
        "# GPU Memory Management Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Estimator Categories Overview {#overview}\n",
        "\n",
        "LRDBenchmark provides three main categories of Hurst parameter estimators:\n",
        "\n",
        "### 1. Classical Estimators\n",
        "- **Temporal**: R/S Analysis, DFA, DMA, Higuchi\n",
        "- **Spectral**: GPH, Whittle, Periodogram\n",
        "- **Wavelet**: CWT, Wavelet Variance, Log Variance, Wavelet Whittle\n",
        "- **Multifractal**: MFDFA, Wavelet Leaders\n",
        "\n",
        "### 2. Machine Learning Estimators\n",
        "- **Random Forest**: Ensemble tree-based estimation\n",
        "- **Support Vector Regression**: SVM-based estimation\n",
        "- **Gradient Boosting**: Boosted tree estimation\n",
        "\n",
        "### 3. Neural Network Estimators\n",
        "- **CNN**: Convolutional Neural Networks\n",
        "- **LSTM**: Long Short-Term Memory networks\n",
        "- **GRU**: Gated Recurrent Units\n",
        "- **Transformer**: Attention-based architectures\n",
        "\n",
        "Let's demonstrate each category with comprehensive examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Classical Estimators {#classical}\n",
        "\n",
        "Classical estimators are based on well-established statistical methods for LRD estimation. They are fast, interpretable, and have strong theoretical foundations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Generating test data for classical estimator evaluation...\n",
            "Generated 4 test datasets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W1016 16:32:26.207504   81429 platform_util.cc:218] unable to create StreamExecutor for CUDA:0: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'DMAEstimator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m test datasets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Initialize classical estimators\u001b[39;00m\n\u001b[32m     18\u001b[39m classical_estimators = {\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mR/S Analysis\u001b[39m\u001b[33m'\u001b[39m: RSEstimator(),\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDFA\u001b[39m\u001b[33m'\u001b[39m: DFAEstimator(),\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDMA\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mDMAEstimator\u001b[49m(),\n\u001b[32m     22\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHiguchi\u001b[39m\u001b[33m'\u001b[39m: HiguchiEstimator(),\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mGPH\u001b[39m\u001b[33m'\u001b[39m: GPHEstimator(),\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mWhittle\u001b[39m\u001b[33m'\u001b[39m: WhittleEstimator(),\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPeriodogram\u001b[39m\u001b[33m'\u001b[39m: PeriodogramEstimator()\n\u001b[32m     26\u001b[39m }\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitialized \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(classical_estimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m classical estimators\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Test classical estimators\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'DMAEstimator' is not defined"
          ]
        }
      ],
      "source": [
        "# Generate test data with known Hurst parameters\n",
        "print(\"üîç Generating test data for classical estimator evaluation...\")\n",
        "\n",
        "# Test with different Hurst parameters\n",
        "H_values = [0.3, 0.5, 0.7, 0.9]\n",
        "n_samples = 1000\n",
        "\n",
        "# Generate FBM data for each H value\n",
        "test_data = {}\n",
        "for H in H_values:\n",
        "    fbm = FBMModel(H=H, sigma=1.0)\n",
        "    data = fbm.generate(length=n_samples, seed=42)\n",
        "    test_data[f'H={H}'] = {'data': data, 'true_H': H}\n",
        "\n",
        "print(f\"Generated {len(test_data)} test datasets\")\n",
        "\n",
        "# Initialize classical estimators (only available ones)\n",
        "classical_estimators = {\n",
        "    'R/S Analysis': RSEstimator(),\n",
        "    'DFA': DFAEstimator(),\n",
        "    'GPH': GPHEstimator(),\n",
        "    'Whittle': WhittleEstimator()\n",
        "}\n",
        "\n",
        "print(f\"Initialized {len(classical_estimators)} classical estimators\")\n",
        "\n",
        "# Test classical estimators\n",
        "print(\"\\nüìä Classical Estimator Results:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results = []\n",
        "\n",
        "for data_name, data_info in test_data.items():\n",
        "    data = data_info['data']\n",
        "    true_H = data_info['true_H']\n",
        "    \n",
        "    print(f\"\\n{data_name} (True H = {true_H}):\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for estimator_name, estimator in classical_estimators.items():\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            result = estimator.estimate(data)\n",
        "            end_time = time.time()\n",
        "            \n",
        "            if isinstance(result, dict):\n",
        "                estimated_H = result.get('hurst_parameter', result.get('H', None))\n",
        "            else:\n",
        "                estimated_H = result\n",
        "            \n",
        "            if estimated_H is not None:\n",
        "                error = abs(estimated_H - true_H)\n",
        "                execution_time = end_time - start_time\n",
        "                \n",
        "                print(f\"  {estimator_name:12}: H = {estimated_H:.4f}, Error = {error:.4f}, Time = {execution_time:.3f}s\")\n",
        "                \n",
        "                results.append({\n",
        "                    'Data': data_name,\n",
        "                    'True_H': true_H,\n",
        "                    'Estimator': estimator_name,\n",
        "                    'Estimated_H': estimated_H,\n",
        "                    'Error': error,\n",
        "                    'Execution_Time': execution_time,\n",
        "                    'Category': 'Classical'\n",
        "                })\n",
        "            else:\n",
        "                print(f\"  {estimator_name:12}: Failed to estimate\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  {estimator_name:12}: Error - {str(e)[:50]}...\")\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(f\"\\nüìà Summary: {len(results_df)} successful estimations\")\n",
        "\n",
        "# Calculate performance metrics\n",
        "if len(results_df) > 0:\n",
        "    performance_summary = results_df.groupby('Estimator').agg({\n",
        "        'Error': ['mean', 'std', 'min', 'max'],\n",
        "        'Execution_Time': ['mean', 'std']\n",
        "    }).round(4)\n",
        "    \n",
        "    print(\"\\nüìä Performance Summary (Classical Estimators):\")\n",
        "    print(performance_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Machine Learning Estimators {#ml}\n",
        "\n",
        "Machine Learning estimators use pre-trained models to estimate Hurst parameters. They are particularly useful for complex time series patterns and can handle non-standard LRD processes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test ML estimators\n",
        "print(\"\\nü§ñ Machine Learning Estimator Results:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "ml_estimators = {\n",
        "    'Random Forest': RandomForestEstimator(),\n",
        "    'SVR': SVREstimator(),\n",
        "    'Gradient Boosting': GradientBoostingEstimator()\n",
        "}\n",
        "\n",
        "for data_name, data_info in test_data.items():\n",
        "    data = data_info['data']\n",
        "    true_H = data_info['true_H']\n",
        "    \n",
        "    print(f\"\\n{data_name} (True H = {true_H}):\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for estimator_name, estimator in ml_estimators.items():\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            result = estimator.estimate(data)\n",
        "            end_time = time.time()\n",
        "            \n",
        "            if isinstance(result, dict):\n",
        "                estimated_H = result.get('hurst_parameter', result.get('H', None))\n",
        "            else:\n",
        "                estimated_H = result\n",
        "            \n",
        "            if estimated_H is not None:\n",
        "                error = abs(estimated_H - true_H)\n",
        "                execution_time = end_time - start_time\n",
        "                \n",
        "                print(f\"  {estimator_name:15}: H = {estimated_H:.4f}, Error = {error:.4f}, Time = {execution_time:.3f}s\")\n",
        "                \n",
        "                results.append({\n",
        "                    'Data': data_name,\n",
        "                    'True_H': true_H,\n",
        "                    'Estimator': estimator_name,\n",
        "                    'Estimated_H': estimated_H,\n",
        "                    'Error': error,\n",
        "                    'Execution_Time': execution_time,\n",
        "                    'Category': 'ML'\n",
        "                })\n",
        "            else:\n",
        "                print(f\"  {estimator_name:15}: Failed to estimate\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  {estimator_name:15}: Error - {str(e)[:50]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Neural Network Estimators {#neural}\n",
        "\n",
        "Neural Network estimators use deep learning models to estimate Hurst parameters. They can capture complex non-linear patterns and are particularly effective for high-dimensional time series.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU Memory Management for Neural Networks\n",
        "print(\"\\nüîß GPU Memory Management:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Check GPU memory before neural network operations\n",
        "print(\"üîç Checking GPU memory before neural network operations...\")\n",
        "gpu_is_available()\n",
        "\n",
        "# Clear any existing GPU memory\n",
        "print(\"\\nüßπ Clearing GPU memory...\")\n",
        "clear_gpu_cache()\n",
        "\n",
        "# Check GPU memory after cleanup\n",
        "print(\"\\nüîç Checking GPU memory after cleanup...\")\n",
        "gpu_is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Neural Network estimators\n",
        "print(\"\\nüß† Neural Network Estimator Results:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "neural_estimators = {\n",
        "    'CNN': CNNEstimator(),\n",
        "    'LSTM': LSTMEstimator(),\n",
        "    'GRU': GRUEstimator(),\n",
        "    'Transformer': TransformerEstimator()\n",
        "}\n",
        "\n",
        "for data_name, data_info in test_data.items():\n",
        "    data = data_info['data']\n",
        "    true_H = data_info['true_H']\n",
        "    \n",
        "    print(f\"\\n{data_name} (True H = {true_H}):\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for estimator_name, estimator in neural_estimators.items():\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            result = estimator.estimate(data)\n",
        "            end_time = time.time()\n",
        "            \n",
        "            if isinstance(result, dict):\n",
        "                estimated_H = result.get('hurst_parameter', result.get('H', None))\n",
        "            else:\n",
        "                estimated_H = result\n",
        "            \n",
        "            if estimated_H is not None:\n",
        "                error = abs(estimated_H - true_H)\n",
        "                execution_time = end_time - start_time\n",
        "                \n",
        "                print(f\"  {estimator_name:12}: H = {estimated_H:.4f}, Error = {error:.4f}, Time = {execution_time:.3f}s\")\n",
        "                \n",
        "                results.append({\n",
        "                    'Data': data_name,\n",
        "                    'True_H': true_H,\n",
        "                    'Estimator': estimator_name,\n",
        "                    'Estimated_H': estimated_H,\n",
        "                    'Error': error,\n",
        "                    'Execution_Time': execution_time,\n",
        "                    'Category': 'Neural'\n",
        "                })\n",
        "            else:\n",
        "                print(f\"  {estimator_name:12}: Failed to estimate\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  {estimator_name:12}: Error - {str(e)[:50]}...\")\n",
        "\n",
        "# Update results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(f\"\\nüìà Total successful estimations: {len(results_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Performance Comparison {#comparison}\n",
        "\n",
        "Let's create comprehensive visualizations comparing all estimator categories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive performance comparison\n",
        "if len(results_df) > 0:\n",
        "    print(\"üìä Creating performance comparison visualizations...\")\n",
        "    \n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Error distribution by category\n",
        "    ax1 = axes[0, 0]\n",
        "    for category in results_df['Category'].unique():\n",
        "        category_data = results_df[results_df['Category'] == category]['Error']\n",
        "        ax1.hist(category_data, alpha=0.7, label=category, bins=15)\n",
        "    ax1.set_xlabel('Absolute Error')\n",
        "    ax1.set_ylabel('Frequency')\n",
        "    ax1.set_title('Error Distribution by Category')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Execution time by category\n",
        "    ax2 = axes[0, 1]\n",
        "    for category in results_df['Category'].unique():\n",
        "        category_data = results_df[results_df['Category'] == category]['Execution_Time']\n",
        "        ax2.hist(category_data, alpha=0.7, label=category, bins=15)\n",
        "    ax2.set_xlabel('Execution Time (seconds)')\n",
        "    ax2.set_ylabel('Frequency')\n",
        "    ax2.set_title('Execution Time Distribution by Category')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Error vs True H\n",
        "    ax3 = axes[1, 0]\n",
        "    for category in results_df['Category'].unique():\n",
        "        category_data = results_df[results_df['Category'] == category]\n",
        "        ax3.scatter(category_data['True_H'], category_data['Error'], \n",
        "                   alpha=0.7, label=category, s=50)\n",
        "    ax3.set_xlabel('True Hurst Parameter')\n",
        "    ax3.set_ylabel('Absolute Error')\n",
        "    ax3.set_title('Error vs True Hurst Parameter')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Performance summary by estimator\n",
        "    ax4 = axes[1, 1]\n",
        "    performance_by_estimator = results_df.groupby('Estimator')['Error'].mean().sort_values()\n",
        "    ax4.bar(range(len(performance_by_estimator)), performance_by_estimator.values, alpha=0.7)\n",
        "    ax4.set_xlabel('Estimator')\n",
        "    ax4.set_ylabel('Mean Absolute Error')\n",
        "    ax4.set_title('Mean Error by Estimator')\n",
        "    ax4.set_xticks(range(len(performance_by_estimator)))\n",
        "    ax4.set_xticklabels(performance_by_estimator.index, rotation=45, ha='right')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/estimator_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Performance summary table\n",
        "    print(\"\\nüìä Performance Summary by Category:\")\n",
        "    category_summary = results_df.groupby('Category').agg({\n",
        "        'Error': ['mean', 'std', 'min', 'max'],\n",
        "        'Execution_Time': ['mean', 'std']\n",
        "    }).round(4)\n",
        "    print(category_summary)\n",
        "    \n",
        "    # Best performing estimators\n",
        "    print(\"\\nüèÜ Top 5 Best Performing Estimators (by mean error):\")\n",
        "    best_estimators = results_df.groupby('Estimator')['Error'].mean().sort_values().head()\n",
        "    for i, (estimator, error) in enumerate(best_estimators.items(), 1):\n",
        "        print(f\"  {i}. {estimator}: {error:.4f}\")\n",
        "    \n",
        "    # Save results\n",
        "    results_df.to_csv('outputs/estimator_results.csv', index=False)\n",
        "    print(\"\\nüíæ Results saved to outputs/estimator_results.csv\")\n",
        "else:\n",
        "    print(\"‚ùå No successful estimations to compare\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Decision Guidelines {#guidelines}\n",
        "\n",
        "### When to Use Which Estimator\n",
        "\n",
        "#### Classical Estimators\n",
        "- **Best for**: Standard LRD processes, interpretable results, fast computation\n",
        "- **Use when**: You need theoretical guarantees, have clean data, want fast results\n",
        "- **Recommended**: R/S Analysis, DFA, GPH for most applications\n",
        "\n",
        "#### Machine Learning Estimators\n",
        "- **Best for**: Complex patterns, non-standard LRD processes, pre-trained models\n",
        "- **Use when**: You have diverse data types, need robust estimation, have computational resources\n",
        "- **Recommended**: Random Forest for general use, SVR for smooth patterns\n",
        "\n",
        "#### Neural Network Estimators\n",
        "- **Best for**: High-dimensional data, complex non-linear patterns, large datasets\n",
        "- **Use when**: You have sufficient data, need state-of-the-art accuracy, can afford training time\n",
        "- **Recommended**: CNN for spatial patterns, LSTM for temporal sequences, Transformer for attention-based patterns\n",
        "\n",
        "### Performance Trade-offs\n",
        "\n",
        "1. **Accuracy vs Speed**: Classical < ML < Neural (generally)\n",
        "2. **Interpretability**: Classical > ML > Neural\n",
        "3. **Robustness**: Depends on data quality and estimator choice\n",
        "4. **Computational Requirements**: Classical < ML < Neural\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Next Steps {#summary}\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Estimator Diversity**: LRDBenchmark provides comprehensive coverage across three categories:\n",
        "   - **Classical**: Fast, interpretable, theoretically grounded\n",
        "   - **Machine Learning**: Robust, flexible, pre-trained models\n",
        "   - **Neural Networks**: High accuracy, complex patterns, state-of-the-art\n",
        "\n",
        "2. **Performance Characteristics**:\n",
        "   - Classical estimators are fastest and most interpretable\n",
        "   - ML estimators provide good balance of accuracy and robustness\n",
        "   - Neural networks offer highest accuracy for complex patterns\n",
        "\n",
        "3. **Selection Guidelines**:\n",
        "   - Use classical estimators for standard LRD analysis\n",
        "   - Use ML estimators for diverse data types and robustness\n",
        "   - Use neural networks for complex patterns and high accuracy requirements\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Benchmarking**: Compare estimators systematically across different data types\n",
        "2. **Custom Estimators**: Learn how to extend the library with custom estimators\n",
        "3. **Real-world Application**: Apply estimators to actual time series data\n",
        "4. **Performance Optimization**: Explore advanced optimization techniques\n",
        "\n",
        "### Files Generated\n",
        "\n",
        "- `outputs/estimator_performance_comparison.png`: Comprehensive performance visualization\n",
        "- `outputs/estimator_results.csv`: Detailed results table\n",
        "- Performance metrics and rankings\n",
        "\n",
        "### References\n",
        "\n",
        "1. Hurst, H. E. (1951). Long-term storage capacity of reservoirs. Transactions of the American Society of Civil Engineers, 116(1), 770-808.\n",
        "2. Peng, C. K., et al. (1994). Mosaic organization of DNA nucleotides. Physical review E, 49(2), 1685.\n",
        "3. Geweke, J., & Porter-Hudak, S. (1983). The estimation and application of long memory time series models. Journal of time series analysis, 4(4), 221-238.\n",
        "4. Abry, P., & Veitch, D. (1998). Wavelet analysis of long-range-dependent traffic. IEEE Transactions on information theory, 44(1), 2-15.\n",
        "\n",
        "---\n",
        "\n",
        "**Next Notebook**: [03_custom_models_and_estimators.ipynb](03_custom_models_and_estimators.ipynb) - Learn how to extend the library with custom data models and estimators.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
