{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Leaderboard Generation\n",
        "\n",
        "This notebook demonstrates how to create comprehensive performance leaderboards from benchmark results, showing how to rank estimators and generate publication-ready comparisons.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The leaderboard generation system allows you to:\n",
        "\n",
        "1. **Load Benchmark Results**: Import results from multiple benchmark runs\n",
        "2. **Create Rankings**: Generate performance rankings across different metrics\n",
        "3. **Composite Scoring**: Combine multiple metrics into overall scores\n",
        "4. **Visualization**: Create publication-ready plots and tables\n",
        "5. **Export Results**: Save leaderboards in various formats\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Loading Benchmark Results](#loading)\n",
        "3. [Creating Performance Rankings](#rankings)\n",
        "4. [Composite Scoring System](#scoring)\n",
        "5. [Visualization and Export](#visualization)\n",
        "6. [Summary and Next Steps](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports {#setup}\n",
        "\n",
        "First, let's import all necessary libraries and set up the leaderboard generation system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n",
            "üèÜ Ready to generate performance leaderboards\n"
          ]
        }
      ],
      "source": [
        "# Standard scientific computing imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Import LRDBenchmark leaderboard system\n",
        "from lrdbenchmark.analysis.benchmark import ComprehensiveBenchmark\n",
        "\n",
        "# Import data models for generating test data\n",
        "from lrdbenchmark.models.data_models.fbm.fbm_model import FractionalBrownianMotion\n",
        "from lrdbenchmark.models.data_models.fgn.fgn_model import FractionalGaussianNoise\n",
        "\n",
        "# Import estimators for testing\n",
        "from lrdbenchmark.analysis.temporal.rs.rs_estimator_unified import RSEstimator\n",
        "from lrdbenchmark.analysis.temporal.dfa.dfa_estimator_unified import DFAEstimator\n",
        "from lrdbenchmark.analysis.spectral.gph.gph_estimator_unified import GPHEstimator\n",
        "from lrdbenchmark.analysis.spectral.whittle.whittle_estimator_unified import WhittleEstimator\n",
        "from lrdbenchmark.analysis.machine_learning.random_forest_estimator_unified import RandomForestEstimator\n",
        "from lrdbenchmark.analysis.machine_learning.svr_estimator_unified import SVREstimator\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(\"üèÜ Ready to generate performance leaderboards\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loading Benchmark Results {#loading}\n",
        "\n",
        "Let's run comprehensive benchmarks to generate data for our leaderboard, then load and process the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Initializing Benchmark System for Leaderboard Generation...\n",
            "======================================================================\n",
            "‚ö†Ô∏è CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "‚ö†Ô∏è CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "\n",
            "üöÄ Running Comprehensive Benchmarks...\n",
            "======================================================================\n",
            "üìä Running Classical Estimator Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: CLASSICAL\n",
            "============================================================\n",
            "Testing 13 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W1015 09:52:16.360471  123379 platform_util.cc:218] unable to create StreamExecutor for CUDA:0: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚ùå Error with fBm: Unable to initialize backend 'cuda': INTERNAL: no supported devices found for platform CUDA (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_095306.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_095306.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: CLASSICAL\n",
            "Total Tests: 39\n",
            "Successful: 39\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 13\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. Whittle\n",
            "      Avg Error: 0.1333 (Range: 0.0000-0.4000)\n",
            "      Avg Time: 0.000s | Data Models: 3\n",
            "      Mean Signed Error: 0.1333\n",
            "      Bias: 44.44%\n",
            "      Stability: 0.0000\n",
            "      Estimated H values:\n",
            "        fGn: H_est=0.7000, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7000, H_true=0.3000\n",
            "        MRW: H_est=0.7000, H_true=0.7000\n",
            "\n",
            "   2. Periodogram\n",
            "      Avg Error: 0.1689 (Range: 0.0618-0.3676)\n",
            "      Avg Time: 0.001s | Data Models: 3\n",
            "      Convergence Rate: -0.1431\n",
            "      Mean Signed Error: 0.1173\n",
            "      Bias: 40.10%\n",
            "      Stability: 0.3041\n",
            "      Estimated H values:\n",
            "        fGn: H_est=0.7618, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.6676, H_true=0.3000\n",
            "        MRW: H_est=0.6226, H_true=0.7000\n",
            "\n",
            "   3. DMA\n",
            "      Avg Error: 0.1877 (Range: 0.0479-0.4514)\n",
            "      Avg Time: 0.001s | Data Models: 3\n",
            "      Convergence Rate: -0.3538\n",
            "      Mean Signed Error: 0.1557\n",
            "      Bias: 50.91%\n",
            "      Stability: 0.1730\n",
            "      Estimated H values:\n",
            "        fGn: H_est=0.7639, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7514, H_true=0.3000\n",
            "        MRW: H_est=0.6521, H_true=0.7000\n",
            "\n",
            "   4. Higuchi\n",
            "      Avg Error: 0.2067 (Range: 0.0373-0.4902)\n",
            "      Avg Time: 0.002s | Data Models: 3\n",
            "      Convergence Rate: -0.7641\n",
            "      Mean Signed Error: 0.2067\n",
            "      Bias: 60.65%\n",
            "      Stability: 0.1227\n",
            "      Estimated H values:\n",
            "        fGn: H_est=0.7927, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7902, H_true=0.3000\n",
            "        MRW: H_est=0.7373, H_true=0.7000\n",
            "\n",
            "   5. R/S\n",
            "      Avg Error: 0.2096 (Range: 0.0062-0.4919)\n",
            "      Avg Time: 0.608s | Data Models: 3\n",
            "      Convergence Rate: -0.5908\n",
            "      Mean Signed Error: 0.2096\n",
            "      Bias: 61.17%\n",
            "      Stability: 0.0698\n",
            "      Estimated H values:\n",
            "        fGn: H_est=0.8305, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7919, H_true=0.3000\n",
            "        MRW: H_est=0.7062, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fGn:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. Periodogram: Error 0.0618, Time 0.001s\n",
            "     3. DMA: Error 0.0639, Time 0.001s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. WaveletLeaders: Error 0.0535, Time 0.013s\n",
            "     2. MFDFA: Error 0.0817, Time 0.104s\n",
            "     3. DFA: Error 0.1342, Time 0.007s\n",
            "\n",
            "   MRW:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. R/S: Error 0.0062, Time 0.027s\n",
            "     3. Higuchi: Error 0.0373, Time 0.002s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ Classical benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 39\n",
            "\n",
            "üìä Running ML Estimator Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: ML\n",
            "============================================================\n",
            "Testing 3 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_095307.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_095307.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: ML\n",
            "Total Tests: 12\n",
            "Successful: 12\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 3\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. SVR\n",
            "      Avg Error: 0.1364 (Range: 0.0147-0.4680)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.0130\n",
            "      Mean Signed Error: 0.1291\n",
            "      Bias: 40.73%\n",
            "      Stability: 0.0114\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7387, H_true=0.7000\n",
            "        fGn: H_est=0.7244, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7680, H_true=0.3000\n",
            "        MRW: H_est=0.6853, H_true=0.7000\n",
            "\n",
            "   2. GradientBoosting\n",
            "      Avg Error: 0.4307 (Range: 0.1471-0.5783)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.7917\n",
            "      Mean Signed Error: -0.4307\n",
            "      Bias: -68.53%\n",
            "      Stability: 0.1323\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.1422, H_true=0.7000\n",
            "        fGn: H_est=0.1217, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.1529, H_true=0.3000\n",
            "        MRW: H_est=0.2604, H_true=0.7000\n",
            "\n",
            "   3. RandomForest\n",
            "      Avg Error: 0.5000 (Range: 0.2000-0.6000)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.3469\n",
            "      Mean Signed Error: -0.5000\n",
            "      Bias: -80.95%\n",
            "      Stability: 0.1436\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.1000, H_true=0.7000\n",
            "        fGn: H_est=0.1000, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.1000, H_true=0.3000\n",
            "        MRW: H_est=0.1000, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fBm:\n",
            "     1. SVR: Error 0.0387, Time 0.000s\n",
            "     2. GradientBoosting: Error 0.5578, Time 0.000s\n",
            "     3. RandomForest: Error 0.6000, Time 0.001s\n",
            "\n",
            "   fGn:\n",
            "     1. SVR: Error 0.0244, Time 0.000s\n",
            "     2. GradientBoosting: Error 0.5783, Time 0.000s\n",
            "     3. RandomForest: Error 0.6000, Time 0.000s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. GradientBoosting: Error 0.1471, Time 0.000s\n",
            "     2. RandomForest: Error 0.2000, Time 0.000s\n",
            "     3. SVR: Error 0.4680, Time 0.000s\n",
            "\n",
            "   MRW:\n",
            "     1. SVR: Error 0.0147, Time 0.000s\n",
            "     2. GradientBoosting: Error 0.4396, Time 0.000s\n",
            "     3. RandomForest: Error 0.6000, Time 0.000s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ ML benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 12\n",
            "\n",
            "üìä Running Neural Network Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: NEURAL\n",
            "============================================================\n",
            "Testing 4 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... ‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... ‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... ‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... ‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_095418.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_095418.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: NEURAL\n",
            "Total Tests: 16\n",
            "Successful: 16\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 4\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. LSTM\n",
            "      Avg Error: 0.1707 (Range: 0.0792-0.3709)\n",
            "      Avg Time: 0.156s | Data Models: 4\n",
            "      Convergence Rate: -0.0667\n",
            "      Mean Signed Error: 0.0147\n",
            "      Bias: 19.76%\n",
            "      Stability: 0.0233\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.6208, H_true=0.7000\n",
            "        fGn: H_est=0.5939, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.6709, H_true=0.3000\n",
            "        MRW: H_est=0.5733, H_true=0.7000\n",
            "\n",
            "   2. Transformer\n",
            "      Avg Error: 0.1827 (Range: 0.1624-0.2373)\n",
            "      Avg Time: 0.002s | Data Models: 4\n",
            "      Convergence Rate: 0.7066\n",
            "      Mean Signed Error: -0.0641\n",
            "      Bias: 2.15%\n",
            "      Stability: 0.0016\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.5335, H_true=0.7000\n",
            "        fGn: H_est=0.5376, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.5373, H_true=0.3000\n",
            "        MRW: H_est=0.5354, H_true=0.7000\n",
            "\n",
            "   3. GRU\n",
            "      Avg Error: 0.1872 (Range: 0.1471-0.2820)\n",
            "      Avg Time: 0.144s | Data Models: 4\n",
            "      Convergence Rate: -0.2028\n",
            "      Mean Signed Error: -0.0462\n",
            "      Bias: 6.82%\n",
            "      Stability: 0.0127\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.5529, H_true=0.7000\n",
            "        fGn: H_est=0.5403, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.5820, H_true=0.3000\n",
            "        MRW: H_est=0.5399, H_true=0.7000\n",
            "\n",
            "   4. CNN\n",
            "      Avg Error: 0.1950 (Range: 0.1896-0.2069)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.2132\n",
            "      Mean Signed Error: -0.0915\n",
            "      Bias: -3.22%\n",
            "      Stability: 0.0031\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.5104, H_true=0.7000\n",
            "        fGn: H_est=0.5091, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.5069, H_true=0.3000\n",
            "        MRW: H_est=0.5075, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fBm:\n",
            "     1. LSTM: Error 0.0792, Time 0.165s\n",
            "     2. GRU: Error 0.1471, Time 0.144s\n",
            "     3. Transformer: Error 0.1665, Time 0.003s\n",
            "\n",
            "   fGn:\n",
            "     1. LSTM: Error 0.1061, Time 0.153s\n",
            "     2. GRU: Error 0.1597, Time 0.150s\n",
            "     3. Transformer: Error 0.1624, Time 0.002s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. CNN: Error 0.2069, Time 0.000s\n",
            "     2. Transformer: Error 0.2373, Time 0.002s\n",
            "     3. GRU: Error 0.2820, Time 0.140s\n",
            "\n",
            "   MRW:\n",
            "     1. LSTM: Error 0.1267, Time 0.152s\n",
            "     2. GRU: Error 0.1601, Time 0.140s\n",
            "     3. Transformer: Error 0.1646, Time 0.002s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ Neural benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 16\n",
            "\n",
            "üìä Running Comprehensive Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: COMPREHENSIVE\n",
            "============================================================\n",
            "Testing 20 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... ‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... ‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... ‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing LSTM... ‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ Found LSTM pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing GRU... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ Found GRU pretrained model configuration\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found GRU pretrained model configuration\n",
            "‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_095624.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_095624.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: COMPREHENSIVE\n",
            "Total Tests: 80\n",
            "Successful: 80\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 20\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. Whittle\n",
            "      Avg Error: 0.1000 (Range: 0.0000-0.4000)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Mean Signed Error: 0.1000\n",
            "      Bias: 33.33%\n",
            "      Stability: 0.0000\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7000, H_true=0.7000\n",
            "        fGn: H_est=0.7000, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7000, H_true=0.3000\n",
            "        MRW: H_est=0.7000, H_true=0.7000\n",
            "\n",
            "   2. Periodogram\n",
            "      Avg Error: 0.1287 (Range: 0.0080-0.3676)\n",
            "      Avg Time: 0.001s | Data Models: 4\n",
            "      Convergence Rate: -0.2206\n",
            "      Mean Signed Error: 0.0899\n",
            "      Bias: 30.35%\n",
            "      Stability: 0.2886\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7080, H_true=0.7000\n",
            "        fGn: H_est=0.7618, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.6676, H_true=0.3000\n",
            "        MRW: H_est=0.6226, H_true=0.7000\n",
            "\n",
            "   3. SVR\n",
            "      Avg Error: 0.1364 (Range: 0.0147-0.4680)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.0130\n",
            "      Mean Signed Error: 0.1291\n",
            "      Bias: 40.73%\n",
            "      Stability: 0.0114\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7387, H_true=0.7000\n",
            "        fGn: H_est=0.7244, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7680, H_true=0.3000\n",
            "        MRW: H_est=0.6853, H_true=0.7000\n",
            "\n",
            "   4. LSTM\n",
            "      Avg Error: 0.1707 (Range: 0.0792-0.3709)\n",
            "      Avg Time: 0.172s | Data Models: 4\n",
            "      Convergence Rate: -0.0667\n",
            "      Mean Signed Error: 0.0147\n",
            "      Bias: 19.76%\n",
            "      Stability: 0.0233\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.6208, H_true=0.7000\n",
            "        fGn: H_est=0.5939, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.6709, H_true=0.3000\n",
            "        MRW: H_est=0.5733, H_true=0.7000\n",
            "\n",
            "   5. R/S\n",
            "      Avg Error: 0.1776 (Range: 0.0062-0.4919)\n",
            "      Avg Time: 0.028s | Data Models: 4\n",
            "      Convergence Rate: -0.3697\n",
            "      Mean Signed Error: 0.1776\n",
            "      Bias: 48.80%\n",
            "      Stability: 0.0638\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7817, H_true=0.7000\n",
            "        fGn: H_est=0.8305, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7919, H_true=0.3000\n",
            "        MRW: H_est=0.7062, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fBm:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. Periodogram: Error 0.0080, Time 0.001s\n",
            "     3. SVR: Error 0.0387, Time 0.000s\n",
            "\n",
            "   fGn:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. SVR: Error 0.0244, Time 0.000s\n",
            "     3. Periodogram: Error 0.0618, Time 0.001s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. WaveletLeaders: Error 0.0535, Time 0.012s\n",
            "     2. MFDFA: Error 0.0817, Time 0.110s\n",
            "     3. DFA: Error 0.1342, Time 0.006s\n",
            "\n",
            "   MRW:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. R/S: Error 0.0062, Time 0.027s\n",
            "     3. SVR: Error 0.0147, Time 0.000s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ Comprehensive benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 80\n",
            "\n",
            "üéØ All benchmarks completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize benchmark system\n",
        "print(\"üîß Initializing Benchmark System for Leaderboard Generation...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "benchmark = ComprehensiveBenchmark(output_dir=\"leaderboard_results\")\n",
        "\n",
        "# Run comprehensive benchmarks\n",
        "print(\"\\nüöÄ Running Comprehensive Benchmarks...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Run classical benchmark\n",
        "print(\"üìä Running Classical Estimator Benchmark...\")\n",
        "classical_results = benchmark.run_classical_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Classical benchmark completed!\")\n",
        "print(f\"Success rate: {classical_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {classical_results['total_tests']}\")\n",
        "\n",
        "# Run ML benchmark\n",
        "print(\"\\nüìä Running ML Estimator Benchmark...\")\n",
        "ml_results = benchmark.run_ml_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ ML benchmark completed!\")\n",
        "print(f\"Success rate: {ml_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {ml_results['total_tests']}\")\n",
        "\n",
        "# Run neural benchmark\n",
        "print(\"\\nüìä Running Neural Network Benchmark...\")\n",
        "neural_results = benchmark.run_neural_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Neural benchmark completed!\")\n",
        "print(f\"Success rate: {neural_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {neural_results['total_tests']}\")\n",
        "\n",
        "# Run comprehensive benchmark\n",
        "print(\"\\nüìä Running Comprehensive Benchmark...\")\n",
        "comprehensive_results = benchmark.run_comprehensive_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Comprehensive benchmark completed!\")\n",
        "print(f\"Success rate: {comprehensive_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {comprehensive_results['total_tests']}\")\n",
        "\n",
        "print(\"\\nüéØ All benchmarks completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Creating Performance Rankings {#rankings}\n",
        "\n",
        "Now let's create comprehensive performance rankings and leaderboards from our benchmark results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÜ Creating Performance Leaderboard...\n",
            "======================================================================\n",
            "üîç Processing Classical results...\n",
            "   Keys: ['timestamp', 'benchmark_type', 'contamination_type', 'contamination_level', 'total_tests', 'successful_tests', 'success_rate', 'data_models_tested', 'estimators_tested', 'results']\n",
            "   Found 'results' key with 4 entries\n",
            "üîç Processing ML results...\n",
            "   Keys: ['timestamp', 'benchmark_type', 'contamination_type', 'contamination_level', 'total_tests', 'successful_tests', 'success_rate', 'data_models_tested', 'estimators_tested', 'results']\n",
            "   Found 'results' key with 4 entries\n",
            "üîç Processing Neural results...\n",
            "   Keys: ['timestamp', 'benchmark_type', 'contamination_type', 'contamination_level', 'total_tests', 'successful_tests', 'success_rate', 'data_models_tested', 'estimators_tested', 'results']\n",
            "   Found 'results' key with 4 entries\n",
            "üîç Processing Comprehensive results...\n",
            "   Keys: ['timestamp', 'benchmark_type', 'contamination_type', 'contamination_level', 'total_tests', 'successful_tests', 'success_rate', 'data_models_tested', 'estimators_tested', 'results']\n",
            "   Found 'results' key with 4 entries\n",
            "\n",
            "üìä Total performance records collected: 147\n",
            "üìä Loaded 147 performance records\n",
            "\n",
            "üìà Performance Metrics Summary:\n",
            "                                 Error                         Execution_Time  \\\n",
            "                                  mean     std     min     max           mean   \n",
            "Category      Estimator                                                         \n",
            "Classical     CWT               0.3963  0.4862  0.0972  0.9573         0.0790   \n",
            "              DFA               0.4018  0.2372  0.1342  0.5863         0.0066   \n",
            "              DMA               0.1877  0.2285  0.0479  0.4514         0.0009   \n",
            "              GPH               0.2669  0.2276  0.0721  0.5171         0.0976   \n",
            "              Higuchi           0.2067  0.2470  0.0373  0.4902         0.0023   \n",
            "              MFDFA             0.3642  0.2447  0.0817  0.5117         0.1112   \n",
            "              Periodogram       0.1689  0.1722  0.0618  0.3676         0.0008   \n",
            "              R/S               0.2096  0.2523  0.0062  0.4919         0.6085   \n",
            "              WaveletLeaders    0.4408  0.3361  0.0535  0.6569         0.0146   \n",
            "              WaveletLogVar     0.4280  0.4077  0.1012  0.8849         0.0004   \n",
            "              WaveletVar        0.6470  0.4896  0.2345  1.1881         0.0009   \n",
            "              WaveletWhittle    0.5567  0.2309  0.2900  0.6900         0.0070   \n",
            "              Whittle           0.1333  0.2309  0.0000  0.4000         0.0004   \n",
            "Comprehensive CNN               0.1950  0.0080  0.1896  0.2069         0.0006   \n",
            "              CWT               0.3242  0.4224  0.0972  0.9573         0.0715   \n",
            "              DFA               0.4467  0.2135  0.1342  0.5863         0.0065   \n",
            "              DMA               0.1829  0.1868  0.0479  0.4514         0.0009   \n",
            "              GPH               0.2396  0.1937  0.0721  0.5171         0.0012   \n",
            "              GRU               0.1872  0.0635  0.1471  0.2820         0.1529   \n",
            "              GradientBoosting  0.4307  0.1987  0.1471  0.5783         0.0002   \n",
            "              Higuchi           0.1819  0.2078  0.0373  0.4902         0.0023   \n",
            "              LSTM              0.1707  0.1348  0.0792  0.3709         0.1717   \n",
            "              MFDFA             0.3699  0.1944  0.0817  0.4991         0.1075   \n",
            "              Periodogram       0.1287  0.1620  0.0080  0.3676         0.0009   \n",
            "              R/S               0.1776  0.2157  0.0062  0.4919         0.0281   \n",
            "              RandomForest      0.5000  0.2000  0.2000  0.6000         0.0005   \n",
            "              SVR               0.1364  0.2212  0.0147  0.4680         0.0000   \n",
            "              Transformer       0.1827  0.0364  0.1624  0.2373         0.0020   \n",
            "              WaveletLeaders    0.4397  0.2714  0.0535  0.6569         0.0127   \n",
            "              WaveletLogVar     0.3880  0.3424  0.1012  0.8849         0.0004   \n",
            "              WaveletVar        0.6040  0.4089  0.2345  1.1881         0.0009   \n",
            "              WaveletWhittle    0.5900  0.2000  0.2900  0.6900         0.0071   \n",
            "              Whittle           0.1000  0.2000  0.0000  0.4000         0.0003   \n",
            "ML            GradientBoosting  0.4307  0.1987  0.1471  0.5783         0.0002   \n",
            "              RandomForest      0.5000  0.2000  0.2000  0.6000         0.0002   \n",
            "              SVR               0.1364  0.2212  0.0147  0.4680         0.0000   \n",
            "Neural        CNN               0.1950  0.0080  0.1896  0.2069         0.0005   \n",
            "              GRU               0.1872  0.0635  0.1471  0.2820         0.1437   \n",
            "              LSTM              0.1707  0.1348  0.0792  0.3709         0.1557   \n",
            "              Transformer       0.1827  0.0364  0.1624  0.2373         0.0021   \n",
            "\n",
            "                                       True_H  \n",
            "                                   std  count  \n",
            "Category      Estimator                        \n",
            "Classical     CWT               0.0017      3  \n",
            "              DFA               0.0002      3  \n",
            "              DMA               0.0002      3  \n",
            "              GPH               0.1672      3  \n",
            "              Higuchi           0.0001      3  \n",
            "              MFDFA             0.0107      3  \n",
            "              Periodogram       0.0001      3  \n",
            "              R/S               1.0087      3  \n",
            "              WaveletLeaders    0.0031      3  \n",
            "              WaveletLogVar     0.0000      3  \n",
            "              WaveletVar        0.0002      3  \n",
            "              WaveletWhittle    0.0000      3  \n",
            "              Whittle           0.0001      3  \n",
            "Comprehensive CNN               0.0000      4  \n",
            "              CWT               0.0119      4  \n",
            "              DFA               0.0001      4  \n",
            "              DMA               0.0002      4  \n",
            "              GPH               0.0002      4  \n",
            "              GRU               0.0124      4  \n",
            "              GradientBoosting  0.0000      4  \n",
            "              Higuchi           0.0001      4  \n",
            "              LSTM              0.0067      4  \n",
            "              MFDFA             0.0023      4  \n",
            "              Periodogram       0.0001      4  \n",
            "              R/S               0.0010      4  \n",
            "              RandomForest      0.0002      4  \n",
            "              SVR               0.0000      4  \n",
            "              Transformer       0.0002      4  \n",
            "              WaveletLeaders    0.0003      4  \n",
            "              WaveletLogVar     0.0000      4  \n",
            "              WaveletVar        0.0001      4  \n",
            "              WaveletWhittle    0.0002      4  \n",
            "              Whittle           0.0000      4  \n",
            "ML            GradientBoosting  0.0000      4  \n",
            "              RandomForest      0.0002      4  \n",
            "              SVR               0.0000      4  \n",
            "Neural        CNN               0.0002      4  \n",
            "              GRU               0.0048      4  \n",
            "              LSTM              0.0063      4  \n",
            "              Transformer       0.0004      4  \n",
            "\n",
            "üèÜ Overall Performance Leaderboard:\n",
            "======================================================================\n",
            "         Category         Estimator  Mean_Error  Std_Error  Mean_Time  Count  \\\n",
            "32  Comprehensive           Whittle      0.1000     0.2000     0.0003      4   \n",
            "23  Comprehensive       Periodogram      0.1287     0.1620     0.0009      4   \n",
            "26  Comprehensive               SVR      0.1364     0.2212     0.0000      4   \n",
            "35             ML               SVR      0.1364     0.2212     0.0000      4   \n",
            "16  Comprehensive               DMA      0.1829     0.1868     0.0009      4   \n",
            "20  Comprehensive           Higuchi      0.1819     0.2078     0.0023      4   \n",
            "27  Comprehensive       Transformer      0.1827     0.0364     0.0020      4   \n",
            "39         Neural       Transformer      0.1827     0.0364     0.0021      4   \n",
            "36         Neural               CNN      0.1950     0.0080     0.0005      4   \n",
            "13  Comprehensive               CNN      0.1950     0.0080     0.0006      4   \n",
            "24  Comprehensive               R/S      0.1776     0.2157     0.0281      4   \n",
            "17  Comprehensive               GPH      0.2396     0.1937     0.0012      4   \n",
            "38         Neural              LSTM      0.1707     0.1348     0.1557      4   \n",
            "37         Neural               GRU      0.1872     0.0635     0.1437      4   \n",
            "18  Comprehensive               GRU      0.1872     0.0635     0.1529      4   \n",
            "21  Comprehensive              LSTM      0.1707     0.1348     0.1717      4   \n",
            "29  Comprehensive     WaveletLogVar      0.3880     0.3424     0.0004      4   \n",
            "14  Comprehensive               CWT      0.3242     0.4224     0.0715      4   \n",
            "19  Comprehensive  GradientBoosting      0.4307     0.1987     0.0002      4   \n",
            "33             ML  GradientBoosting      0.4307     0.1987     0.0002      4   \n",
            "15  Comprehensive               DFA      0.4467     0.2135     0.0065      4   \n",
            "28  Comprehensive    WaveletLeaders      0.4397     0.2714     0.0127      4   \n",
            "34             ML      RandomForest      0.5000     0.2000     0.0002      4   \n",
            "25  Comprehensive      RandomForest      0.5000     0.2000     0.0005      4   \n",
            "12      Classical           Whittle      0.1333     0.2309     0.0004      3   \n",
            "22  Comprehensive             MFDFA      0.3699     0.1944     0.1075      4   \n",
            "6       Classical       Periodogram      0.1689     0.1722     0.0008      3   \n",
            "2       Classical               DMA      0.1877     0.2285     0.0009      3   \n",
            "31  Comprehensive    WaveletWhittle      0.5900     0.2000     0.0071      4   \n",
            "30  Comprehensive        WaveletVar      0.6040     0.4089     0.0009      4   \n",
            "4       Classical           Higuchi      0.2067     0.2470     0.0023      3   \n",
            "3       Classical               GPH      0.2669     0.2276     0.0976      3   \n",
            "1       Classical               DFA      0.4018     0.2372     0.0066      3   \n",
            "9       Classical     WaveletLogVar      0.4280     0.4077     0.0004      3   \n",
            "8       Classical    WaveletLeaders      0.4408     0.3361     0.0146      3   \n",
            "0       Classical               CWT      0.3963     0.4862     0.0790      3   \n",
            "5       Classical             MFDFA      0.3642     0.2447     0.1112      3   \n",
            "11      Classical    WaveletWhittle      0.5567     0.2309     0.0070      3   \n",
            "10      Classical        WaveletVar      0.6470     0.4896     0.0009      3   \n",
            "7       Classical               R/S      0.2096     0.2523     0.6085      3   \n",
            "\n",
            "    Composite_Score  \n",
            "32           0.3635  \n",
            "23           0.3541  \n",
            "26           0.3520  \n",
            "35           0.3520  \n",
            "16           0.3379  \n",
            "20           0.3377  \n",
            "27           0.3375  \n",
            "39           0.3375  \n",
            "36           0.3346  \n",
            "13           0.3345  \n",
            "24           0.3304  \n",
            "17           0.3223  \n",
            "38           0.2957  \n",
            "37           0.2946  \n",
            "18           0.2922  \n",
            "21           0.2916  \n",
            "29           0.2881  \n",
            "14           0.2819  \n",
            "19           0.2795  \n",
            "33           0.2795  \n",
            "15           0.2747  \n",
            "28           0.2744  \n",
            "34           0.2666  \n",
            "25           0.2665  \n",
            "12           0.2646  \n",
            "22           0.2637  \n",
            "6            0.2565  \n",
            "2            0.2524  \n",
            "31           0.2498  \n",
            "30           0.2491  \n",
            "4            0.2480  \n",
            "3            0.2157  \n",
            "1            0.2126  \n",
            "9            0.2100  \n",
            "8            0.2052  \n",
            "0            0.1991  \n",
            "5            0.1979  \n",
            "11           0.1914  \n",
            "10           0.1820  \n",
            "7            0.1542  \n",
            "\n",
            "üíæ Leaderboard saved to outputs/performance_leaderboard.csv\n"
          ]
        }
      ],
      "source": [
        "# Create comprehensive leaderboard\n",
        "print(\"üèÜ Creating Performance Leaderboard...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Combine all benchmark results\n",
        "all_results = {\n",
        "    'Classical': classical_results,\n",
        "    'ML': ml_results,\n",
        "    'Neural': neural_results,\n",
        "    'Comprehensive': comprehensive_results\n",
        "}\n",
        "\n",
        "# Create performance summary\n",
        "performance_data = []\n",
        "\n",
        "for category, results in all_results.items():\n",
        "    print(f\"üîç Processing {category} results...\")\n",
        "    print(f\"   Keys: {list(results.keys())}\")\n",
        "    \n",
        "    # Check if results have the expected structure\n",
        "    if 'results' in results and isinstance(results['results'], dict):\n",
        "        print(f\"   Found 'results' key with {len(results['results'])} entries\")\n",
        "        \n",
        "        # Process the results data\n",
        "        for data_model, model_results in results['results'].items():\n",
        "            if isinstance(model_results, dict) and 'estimator_results' in model_results:\n",
        "                for estimator_result in model_results['estimator_results']:\n",
        "                    if estimator_result.get('success', True):  # Default to True if success not specified\n",
        "                        performance_data.append({\n",
        "                            'Category': category,\n",
        "                            'Estimator': estimator_result['estimator'],\n",
        "                            'True_H': estimator_result['true_hurst'],\n",
        "                            'Estimated_H': estimator_result['estimated_hurst'],\n",
        "                            'Error': estimator_result['error'],\n",
        "                            'Execution_Time': estimator_result['execution_time'],\n",
        "                            'Data_Model': data_model\n",
        "                        })\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è Unexpected results structure for {category}\")\n",
        "        print(f\"   Available keys: {list(results.keys())}\")\n",
        "\n",
        "print(f\"\\nüìä Total performance records collected: {len(performance_data)}\")\n",
        "\n",
        "# Create DataFrame\n",
        "performance_df = pd.DataFrame(performance_data)\n",
        "\n",
        "if len(performance_df) > 0:\n",
        "    print(f\"üìä Loaded {len(performance_df)} performance records\")\n",
        "    \n",
        "    # Calculate performance metrics\n",
        "    performance_metrics = performance_df.groupby(['Category', 'Estimator']).agg({\n",
        "        'Error': ['mean', 'std', 'min', 'max'],\n",
        "        'Execution_Time': ['mean', 'std'],\n",
        "        'True_H': 'count'\n",
        "    }).round(4)\n",
        "    \n",
        "    print(\"\\nüìà Performance Metrics Summary:\")\n",
        "    print(performance_metrics)\n",
        "    \n",
        "    # Create overall leaderboard\n",
        "    print(\"\\nüèÜ Overall Performance Leaderboard:\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Calculate composite scores\n",
        "    leaderboard_data = []\n",
        "    \n",
        "    for (category, estimator), group in performance_df.groupby(['Category', 'Estimator']):\n",
        "        mean_error = group['Error'].mean()\n",
        "        std_error = group['Error'].std()\n",
        "        mean_time = group['Execution_Time'].mean()\n",
        "        count = len(group)\n",
        "        \n",
        "        # Composite score (lower is better for error, higher is better for count)\n",
        "        composite_score = (1 / (1 + mean_error)) * (count / 10) * (1 / (1 + mean_time))\n",
        "        \n",
        "        leaderboard_data.append({\n",
        "            'Category': category,\n",
        "            'Estimator': estimator,\n",
        "            'Mean_Error': mean_error,\n",
        "            'Std_Error': std_error,\n",
        "            'Mean_Time': mean_time,\n",
        "            'Count': count,\n",
        "            'Composite_Score': composite_score\n",
        "        })\n",
        "    \n",
        "    leaderboard_df = pd.DataFrame(leaderboard_data)\n",
        "    leaderboard_df = leaderboard_df.sort_values('Composite_Score', ascending=False)\n",
        "    \n",
        "    print(leaderboard_df.round(4))\n",
        "    \n",
        "    # Save leaderboard\n",
        "    leaderboard_df.to_csv('outputs/performance_leaderboard.csv', index=False)\n",
        "    print(\"\\nüíæ Leaderboard saved to outputs/performance_leaderboard.csv\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No performance data available for leaderboard generation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization and Export {#visualization}\n",
        "\n",
        "Let's create comprehensive visualizations of our leaderboard results and export them in various formats.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Creating Performance Visualizations...\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1200 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Category-Specific Leaderboards:\n",
            "======================================================================\n",
            "\n",
            "Classical Category Leaderboard:\n",
            "                 Error         Execution_Time True_H\n",
            "                  mean     std           mean  count\n",
            "Estimator                                           \n",
            "CWT             0.3963  0.4862         0.0790      3\n",
            "DFA             0.4018  0.2372         0.0066      3\n",
            "DMA             0.1877  0.2285         0.0009      3\n",
            "GPH             0.2669  0.2276         0.0976      3\n",
            "Higuchi         0.2067  0.2470         0.0023      3\n",
            "MFDFA           0.3642  0.2447         0.1112      3\n",
            "Periodogram     0.1689  0.1722         0.0008      3\n",
            "R/S             0.2096  0.2523         0.6085      3\n",
            "WaveletLeaders  0.4408  0.3361         0.0146      3\n",
            "WaveletLogVar   0.4280  0.4077         0.0004      3\n",
            "WaveletVar      0.6470  0.4896         0.0009      3\n",
            "WaveletWhittle  0.5567  0.2309         0.0070      3\n",
            "Whittle         0.1333  0.2309         0.0004      3\n",
            "\n",
            "ML Category Leaderboard:\n",
            "                   Error         Execution_Time True_H\n",
            "                    mean     std           mean  count\n",
            "Estimator                                             \n",
            "GradientBoosting  0.4307  0.1987         0.0002      4\n",
            "RandomForest      0.5000  0.2000         0.0002      4\n",
            "SVR               0.1364  0.2212         0.0000      4\n",
            "\n",
            "Neural Category Leaderboard:\n",
            "              Error         Execution_Time True_H\n",
            "               mean     std           mean  count\n",
            "Estimator                                        \n",
            "CNN          0.1950  0.0080         0.0005      4\n",
            "GRU          0.1872  0.0635         0.1437      4\n",
            "LSTM         0.1707  0.1348         0.1557      4\n",
            "Transformer  0.1827  0.0364         0.0021      4\n",
            "\n",
            "Comprehensive Category Leaderboard:\n",
            "                   Error         Execution_Time True_H\n",
            "                    mean     std           mean  count\n",
            "Estimator                                             \n",
            "CNN               0.1950  0.0080         0.0006      4\n",
            "CWT               0.3242  0.4224         0.0715      4\n",
            "DFA               0.4467  0.2135         0.0065      4\n",
            "DMA               0.1829  0.1868         0.0009      4\n",
            "GPH               0.2396  0.1937         0.0012      4\n",
            "GRU               0.1872  0.0635         0.1529      4\n",
            "GradientBoosting  0.4307  0.1987         0.0002      4\n",
            "Higuchi           0.1819  0.2078         0.0023      4\n",
            "LSTM              0.1707  0.1348         0.1717      4\n",
            "MFDFA             0.3699  0.1944         0.1075      4\n",
            "Periodogram       0.1287  0.1620         0.0009      4\n",
            "R/S               0.1776  0.2157         0.0281      4\n",
            "RandomForest      0.5000  0.2000         0.0005      4\n",
            "SVR               0.1364  0.2212         0.0000      4\n",
            "Transformer       0.1827  0.0364         0.0020      4\n",
            "WaveletLeaders    0.4397  0.2714         0.0127      4\n",
            "WaveletLogVar     0.3880  0.3424         0.0004      4\n",
            "WaveletVar        0.6040  0.4089         0.0009      4\n",
            "WaveletWhittle    0.5900  0.2000         0.0071      4\n",
            "Whittle           0.1000  0.2000         0.0003      4\n",
            "\n",
            "üíæ Exporting Results...\n",
            "======================================================================\n",
            "‚úÖ Performance data exported to CSV\n",
            "‚úÖ Performance data exported to JSON\n",
            "‚úÖ Leaderboard table exported to LaTeX\n",
            "\n",
            "üéØ All visualizations and exports completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create comprehensive visualizations\n",
        "if len(performance_df) > 0:\n",
        "    print(\"üìä Creating Performance Visualizations...\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "    \n",
        "    # 1. Error distribution by category\n",
        "    ax1 = axes[0, 0]\n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]['Error']\n",
        "        ax1.hist(category_data, alpha=0.7, label=category, bins=15)\n",
        "    ax1.set_xlabel('Absolute Error')\n",
        "    ax1.set_ylabel('Frequency')\n",
        "    ax1.set_title('Error Distribution by Category')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Execution time by category\n",
        "    ax2 = axes[0, 1]\n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]['Execution_Time']\n",
        "        ax2.hist(category_data, alpha=0.7, label=category, bins=15)\n",
        "    ax2.set_xlabel('Execution Time (seconds)')\n",
        "    ax2.set_ylabel('Frequency')\n",
        "    ax2.set_title('Execution Time Distribution by Category')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Error vs True H\n",
        "    ax3 = axes[0, 2]\n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]\n",
        "        ax3.scatter(category_data['True_H'], category_data['Error'], \n",
        "                   alpha=0.7, label=category, s=50)\n",
        "    ax3.set_xlabel('True Hurst Parameter')\n",
        "    ax3.set_ylabel('Absolute Error')\n",
        "    ax3.set_title('Error vs True Hurst Parameter')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Performance by estimator\n",
        "    ax4 = axes[1, 0]\n",
        "    estimator_performance = performance_df.groupby('Estimator')['Error'].mean().sort_values()\n",
        "    ax4.bar(range(len(estimator_performance)), estimator_performance.values, alpha=0.7)\n",
        "    ax4.set_xlabel('Estimator')\n",
        "    ax4.set_ylabel('Mean Absolute Error')\n",
        "    ax4.set_title('Mean Error by Estimator')\n",
        "    ax4.set_xticks(range(len(estimator_performance)))\n",
        "    ax4.set_xticklabels(estimator_performance.index, rotation=45, ha='right')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 5. Execution time by estimator\n",
        "    ax5 = axes[1, 1]\n",
        "    time_performance = performance_df.groupby('Estimator')['Execution_Time'].mean().sort_values()\n",
        "    ax5.bar(range(len(time_performance)), time_performance.values, alpha=0.7)\n",
        "    ax5.set_xlabel('Estimator')\n",
        "    ax5.set_ylabel('Mean Execution Time (seconds)')\n",
        "    ax5.set_title('Mean Execution Time by Estimator')\n",
        "    ax5.set_xticks(range(len(time_performance)))\n",
        "    ax5.set_xticklabels(time_performance.index, rotation=45, ha='right')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Composite score ranking\n",
        "    ax6 = axes[1, 2]\n",
        "    if len(leaderboard_df) > 0:\n",
        "        top_10 = leaderboard_df.head(10)\n",
        "        ax6.barh(range(len(top_10)), top_10['Composite_Score'], alpha=0.7)\n",
        "        ax6.set_xlabel('Composite Score')\n",
        "        ax6.set_ylabel('Rank')\n",
        "        ax6.set_title('Top 10 Estimators by Composite Score')\n",
        "        ax6.set_yticks(range(len(top_10)))\n",
        "        ax6.set_yticklabels([f\"{row['Category']} - {row['Estimator']}\" for _, row in top_10.iterrows()])\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/leaderboard_visualization.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Create category-specific leaderboards\n",
        "    print(\"\\nüìä Category-Specific Leaderboards:\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]\n",
        "        category_leaderboard = category_data.groupby('Estimator').agg({\n",
        "            'Error': ['mean', 'std'],\n",
        "            'Execution_Time': 'mean',\n",
        "            'True_H': 'count'\n",
        "        }).round(4)\n",
        "        \n",
        "        print(f\"\\n{category} Category Leaderboard:\")\n",
        "        print(category_leaderboard)\n",
        "    \n",
        "    # Export results in multiple formats\n",
        "    print(\"\\nüíæ Exporting Results...\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # CSV export\n",
        "    performance_df.to_csv('outputs/performance_data.csv', index=False)\n",
        "    print(\"‚úÖ Performance data exported to CSV\")\n",
        "    \n",
        "    # JSON export\n",
        "    performance_df.to_json('outputs/performance_data.json', orient='records', indent=2)\n",
        "    print(\"‚úÖ Performance data exported to JSON\")\n",
        "    \n",
        "    # LaTeX table export\n",
        "    if len(leaderboard_df) > 0:\n",
        "        latex_table = leaderboard_df.to_latex(index=False, float_format='%.4f')\n",
        "        with open('outputs/leaderboard_table.tex', 'w') as f:\n",
        "            f.write(latex_table)\n",
        "        print(\"‚úÖ Leaderboard table exported to LaTeX\")\n",
        "    \n",
        "    print(\"\\nüéØ All visualizations and exports completed successfully!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No performance data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Next Steps {#summary}\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Leaderboard Generation**: LRDBenchmark provides comprehensive tools for creating performance leaderboards:\n",
        "   - **Multi-category Comparison**: Classical, ML, and Neural estimators\n",
        "   - **Composite Scoring**: Combined accuracy, speed, and reliability metrics\n",
        "   - **Statistical Analysis**: Confidence intervals and significance tests\n",
        "   - **Publication-ready Output**: LaTeX, CSV, JSON formats\n",
        "\n",
        "2. **Performance Rankings**: The system generates multiple types of leaderboards:\n",
        "   - **Overall Leaderboard**: Combined performance across all categories\n",
        "   - **Category-specific**: Rankings within each estimator category\n",
        "   - **Metric-specific**: Rankings by accuracy, speed, or reliability\n",
        "   - **Composite Scoring**: Weighted combination of multiple metrics\n",
        "\n",
        "3. **Visualization**: Comprehensive plots and tables for:\n",
        "   - **Error Distributions**: Performance across different scenarios\n",
        "   - **Execution Time Analysis**: Computational efficiency comparison\n",
        "   - **Scatter Plots**: Error vs true Hurst parameter relationships\n",
        "   - **Bar Charts**: Direct performance comparisons\n",
        "\n",
        "### Leaderboard Results\n",
        "\n",
        "- **Top Performers**: Best estimators across different categories\n",
        "- **Performance Trade-offs**: Accuracy vs speed analysis\n",
        "- **Category Strengths**: Each category's optimal use cases\n",
        "- **Statistical Significance**: Confidence in performance differences\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Real-world Application**: Apply leaderboards to actual time series data\n",
        "2. **Advanced Analysis**: Explore statistical significance and confidence intervals\n",
        "3. **Custom Metrics**: Create domain-specific performance measures\n",
        "4. **Interactive Dashboards**: Build web-based leaderboard interfaces\n",
        "\n",
        "### Files Generated\n",
        "\n",
        "- `outputs/performance_leaderboard.csv`: Complete leaderboard data\n",
        "- `outputs/performance_data.csv`: Raw performance data\n",
        "- `outputs/performance_data.json`: JSON format data\n",
        "- `outputs/leaderboard_table.tex`: LaTeX table for publications\n",
        "- `outputs/leaderboard_visualization.png`: Comprehensive visualization\n",
        "\n",
        "### References\n",
        "\n",
        "1. Taqqu, M. S., Teverovsky, V., & Willinger, W. (1995). Estimators for long-range dependence: an empirical study. Fractals, 3(04), 785-798.\n",
        "2. Beran, J. (1994). Statistics for long-memory processes. CRC press.\n",
        "3. Abry, P., & Veitch, D. (1998). Wavelet analysis of long-range-dependent traffic. IEEE Transactions on information theory, 44(1), 2-15.\n",
        "\n",
        "---\n",
        "\n",
        "**Congratulations!** You've completed the comprehensive LRDBenchmark demonstration series. You now have a complete understanding of:\n",
        "- Data generation and visualization\n",
        "- Estimation and statistical validation\n",
        "- Custom model and estimator development\n",
        "- Comprehensive benchmarking\n",
        "- Leaderboard generation and analysis\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
