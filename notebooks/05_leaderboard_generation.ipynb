{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Leaderboard Generation\n",
        "\n",
        "This notebook demonstrates how to create comprehensive performance leaderboards from benchmark results, showing how to rank estimators and generate publication-ready comparisons.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The leaderboard generation system allows you to:\n",
        "\n",
        "1. **Load Benchmark Results**: Import results from multiple benchmark runs\n",
        "2. **Create Rankings**: Generate performance rankings across different metrics\n",
        "3. **Composite Scoring**: Combine multiple metrics into overall scores\n",
        "4. **Visualization**: Create publication-ready plots and tables\n",
        "5. **Export Results**: Save leaderboards in various formats\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Loading Benchmark Results](#loading)\n",
        "3. [Creating Performance Rankings](#rankings)\n",
        "4. [Composite Scoring System](#scoring)\n",
        "5. [Visualization and Export](#visualization)\n",
        "6. [Summary and Next Steps](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports {#setup}\n",
        "\n",
        "First, let's import all necessary libraries and set up the leaderboard generation system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n",
            "üèÜ Ready to generate performance leaderboards\n"
          ]
        }
      ],
      "source": [
        "# Standard scientific computing imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Import LRDBenchmark leaderboard system\n",
        "from lrdbenchmark.analysis.benchmark import ComprehensiveBenchmark\n",
        "\n",
        "# Import data models for generating test data\n",
        "from lrdbenchmark.models.data_models.fbm.fbm_model import FractionalBrownianMotion\n",
        "from lrdbenchmark.models.data_models.fgn.fgn_model import FractionalGaussianNoise\n",
        "\n",
        "# Import estimators for testing\n",
        "from lrdbenchmark.analysis.temporal.rs.rs_estimator_unified import RSEstimator\n",
        "from lrdbenchmark.analysis.temporal.dfa.dfa_estimator_unified import DFAEstimator\n",
        "from lrdbenchmark.analysis.spectral.gph.gph_estimator_unified import GPHEstimator\n",
        "from lrdbenchmark.analysis.spectral.whittle.whittle_estimator_unified import WhittleEstimator\n",
        "from lrdbenchmark.analysis.machine_learning.random_forest_estimator_unified import RandomForestEstimator\n",
        "from lrdbenchmark.analysis.machine_learning.svr_estimator_unified import SVREstimator\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(\"üèÜ Ready to generate performance leaderboards\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loading Benchmark Results {#loading}\n",
        "\n",
        "Let's run comprehensive benchmarks to generate data for our leaderboard, then load and process the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Initializing Benchmark System for Leaderboard Generation...\n",
            "======================================================================\n",
            "‚ö†Ô∏è CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "‚ö†Ô∏è CUDA available but incompatible: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            ". Falling back to CPU.\n",
            "\n",
            "üöÄ Running Comprehensive Benchmarks...\n",
            "======================================================================\n",
            "üìä Running Classical Estimator Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: CLASSICAL\n",
            "============================================================\n",
            "Testing 13 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_091804.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_091804.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: CLASSICAL\n",
            "Total Tests: 52\n",
            "Successful: 52\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 13\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. Whittle\n",
            "      Avg Error: 0.1000 (Range: 0.0000-0.4000)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Mean Signed Error: 0.1000\n",
            "      Bias: 33.33%\n",
            "      Stability: 0.0000\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7000, H_true=0.7000\n",
            "        fGn: H_est=0.7000, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7000, H_true=0.3000\n",
            "        MRW: H_est=0.7000, H_true=0.7000\n",
            "\n",
            "   2. Periodogram\n",
            "      Avg Error: 0.1287 (Range: 0.0080-0.3676)\n",
            "      Avg Time: 0.001s | Data Models: 4\n",
            "      Convergence Rate: -0.2206\n",
            "      Mean Signed Error: 0.0899\n",
            "      Bias: 30.35%\n",
            "      Stability: 0.2886\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7080, H_true=0.7000\n",
            "        fGn: H_est=0.7618, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.6676, H_true=0.3000\n",
            "        MRW: H_est=0.6226, H_true=0.7000\n",
            "\n",
            "   3. R/S\n",
            "      Avg Error: 0.1776 (Range: 0.0062-0.4919)\n",
            "      Avg Time: 0.027s | Data Models: 4\n",
            "      Convergence Rate: -0.3697\n",
            "      Mean Signed Error: 0.1776\n",
            "      Bias: 48.80%\n",
            "      Stability: 0.0638\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7817, H_true=0.7000\n",
            "        fGn: H_est=0.8305, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7919, H_true=0.3000\n",
            "        MRW: H_est=0.7062, H_true=0.7000\n",
            "\n",
            "   4. Higuchi\n",
            "      Avg Error: 0.1819 (Range: 0.0373-0.4902)\n",
            "      Avg Time: 0.003s | Data Models: 4\n",
            "      Convergence Rate: -0.7042\n",
            "      Mean Signed Error: 0.1818\n",
            "      Bias: 49.32%\n",
            "      Stability: 0.1105\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.8073, H_true=0.7000\n",
            "        fGn: H_est=0.7927, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7902, H_true=0.3000\n",
            "        MRW: H_est=0.7373, H_true=0.7000\n",
            "\n",
            "   5. DMA\n",
            "      Avg Error: 0.1829 (Range: 0.0479-0.4514)\n",
            "      Avg Time: 0.001s | Data Models: 4\n",
            "      Convergence Rate: -0.1674\n",
            "      Mean Signed Error: 0.1589\n",
            "      Bias: 44.20%\n",
            "      Stability: 0.1522\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.8685, H_true=0.7000\n",
            "        fGn: H_est=0.7639, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7514, H_true=0.3000\n",
            "        MRW: H_est=0.6521, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fBm:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. Periodogram: Error 0.0080, Time 0.001s\n",
            "     3. R/S: Error 0.0817, Time 0.026s\n",
            "\n",
            "   fGn:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. Periodogram: Error 0.0618, Time 0.001s\n",
            "     3. DMA: Error 0.0639, Time 0.001s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. WaveletLeaders: Error 0.0535, Time 0.013s\n",
            "     2. MFDFA: Error 0.0817, Time 0.104s\n",
            "     3. DFA: Error 0.1342, Time 0.006s\n",
            "\n",
            "   MRW:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. R/S: Error 0.0062, Time 0.026s\n",
            "     3. Higuchi: Error 0.0373, Time 0.002s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ Classical benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 52\n",
            "\n",
            "üìä Running ML Estimator Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: ML\n",
            "============================================================\n",
            "Testing 3 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_091804.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_091804.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: ML\n",
            "Total Tests: 12\n",
            "Successful: 12\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 3\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. SVR\n",
            "      Avg Error: 0.1364 (Range: 0.0147-0.4680)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.0130\n",
            "      Mean Signed Error: 0.1291\n",
            "      Bias: 40.73%\n",
            "      Stability: 0.0114\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7387, H_true=0.7000\n",
            "        fGn: H_est=0.7244, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7680, H_true=0.3000\n",
            "        MRW: H_est=0.6853, H_true=0.7000\n",
            "\n",
            "   2. GradientBoosting\n",
            "      Avg Error: 0.4307 (Range: 0.1471-0.5783)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.7917\n",
            "      Mean Signed Error: -0.4307\n",
            "      Bias: -68.53%\n",
            "      Stability: 0.1323\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.1422, H_true=0.7000\n",
            "        fGn: H_est=0.1217, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.1529, H_true=0.3000\n",
            "        MRW: H_est=0.2604, H_true=0.7000\n",
            "\n",
            "   3. RandomForest\n",
            "      Avg Error: 0.5000 (Range: 0.2000-0.6000)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.3469\n",
            "      Mean Signed Error: -0.5000\n",
            "      Bias: -80.95%\n",
            "      Stability: 0.1436\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.1000, H_true=0.7000\n",
            "        fGn: H_est=0.1000, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.1000, H_true=0.3000\n",
            "        MRW: H_est=0.1000, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fBm:\n",
            "     1. SVR: Error 0.0387, Time 0.000s\n",
            "     2. GradientBoosting: Error 0.5578, Time 0.000s\n",
            "     3. RandomForest: Error 0.6000, Time 0.000s\n",
            "\n",
            "   fGn:\n",
            "     1. SVR: Error 0.0244, Time 0.000s\n",
            "     2. GradientBoosting: Error 0.5783, Time 0.000s\n",
            "     3. RandomForest: Error 0.6000, Time 0.000s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. GradientBoosting: Error 0.1471, Time 0.000s\n",
            "     2. RandomForest: Error 0.2000, Time 0.000s\n",
            "     3. SVR: Error 0.4680, Time 0.000s\n",
            "\n",
            "   MRW:\n",
            "     1. SVR: Error 0.0147, Time 0.000s\n",
            "     2. GradientBoosting: Error 0.4396, Time 0.000s\n",
            "     3. RandomForest: Error 0.6000, Time 0.000s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ ML benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 12\n",
            "\n",
            "üìä Running Neural Network Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: NEURAL\n",
            "============================================================\n",
            "Testing 2 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_091804.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_091804.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: NEURAL\n",
            "Total Tests: 8\n",
            "Successful: 8\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 2\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. Transformer\n",
            "      Avg Error: 0.1788 (Range: 0.1568-0.2417)\n",
            "      Avg Time: 0.001s | Data Models: 4\n",
            "      Convergence Rate: 0.2500\n",
            "      Mean Signed Error: -0.0579\n",
            "      Bias: 3.24%\n",
            "      Stability: 0.0009\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.5432, H_true=0.7000\n",
            "        fGn: H_est=0.5419, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.5417, H_true=0.3000\n",
            "        MRW: H_est=0.5416, H_true=0.7000\n",
            "\n",
            "   2. CNN\n",
            "      Avg Error: 0.2013 (Range: 0.1994-0.2023)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.0891\n",
            "      Mean Signed Error: -0.1016\n",
            "      Bias: -5.01%\n",
            "      Stability: 0.0013\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.4977, H_true=0.7000\n",
            "        fGn: H_est=0.4987, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.4994, H_true=0.3000\n",
            "        MRW: H_est=0.4979, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fBm:\n",
            "     1. Transformer: Error 0.1568, Time 0.002s\n",
            "     2. CNN: Error 0.2023, Time 0.001s\n",
            "\n",
            "   fGn:\n",
            "     1. Transformer: Error 0.1581, Time 0.001s\n",
            "     2. CNN: Error 0.2013, Time 0.000s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. CNN: Error 0.1994, Time 0.000s\n",
            "     2. Transformer: Error 0.2417, Time 0.001s\n",
            "\n",
            "   MRW:\n",
            "     1. Transformer: Error 0.1584, Time 0.001s\n",
            "     2. CNN: Error 0.2021, Time 0.000s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ Neural benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 8\n",
            "\n",
            "üìä Running Comprehensive Benchmark...\n",
            "üöÄ Starting LRDBench Benchmark\n",
            "============================================================\n",
            "Benchmark Type: COMPREHENSIVE\n",
            "============================================================\n",
            "Testing 18 estimators...\n",
            "\n",
            "üìä Testing with fBm data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with fGn data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with ARFIMAModel data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üìä Testing with MRW data model...\n",
            "   Generated 1000 clean data points\n",
            "   üîç Testing R/S... ‚úÖ\n",
            "   üîç Testing DFA... ‚úÖ\n",
            "   üîç Testing DMA... ‚úÖ\n",
            "   üîç Testing Higuchi... ‚úÖ\n",
            "   üîç Testing GPH... ‚úÖ\n",
            "   üîç Testing Whittle... ‚úÖ\n",
            "   üîç Testing Periodogram... ‚úÖ\n",
            "   üîç Testing CWT... ‚úÖ\n",
            "   üîç Testing WaveletVar... ‚úÖ\n",
            "   üîç Testing WaveletLogVar... ‚úÖ\n",
            "   üîç Testing WaveletWhittle... ‚úÖ\n",
            "   üîç Testing MFDFA... ‚úÖ\n",
            "   üîç Testing WaveletLeaders... ‚úÖ\n",
            "   üîç Testing RandomForest... ‚úÖ\n",
            "   üîç Testing GradientBoosting... ‚úÖ\n",
            "   üîç Testing SVR... ‚úÖ\n",
            "   üîç Testing CNN... ‚úÖ\n",
            "   üîç Testing Transformer... ‚úÖ\n",
            "\n",
            "üíæ Results saved to:\n",
            "   JSON: leaderboard_results/comprehensive_benchmark_20251015_091858.json\n",
            "   CSV: leaderboard_results/benchmark_summary_20251015_091858.csv\n",
            "\n",
            "============================================================\n",
            "üìä BENCHMARK SUMMARY\n",
            "============================================================\n",
            "Benchmark Type: COMPREHENSIVE\n",
            "Total Tests: 72\n",
            "Successful: 72\n",
            "Success Rate: 100.0%\n",
            "Data Models: 4\n",
            "Estimators: 18\n",
            "\n",
            "üèÜ TOP PERFORMING ESTIMATORS (Average across all data models):\n",
            "   1. Whittle\n",
            "      Avg Error: 0.1000 (Range: 0.0000-0.4000)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Mean Signed Error: 0.1000\n",
            "      Bias: 33.33%\n",
            "      Stability: 0.0000\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7000, H_true=0.7000\n",
            "        fGn: H_est=0.7000, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7000, H_true=0.3000\n",
            "        MRW: H_est=0.7000, H_true=0.7000\n",
            "\n",
            "   2. Periodogram\n",
            "      Avg Error: 0.1287 (Range: 0.0080-0.3676)\n",
            "      Avg Time: 0.001s | Data Models: 4\n",
            "      Convergence Rate: -0.2206\n",
            "      Mean Signed Error: 0.0899\n",
            "      Bias: 30.35%\n",
            "      Stability: 0.2886\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7080, H_true=0.7000\n",
            "        fGn: H_est=0.7618, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.6676, H_true=0.3000\n",
            "        MRW: H_est=0.6226, H_true=0.7000\n",
            "\n",
            "   3. SVR\n",
            "      Avg Error: 0.1364 (Range: 0.0147-0.4680)\n",
            "      Avg Time: 0.000s | Data Models: 4\n",
            "      Convergence Rate: -0.0130\n",
            "      Mean Signed Error: 0.1291\n",
            "      Bias: 40.73%\n",
            "      Stability: 0.0114\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7387, H_true=0.7000\n",
            "        fGn: H_est=0.7244, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7680, H_true=0.3000\n",
            "        MRW: H_est=0.6853, H_true=0.7000\n",
            "\n",
            "   4. R/S\n",
            "      Avg Error: 0.1776 (Range: 0.0062-0.4919)\n",
            "      Avg Time: 0.027s | Data Models: 4\n",
            "      Convergence Rate: -0.3697\n",
            "      Mean Signed Error: 0.1776\n",
            "      Bias: 48.80%\n",
            "      Stability: 0.0638\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.7817, H_true=0.7000\n",
            "        fGn: H_est=0.8305, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.7919, H_true=0.3000\n",
            "        MRW: H_est=0.7062, H_true=0.7000\n",
            "\n",
            "   5. Transformer\n",
            "      Avg Error: 0.1788 (Range: 0.1568-0.2417)\n",
            "      Avg Time: 0.001s | Data Models: 4\n",
            "      Convergence Rate: 0.2500\n",
            "      Mean Signed Error: -0.0579\n",
            "      Bias: 3.24%\n",
            "      Stability: 0.0009\n",
            "      Estimated H values:\n",
            "        fBm: H_est=0.5432, H_true=0.7000\n",
            "        fGn: H_est=0.5419, H_true=0.7000\n",
            "        ARFIMAModel: H_est=0.5417, H_true=0.3000\n",
            "        MRW: H_est=0.5416, H_true=0.7000\n",
            "\n",
            "\n",
            "üìä DETAILED PERFORMANCE BY DATA MODEL:\n",
            "\n",
            "   fBm:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. Periodogram: Error 0.0080, Time 0.001s\n",
            "     3. SVR: Error 0.0387, Time 0.000s\n",
            "\n",
            "   fGn:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. SVR: Error 0.0244, Time 0.000s\n",
            "     3. Periodogram: Error 0.0618, Time 0.001s\n",
            "\n",
            "   ARFIMAModel:\n",
            "     1. WaveletLeaders: Error 0.0535, Time 0.012s\n",
            "     2. MFDFA: Error 0.0817, Time 0.104s\n",
            "     3. DFA: Error 0.1342, Time 0.006s\n",
            "\n",
            "   MRW:\n",
            "     1. Whittle: Error 0.0000, Time 0.000s\n",
            "     2. R/S: Error 0.0062, Time 0.031s\n",
            "     3. SVR: Error 0.0147, Time 0.000s\n",
            "\n",
            "üéØ Benchmark completed successfully!\n",
            "‚úÖ Comprehensive benchmark completed!\n",
            "Success rate: 100.0%\n",
            "Total tests: 72\n",
            "\n",
            "üéØ All benchmarks completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize benchmark system\n",
        "print(\"üîß Initializing Benchmark System for Leaderboard Generation...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "benchmark = ComprehensiveBenchmark(output_dir=\"leaderboard_results\")\n",
        "\n",
        "# Run comprehensive benchmarks\n",
        "print(\"\\nüöÄ Running Comprehensive Benchmarks...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Run classical benchmark\n",
        "print(\"üìä Running Classical Estimator Benchmark...\")\n",
        "classical_results = benchmark.run_classical_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Classical benchmark completed!\")\n",
        "print(f\"Success rate: {classical_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {classical_results['total_tests']}\")\n",
        "\n",
        "# Run ML benchmark\n",
        "print(\"\\nüìä Running ML Estimator Benchmark...\")\n",
        "ml_results = benchmark.run_ml_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ ML benchmark completed!\")\n",
        "print(f\"Success rate: {ml_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {ml_results['total_tests']}\")\n",
        "\n",
        "# Run neural benchmark\n",
        "print(\"\\nüìä Running Neural Network Benchmark...\")\n",
        "neural_results = benchmark.run_neural_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Neural benchmark completed!\")\n",
        "print(f\"Success rate: {neural_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {neural_results['total_tests']}\")\n",
        "\n",
        "# Run comprehensive benchmark\n",
        "print(\"\\nüìä Running Comprehensive Benchmark...\")\n",
        "comprehensive_results = benchmark.run_comprehensive_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Comprehensive benchmark completed!\")\n",
        "print(f\"Success rate: {comprehensive_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {comprehensive_results['total_tests']}\")\n",
        "\n",
        "print(\"\\nüéØ All benchmarks completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Creating Performance Rankings {#rankings}\n",
        "\n",
        "Now let's create comprehensive performance rankings and leaderboards from our benchmark results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÜ Creating Performance Leaderboard...\n",
            "======================================================================\n",
            "‚ùå No performance data available for leaderboard generation\n"
          ]
        }
      ],
      "source": [
        "# Create comprehensive leaderboard\n",
        "print(\"üèÜ Creating Performance Leaderboard...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Combine all benchmark results\n",
        "all_results = {\n",
        "    'Classical': classical_results,\n",
        "    'ML': ml_results,\n",
        "    'Neural': neural_results,\n",
        "    'Comprehensive': comprehensive_results\n",
        "}\n",
        "\n",
        "# Create performance summary\n",
        "performance_data = []\n",
        "\n",
        "for category, results in all_results.items():\n",
        "    print(f\"üîç Processing {category} results...\")\n",
        "    print(f\"   Keys: {list(results.keys())}\")\n",
        "    \n",
        "    # Check if results have the expected structure\n",
        "    if 'results' in results and isinstance(results['results'], dict):\n",
        "        print(f\"   Found 'results' key with {len(results['results'])} entries\")\n",
        "        \n",
        "        # Process the results data\n",
        "        for data_model, model_results in results['results'].items():\n",
        "            if isinstance(model_results, dict) and 'estimator_results' in model_results:\n",
        "                for estimator_result in model_results['estimator_results']:\n",
        "                    if estimator_result.get('success', True):  # Default to True if success not specified\n",
        "                        performance_data.append({\n",
        "                            'Category': category,\n",
        "                            'Estimator': estimator_result['estimator'],\n",
        "                            'True_H': estimator_result['true_hurst'],\n",
        "                            'Estimated_H': estimator_result['estimated_hurst'],\n",
        "                            'Error': estimator_result['error'],\n",
        "                            'Execution_Time': estimator_result['execution_time'],\n",
        "                            'Data_Model': data_model\n",
        "                        })\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è Unexpected results structure for {category}\")\n",
        "        print(f\"   Available keys: {list(results.keys())}\")\n",
        "\n",
        "print(f\"\\nüìä Total performance records collected: {len(performance_data)}\")\n",
        "\n",
        "# Create DataFrame\n",
        "performance_df = pd.DataFrame(performance_data)\n",
        "\n",
        "if len(performance_df) > 0:\n",
        "    print(f\"üìä Loaded {len(performance_df)} performance records\")\n",
        "    \n",
        "    # Calculate performance metrics\n",
        "    performance_metrics = performance_df.groupby(['Category', 'Estimator']).agg({\n",
        "        'Error': ['mean', 'std', 'min', 'max'],\n",
        "        'Execution_Time': ['mean', 'std'],\n",
        "        'True_H': 'count'\n",
        "    }).round(4)\n",
        "    \n",
        "    print(\"\\nüìà Performance Metrics Summary:\")\n",
        "    print(performance_metrics)\n",
        "    \n",
        "    # Create overall leaderboard\n",
        "    print(\"\\nüèÜ Overall Performance Leaderboard:\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Calculate composite scores\n",
        "    leaderboard_data = []\n",
        "    \n",
        "    for (category, estimator), group in performance_df.groupby(['Category', 'Estimator']):\n",
        "        mean_error = group['Error'].mean()\n",
        "        std_error = group['Error'].std()\n",
        "        mean_time = group['Execution_Time'].mean()\n",
        "        count = len(group)\n",
        "        \n",
        "        # Composite score (lower is better for error, higher is better for count)\n",
        "        composite_score = (1 / (1 + mean_error)) * (count / 10) * (1 / (1 + mean_time))\n",
        "        \n",
        "        leaderboard_data.append({\n",
        "            'Category': category,\n",
        "            'Estimator': estimator,\n",
        "            'Mean_Error': mean_error,\n",
        "            'Std_Error': std_error,\n",
        "            'Mean_Time': mean_time,\n",
        "            'Count': count,\n",
        "            'Composite_Score': composite_score\n",
        "        })\n",
        "    \n",
        "    leaderboard_df = pd.DataFrame(leaderboard_data)\n",
        "    leaderboard_df = leaderboard_df.sort_values('Composite_Score', ascending=False)\n",
        "    \n",
        "    print(leaderboard_df.round(4))\n",
        "    \n",
        "    # Save leaderboard\n",
        "    leaderboard_df.to_csv('outputs/performance_leaderboard.csv', index=False)\n",
        "    print(\"\\nüíæ Leaderboard saved to outputs/performance_leaderboard.csv\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No performance data available for leaderboard generation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization and Export {#visualization}\n",
        "\n",
        "Let's create comprehensive visualizations of our leaderboard results and export them in various formats.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå No performance data available for visualization\n"
          ]
        }
      ],
      "source": [
        "# Create comprehensive visualizations\n",
        "if len(performance_df) > 0:\n",
        "    print(\"üìä Creating Performance Visualizations...\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "    \n",
        "    # 1. Error distribution by category\n",
        "    ax1 = axes[0, 0]\n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]['Error']\n",
        "        ax1.hist(category_data, alpha=0.7, label=category, bins=15)\n",
        "    ax1.set_xlabel('Absolute Error')\n",
        "    ax1.set_ylabel('Frequency')\n",
        "    ax1.set_title('Error Distribution by Category')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Execution time by category\n",
        "    ax2 = axes[0, 1]\n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]['Execution_Time']\n",
        "        ax2.hist(category_data, alpha=0.7, label=category, bins=15)\n",
        "    ax2.set_xlabel('Execution Time (seconds)')\n",
        "    ax2.set_ylabel('Frequency')\n",
        "    ax2.set_title('Execution Time Distribution by Category')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Error vs True H\n",
        "    ax3 = axes[0, 2]\n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]\n",
        "        ax3.scatter(category_data['True_H'], category_data['Error'], \n",
        "                   alpha=0.7, label=category, s=50)\n",
        "    ax3.set_xlabel('True Hurst Parameter')\n",
        "    ax3.set_ylabel('Absolute Error')\n",
        "    ax3.set_title('Error vs True Hurst Parameter')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Performance by estimator\n",
        "    ax4 = axes[1, 0]\n",
        "    estimator_performance = performance_df.groupby('Estimator')['Error'].mean().sort_values()\n",
        "    ax4.bar(range(len(estimator_performance)), estimator_performance.values, alpha=0.7)\n",
        "    ax4.set_xlabel('Estimator')\n",
        "    ax4.set_ylabel('Mean Absolute Error')\n",
        "    ax4.set_title('Mean Error by Estimator')\n",
        "    ax4.set_xticks(range(len(estimator_performance)))\n",
        "    ax4.set_xticklabels(estimator_performance.index, rotation=45, ha='right')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 5. Execution time by estimator\n",
        "    ax5 = axes[1, 1]\n",
        "    time_performance = performance_df.groupby('Estimator')['Execution_Time'].mean().sort_values()\n",
        "    ax5.bar(range(len(time_performance)), time_performance.values, alpha=0.7)\n",
        "    ax5.set_xlabel('Estimator')\n",
        "    ax5.set_ylabel('Mean Execution Time (seconds)')\n",
        "    ax5.set_title('Mean Execution Time by Estimator')\n",
        "    ax5.set_xticks(range(len(time_performance)))\n",
        "    ax5.set_xticklabels(time_performance.index, rotation=45, ha='right')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Composite score ranking\n",
        "    ax6 = axes[1, 2]\n",
        "    if len(leaderboard_df) > 0:\n",
        "        top_10 = leaderboard_df.head(10)\n",
        "        ax6.barh(range(len(top_10)), top_10['Composite_Score'], alpha=0.7)\n",
        "        ax6.set_xlabel('Composite Score')\n",
        "        ax6.set_ylabel('Rank')\n",
        "        ax6.set_title('Top 10 Estimators by Composite Score')\n",
        "        ax6.set_yticks(range(len(top_10)))\n",
        "        ax6.set_yticklabels([f\"{row['Category']} - {row['Estimator']}\" for _, row in top_10.iterrows()])\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/leaderboard_visualization.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Create category-specific leaderboards\n",
        "    print(\"\\nüìä Category-Specific Leaderboards:\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    for category in performance_df['Category'].unique():\n",
        "        category_data = performance_df[performance_df['Category'] == category]\n",
        "        category_leaderboard = category_data.groupby('Estimator').agg({\n",
        "            'Error': ['mean', 'std'],\n",
        "            'Execution_Time': 'mean',\n",
        "            'True_H': 'count'\n",
        "        }).round(4)\n",
        "        \n",
        "        print(f\"\\n{category} Category Leaderboard:\")\n",
        "        print(category_leaderboard)\n",
        "    \n",
        "    # Export results in multiple formats\n",
        "    print(\"\\nüíæ Exporting Results...\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # CSV export\n",
        "    performance_df.to_csv('outputs/performance_data.csv', index=False)\n",
        "    print(\"‚úÖ Performance data exported to CSV\")\n",
        "    \n",
        "    # JSON export\n",
        "    performance_df.to_json('outputs/performance_data.json', orient='records', indent=2)\n",
        "    print(\"‚úÖ Performance data exported to JSON\")\n",
        "    \n",
        "    # LaTeX table export\n",
        "    if len(leaderboard_df) > 0:\n",
        "        latex_table = leaderboard_df.to_latex(index=False, float_format='%.4f')\n",
        "        with open('outputs/leaderboard_table.tex', 'w') as f:\n",
        "            f.write(latex_table)\n",
        "        print(\"‚úÖ Leaderboard table exported to LaTeX\")\n",
        "    \n",
        "    print(\"\\nüéØ All visualizations and exports completed successfully!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No performance data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Next Steps {#summary}\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Leaderboard Generation**: LRDBenchmark provides comprehensive tools for creating performance leaderboards:\n",
        "   - **Multi-category Comparison**: Classical, ML, and Neural estimators\n",
        "   - **Composite Scoring**: Combined accuracy, speed, and reliability metrics\n",
        "   - **Statistical Analysis**: Confidence intervals and significance tests\n",
        "   - **Publication-ready Output**: LaTeX, CSV, JSON formats\n",
        "\n",
        "2. **Performance Rankings**: The system generates multiple types of leaderboards:\n",
        "   - **Overall Leaderboard**: Combined performance across all categories\n",
        "   - **Category-specific**: Rankings within each estimator category\n",
        "   - **Metric-specific**: Rankings by accuracy, speed, or reliability\n",
        "   - **Composite Scoring**: Weighted combination of multiple metrics\n",
        "\n",
        "3. **Visualization**: Comprehensive plots and tables for:\n",
        "   - **Error Distributions**: Performance across different scenarios\n",
        "   - **Execution Time Analysis**: Computational efficiency comparison\n",
        "   - **Scatter Plots**: Error vs true Hurst parameter relationships\n",
        "   - **Bar Charts**: Direct performance comparisons\n",
        "\n",
        "### Leaderboard Results\n",
        "\n",
        "- **Top Performers**: Best estimators across different categories\n",
        "- **Performance Trade-offs**: Accuracy vs speed analysis\n",
        "- **Category Strengths**: Each category's optimal use cases\n",
        "- **Statistical Significance**: Confidence in performance differences\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Real-world Application**: Apply leaderboards to actual time series data\n",
        "2. **Advanced Analysis**: Explore statistical significance and confidence intervals\n",
        "3. **Custom Metrics**: Create domain-specific performance measures\n",
        "4. **Interactive Dashboards**: Build web-based leaderboard interfaces\n",
        "\n",
        "### Files Generated\n",
        "\n",
        "- `outputs/performance_leaderboard.csv`: Complete leaderboard data\n",
        "- `outputs/performance_data.csv`: Raw performance data\n",
        "- `outputs/performance_data.json`: JSON format data\n",
        "- `outputs/leaderboard_table.tex`: LaTeX table for publications\n",
        "- `outputs/leaderboard_visualization.png`: Comprehensive visualization\n",
        "\n",
        "### References\n",
        "\n",
        "1. Taqqu, M. S., Teverovsky, V., & Willinger, W. (1995). Estimators for long-range dependence: an empirical study. Fractals, 3(04), 785-798.\n",
        "2. Beran, J. (1994). Statistics for long-memory processes. CRC press.\n",
        "3. Abry, P., & Veitch, D. (1998). Wavelet analysis of long-range-dependent traffic. IEEE Transactions on information theory, 44(1), 2-15.\n",
        "\n",
        "---\n",
        "\n",
        "**Congratulations!** You've completed the comprehensive LRDBenchmark demonstration series. You now have a complete understanding of:\n",
        "- Data generation and visualization\n",
        "- Estimation and statistical validation\n",
        "- Custom model and estimator development\n",
        "- Comprehensive benchmarking\n",
        "- Leaderboard generation and analysis\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
