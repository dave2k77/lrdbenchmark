{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Generation and Visualisation\n",
        "\n",
        "This notebook demonstrates the comprehensive data generation capabilities of the LRDBenchmark library, covering all available stochastic models for long-range dependence (LRD) analysis.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Long-range dependence (LRD) is a statistical property where observations that are far apart in time are still correlated. This notebook covers:\n",
        "\n",
        "1. **Theoretical Background**: Understanding LRD and the Hurst parameter\n",
        "2. **Data Models**: All available stochastic processes in LRDBenchmark\n",
        "3. **Visualisation**: Comprehensive plots and analysis\n",
        "4. **Quality Assessment**: Statistical validation of generated data\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Theoretical Background](#theory)\n",
        "3. [Fractional Brownian Motion (FBM)](#fbm)\n",
        "4. [Fractional Gaussian Noise (FGN)](#fgn)\n",
        "5. [ARFIMA Processes](#arfima)\n",
        "6. [Multifractal Random Walk (MRW)](#mrw)\n",
        "7. [Alpha-Stable Processes](#alpha-stable)\n",
        "8. [Comparative Analysis](#comparison)\n",
        "9. [Data Quality Assessment](#quality)\n",
        "10. [Summary and Next Steps](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports {#setup}\n",
        "\n",
        "First, let's import all necessary libraries and set up the environment for reproducible results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard scientific computing imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import normaltest, jarque_bera\n",
        "from statsmodels.tsa.stattools import adfuller, acf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Import LRDBenchmark data models\n",
        "from lrdbenchmark.models.data_models.fbm.fbm_model import FractionalBrownianMotion\n",
        "from lrdbenchmark.models.data_models.fgn.fgn_model import FractionalGaussianNoise\n",
        "from lrdbenchmark.models.data_models.arfima.arfima_model import ARFIMAModel\n",
        "from lrdbenchmark.models.data_models.mrw.mrw_model import MultifractalRandomWalk\n",
        "from lrdbenchmark.models.data_models.alpha_stable.alpha_stable_model import AlphaStableModel\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Theoretical Background {#theory}\n",
        "\n",
        "### Long-Range Dependence (LRD)\n",
        "\n",
        "Long-range dependence is characterised by the **Hurst parameter H**:\n",
        "\n",
        "- **H = 0.5**: No long-range dependence (standard random walk)\n",
        "- **H > 0.5**: Persistent (positive long-range dependence)\n",
        "- **H < 0.5**: Anti-persistent (negative long-range dependence)\n",
        "\n",
        "### Key Properties\n",
        "\n",
        "1. **Self-similarity**: Statistical properties are preserved under scaling\n",
        "2. **Power-law decay**: Autocorrelation function decays as œÑ^(2H-2)\n",
        "3. **Spectral density**: Power spectral density follows f^(1-2H) at low frequencies\n",
        "\n",
        "Let's visualise these concepts:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a conceptual plot showing different Hurst parameter effects\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Generate sample data for different H values\n",
        "H_values = [0.3, 0.5, 0.7, 0.9]\n",
        "colors = ['red', 'blue', 'green', 'purple']\n",
        "n_samples = 1000\n",
        "\n",
        "for i, (H, color) in enumerate(zip(H_values, colors)):\n",
        "    # Generate FBM data\n",
        "    fbm = FractionalBrownianMotion(H=H, sigma=1.0)\n",
        "    data = fbm.generate(n_samples, seed=42)\n",
        "    \n",
        "    # Plot time series\n",
        "    axes[0, 0].plot(data[:200], color=color, alpha=0.8, linewidth=1.5, label=f'H = {H}')\n",
        "    \n",
        "    # Plot autocorrelation function\n",
        "    acf_values = acf(data, nlags=50, fft=True)\n",
        "    axes[0, 1].plot(acf_values, color=color, alpha=0.8, linewidth=2, label=f'H = {H}')\n",
        "    \n",
        "    # Plot power spectral density\n",
        "    freqs = np.fft.fftfreq(n_samples)[:n_samples//2]\n",
        "    psd = np.abs(np.fft.fft(data))**2\n",
        "    psd = psd[:n_samples//2]\n",
        "    axes[1, 0].loglog(freqs[1:], psd[1:], color=color, alpha=0.8, linewidth=2, label=f'H = {H}')\n",
        "    \n",
        "    # Plot distribution\n",
        "    axes[1, 1].hist(data, bins=50, alpha=0.6, color=color, density=True, label=f'H = {H}')\n",
        "\n",
        "# Customize plots\n",
        "axes[0, 0].set_title('Time Series (First 200 points)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Time')\n",
        "axes[0, 0].set_ylabel('Value')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].set_title('Autocorrelation Function', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Lag')\n",
        "axes[0, 1].set_ylabel('ACF')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 0].set_title('Power Spectral Density', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Frequency')\n",
        "axes[1, 0].set_ylabel('PSD')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].set_title('Distribution', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Value')\n",
        "axes[1, 1].set_ylabel('Density')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/hurst_parameter_effects.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Key Observations:\")\n",
        "print(\"‚Ä¢ H < 0.5: Anti-persistent (oscillatory, mean-reverting)\")\n",
        "print(\"‚Ä¢ H = 0.5: Standard random walk (no memory)\")\n",
        "print(\"‚Ä¢ H > 0.5: Persistent (trending, long memory)\")\n",
        "print(\"‚Ä¢ Higher H values show stronger long-range dependence\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Fractional Brownian Motion (FBM) {#fbm}\n",
        "\n",
        "Fractional Brownian Motion is a self-similar Gaussian process with stationary increments. It's the foundation for many LRD models.\n",
        "\n",
        "### Key Properties:\n",
        "- **Self-similarity**: B_H(at) = a^H B_H(t)\n",
        "- **Gaussian increments**: All finite-dimensional distributions are Gaussian\n",
        "- **Stationary increments**: Increments are stationary but not independent\n",
        "- **Covariance**: E[B_H(s)B_H(t)] = 0.5(|s|^(2H) + |t|^(2H) - |s-t|^(2H))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate FBM data with different Hurst parameters\n",
        "print(\"üîç Generating Fractional Brownian Motion data...\")\n",
        "\n",
        "H_values = [0.3, 0.5, 0.7, 0.9]\n",
        "fbm_data = {}\n",
        "n_samples = 2000\n",
        "\n",
        "for H in H_values:\n",
        "    fbm = FractionalBrownianMotion(H=H, sigma=1.0)\n",
        "    data = fbm.generate(n_samples, seed=42)\n",
        "    fbm_data[f'FBM_H={H}'] = data\n",
        "    \n",
        "    # Print basic statistics\n",
        "    print(f\"\\nüìà FBM with H = {H}:\")\n",
        "    print(f\"   Mean: {data.mean():.4f}\")\n",
        "    print(f\"   Std: {data.std():.4f}\")\n",
        "    print(f\"   Min: {data.min():.4f}\")\n",
        "    print(f\"   Max: {data.max():.4f}\")\n",
        "    print(f\"   Range: {data.max() - data.min():.4f}\")\n",
        "\n",
        "# Visualise FBM data\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Time series plots\n",
        "for i, (name, data) in enumerate(fbm_data.items()):\n",
        "    ax = axes[i//2, i%2]\n",
        "    ax.plot(data[:500], linewidth=1.5, alpha=0.8)\n",
        "    ax.set_title(f'{name} (First 500 points)', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Time')\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/fbm_time_series.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Analyse theoretical properties\n",
        "print(\"\\nüßÆ Theoretical Properties Analysis:\")\n",
        "for name, data in fbm_data.items():\n",
        "    H = float(name.split('=')[1])\n",
        "    \n",
        "    # Calculate empirical properties\n",
        "    increments = np.diff(data)\n",
        "    \n",
        "    # Variance of increments (should be constant for FBM)\n",
        "    var_increments = np.var(increments)\n",
        "    \n",
        "    # Autocorrelation of increments\n",
        "    acf_increments = acf(increments, nlags=20, fft=True)\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"   Theoretical H: {H:.1f}\")\n",
        "    print(f\"   Variance of increments: {var_increments:.4f}\")\n",
        "    print(f\"   ACF(1): {acf_increments[1]:.4f}\")\n",
        "    print(f\"   ACF(5): {acf_increments[5]:.4f}\")\n",
        "    print(f\"   ACF(10): {acf_increments[10]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Comparative Analysis {#comparison}\n",
        "\n",
        "Now let's compare all data models side by side to understand their different characteristics and use cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comparative data from all models\n",
        "print(\"üîç Generating comparative data from all models...\")\n",
        "\n",
        "# Use H=0.7 for all models where applicable\n",
        "H_target = 0.7\n",
        "n_samples = 1000\n",
        "\n",
        "comparative_data = {}\n",
        "\n",
        "# FBM\n",
        "fbm = FractionalBrownianMotion(H=H_target, sigma=1.0)\n",
        "comparative_data['FBM'] = fbm.generate(n_samples, seed=42)\n",
        "\n",
        "# FGN\n",
        "fgn = FractionalGaussianNoise(H=H_target, sigma=1.0)\n",
        "comparative_data['FGN'] = fgn.generate(n_samples, seed=42)\n",
        "\n",
        "# ARFIMA (d = H - 0.5 = 0.2)\n",
        "arfima = ARFIMAModel(d=0.2, ar_params=[0.3], ma_params=[0.2], sigma=1.0)\n",
        "comparative_data['ARFIMA'] = arfima.generate(n_samples, seed=42)\n",
        "\n",
        "# MRW\n",
        "mrw = MultifractalRandomWalk(H=H_target, lambda_param=0.2, sigma=1.0)\n",
        "comparative_data['MRW'] = mrw.generate(n_samples, seed=42)\n",
        "\n",
        "# Alpha-Stable (symmetric) - using more stable parameters\n",
        "alpha_stable = AlphaStableModel(alpha=1.8, beta=0.0, sigma=0.5, mu=0.0)\n",
        "alpha_stable_data = alpha_stable.generate(n_samples, seed=42)\n",
        "\n",
        "# Check for NaN values and replace with finite values if needed\n",
        "if np.any(np.isnan(alpha_stable_data)) or np.any(np.isinf(alpha_stable_data)):\n",
        "    print(\"‚ö†Ô∏è Alpha-Stable model generated NaN/Inf values, using fallback parameters\")\n",
        "    alpha_stable = AlphaStableModel(alpha=1.9, beta=0.0, sigma=0.3, mu=0.0)\n",
        "    alpha_stable_data = alpha_stable.generate(n_samples, seed=42)\n",
        "\n",
        "comparative_data['Alpha-Stable'] = alpha_stable_data\n",
        "\n",
        "# Create comprehensive comparison plot\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
        "\n",
        "# Define colors for consistency\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
        "model_names = list(comparative_data.keys())\n",
        "\n",
        "# Time series plots\n",
        "for i, (name, data) in enumerate(comparative_data.items()):\n",
        "    ax = axes[0, i//3] if i < 3 else axes[0, i-3]\n",
        "    ax.plot(data[:200], linewidth=1.5, alpha=0.8, color=colors[i], label=name)\n",
        "    ax.set_title(f'{name} (H‚âà0.7)', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Time')\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "\n",
        "# Autocorrelation functions\n",
        "for i, (name, data) in enumerate(comparative_data.items()):\n",
        "    ax = axes[1, i//3] if i < 3 else axes[1, i-3]\n",
        "    acf_values = acf(data, nlags=30, fft=True)\n",
        "    ax.plot(acf_values, linewidth=2, alpha=0.8, color=colors[i], label=name)\n",
        "    ax.set_title(f'{name} ACF', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Lag')\n",
        "    ax.set_ylabel('ACF')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "\n",
        "# Distributions\n",
        "for i, (name, data) in enumerate(comparative_data.items()):\n",
        "    ax = axes[2, i//3] if i < 3 else axes[2, i-3]\n",
        "    ax.hist(data, bins=30, density=True, alpha=0.7, color=colors[i], label=name)\n",
        "    ax.set_title(f'{name} Distribution', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/comparative_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Statistical comparison table\n",
        "print(\"\\nüìä Statistical Comparison Table:\")\n",
        "comparison_stats = []\n",
        "\n",
        "for name, data in comparative_data.items():\n",
        "    # Clean data - remove NaN and infinite values\n",
        "    clean_data = data[np.isfinite(data)]\n",
        "    \n",
        "    if len(clean_data) == 0:\n",
        "        print(f\"‚ö†Ô∏è Warning: {name} contains no finite values\")\n",
        "        stats_dict = {\n",
        "            'Model': name,\n",
        "            'Mean': np.nan,\n",
        "            'Std': np.nan,\n",
        "            'Skewness': np.nan,\n",
        "            'Kurtosis': np.nan,\n",
        "            'Min': np.nan,\n",
        "            'Max': np.nan,\n",
        "            'Range': np.nan\n",
        "        }\n",
        "    else:\n",
        "        stats_dict = {\n",
        "            'Model': name,\n",
        "            'Mean': clean_data.mean(),\n",
        "            'Std': clean_data.std(),\n",
        "            'Skewness': stats.skew(clean_data) if len(clean_data) > 2 else np.nan,\n",
        "            'Kurtosis': stats.kurtosis(clean_data) if len(clean_data) > 3 else np.nan,\n",
        "            'Min': clean_data.min(),\n",
        "            'Max': clean_data.max(),\n",
        "            'Range': clean_data.max() - clean_data.min()\n",
        "        }\n",
        "    comparison_stats.append(stats_dict)\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_stats)\n",
        "print(comparison_df.round(4))\n",
        "\n",
        "# Save comparison table\n",
        "comparison_df.to_csv('outputs/model_comparison_stats.csv', index=False)\n",
        "print(\"\\nüíæ Comparison statistics saved to outputs/model_comparison_stats.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Next Steps {#summary}\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Data Model Diversity**: LRDBenchmark provides comprehensive coverage of LRD models:\n",
        "   - **FBM/FGN**: Gaussian processes with exact Hurst parameter control\n",
        "   - **ARFIMA**: Discrete-time models with fractional differencing\n",
        "   - **MRW**: Multifractal models for complex scaling behavior\n",
        "   - **Alpha-Stable**: Heavy-tailed models for extreme events\n",
        "\n",
        "2. **Model Selection Guidelines**:\n",
        "   - **FBM/FGN**: When you need exact Hurst parameter control and Gaussian properties\n",
        "   - **ARFIMA**: For discrete-time modeling with ARMA components\n",
        "   - **MRW**: For financial time series with volatility clustering\n",
        "   - **Alpha-Stable**: For modeling extreme events and heavy tails\n",
        "\n",
        "3. **Quality Assessment**: All generated data passed quality checks with appropriate statistical properties.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Estimation**: Use the generated data with various Hurst parameter estimators\n",
        "2. **Benchmarking**: Compare estimator performance across different models\n",
        "3. **Real-world Application**: Apply to actual time series data\n",
        "4. **Custom Models**: Extend the library with domain-specific models\n",
        "\n",
        "### Files Generated\n",
        "\n",
        "- `outputs/hurst_parameter_effects.png`: Visual comparison of different H values\n",
        "- `outputs/fbm_time_series.png`: FBM time series examples\n",
        "- `outputs/comparative_analysis.png`: Side-by-side model comparison\n",
        "- `outputs/model_comparison_stats.csv`: Statistical comparison table\n",
        "\n",
        "### References\n",
        "\n",
        "1. Mandelbrot, B. B., & Van Ness, J. W. (1968). Fractional Brownian motions, fractional noises and applications. SIAM review, 10(4), 422-437.\n",
        "2. Hosking, J. R. (1981). Fractional differencing. Biometrika, 68(1), 165-176.\n",
        "3. Muzy, J. F., Bacry, E., & Arneodo, A. (1991). Wavelets and multifractal formalism for singular signals: Application to turbulence data. Physical review letters, 67(25), 3515.\n",
        "4. Samorodnitsky, G., & Taqqu, M. S. (1994). Stable non-Gaussian random processes: stochastic models with infinite variance. CRC press.\n",
        "\n",
        "---\n",
        "\n",
        "**Next Notebook**: [02_estimation_and_validation.ipynb](02_estimation_and_validation.ipynb) - Learn how to estimate Hurst parameters using various estimators.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
