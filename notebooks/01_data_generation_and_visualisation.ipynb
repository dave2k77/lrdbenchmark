{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation and Visualisation\n",
    "\n",
    "This notebook demonstrates the comprehensive data generation capabilities of the LRDBenchmark library, covering all available stochastic models for long-range dependence (LRD) analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Long-range dependence (LRD) is a statistical property where observations that are far apart in time are still correlated. This notebook covers:\n",
    "\n",
    "1. **Theoretical Background**: Understanding LRD and the Hurst parameter\n",
    "2. **Data Models**: All available stochastic processes in LRDBenchmark\n",
    "3. **Visualisation**: Comprehensive plots and analysis\n",
    "4. **Quality Assessment**: Statistical validation of generated data\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Theoretical Background](#theory)\n",
    "3. [Fractional Brownian Motion (FBM)](#fbm)\n",
    "4. [Fractional Gaussian Noise (FGN)](#fgn)\n",
    "5. [ARFIMA Processes](#arfima)\n",
    "6. [Multifractal Random Walk (MRW)](#mrw)\n",
    "7. [Alpha-Stable Processes](#alpha-stable)\n",
    "8. [Comparative Analysis](#comparison)\n",
    "9. [Data Quality Assessment](#quality)\n",
    "10. [Summary and Next Steps](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}\n",
    "\n",
    "First, let's import all necessary libraries and set up the environment for reproducible results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific computing imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, jarque_bera\n",
    "from statsmodels.tsa.stattools import adfuller, acf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LRDBenchmark imports with new GPU utilities\n",
    "from lrdbenchmark import (\n",
    "    FBMModel, FGNModel, ARFIMAModel, MRWModel, AlphaStableModel,\n",
    "    gpu_is_available, get_device_info, clear_gpu_cache, monitor_gpu_memory\n",
    ")\n",
    "\n",
    "# Check GPU availability and status\n",
    "print(\"\ud83d\udd0d Checking GPU status...\")\n",
    "if gpu_is_available():\n",
    "    device_info = get_device_info()\n",
    "    print(f\"\u2705 GPU available: {device_info}\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f  GPU not available - using CPU mode\")\n",
    "\n",
    "# Configure matplotlib for Jupyter notebooks\n",
    "%matplotlib inline\n",
    "plt.ion()  # Turn on interactive mode\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import LRDBenchmark data models\n",
    "from lrdbenchmark import FBMModel, FGNModel, ARFIMAModel, MRWModel, AlphaStableModel\n",
    "\n",
    "print(\"\u2705 All imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib backend: {plt.get_backend()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test ARFIMA generation and plotting\n",
    "print(\"\ud83e\uddea Testing ARFIMA generation and plotting...\")\n",
    "\n",
    "# Generate a small sample of ARFIMA data with valid parameters\n",
    "arfima_test = ARFIMAModel(d=0.2, ar_params=[0.5, -0.2], ma_params=[0.3, -0.1], sigma=1.0) # d = H - 0.5\n",
    "test_data = arfima_test.generate(500, seed=42)\n",
    "\n",
    "# Create a simple test plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_data, linewidth=2, alpha=0.8)\n",
    "plt.title('ARFIMA Test Plot (d=0.2, AR=[0.5, -0.2], MA=[0.3, -0.1])', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\u2705 ARFIMA test successful! Generated {len(test_data)} data points\")\n",
    "print(f\"   Mean: {test_data.mean():.4f}, Std: {test_data.std():.4f}\")\n",
    "print(\"\ud83d\udcca If you can see the plot above, matplotlib is working correctly!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theoretical Background {#theory}\n",
    "\n",
    "### Long-Range Dependence (LRD)\n",
    "\n",
    "Long-range dependence is characterised by the **Hurst parameter H**:\n",
    "\n",
    "- **H = 0.5**: No long-range dependence (standard random walk)\n",
    "- **H > 0.5**: Persistent (positive long-range dependence)\n",
    "- **H < 0.5**: Anti-persistent (negative long-range dependence)\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "1. **Self-similarity**: Statistical properties are preserved under scaling\n",
    "2. **Power-law decay**: Autocorrelation function decays as \u03c4^(2H-2)\n",
    "3. **Spectral density**: Power spectral density follows f^(1-2H) at low frequencies\n",
    "\n",
    "Let's visualise these concepts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conceptual plot showing different Hurst parameter effects\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Generate sample data for different H values\n",
    "H_values = [0.3, 0.5, 0.7, 0.9]\n",
    "colors = ['red', 'blue', 'green', 'purple']\n",
    "n_samples = 1000\n",
    "\n",
    "for i, (H, color) in enumerate(zip(H_values, colors)):\n",
    "    # Generate FBM data\n",
    "    fbm = FBMModel(H=H, sigma=1.0)\n",
    "    data = fbm.generate(n_samples, seed=42)\n",
    "    \n",
    "    # Plot time series\n",
    "    axes[0, 0].plot(data[:200], color=color, alpha=0.8, linewidth=1.5, label=f'H = {H}')\n",
    "    \n",
    "    # Plot autocorrelation function\n",
    "    acf_values = acf(data, nlags=50, fft=True)\n",
    "    axes[0, 1].plot(acf_values, color=color, alpha=0.8, linewidth=2, label=f'H = {H}')\n",
    "    \n",
    "    # Plot power spectral density\n",
    "    freqs = np.fft.fftfreq(n_samples)[:n_samples//2]\n",
    "    psd = np.abs(np.fft.fft(data))**2\n",
    "    psd = psd[:n_samples//2]\n",
    "    axes[1, 0].loglog(freqs[1:], psd[1:], color=color, alpha=0.8, linewidth=2, label=f'H = {H}')\n",
    "    \n",
    "    # Plot distribution\n",
    "    axes[1, 1].hist(data, bins=50, alpha=0.6, color=color, density=True, label=f'H = {H}')\n",
    "\n",
    "# Customize plots\n",
    "axes[0, 0].set_title('Time Series (First 200 points)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].set_title('Autocorrelation Function', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Lag')\n",
    "axes[0, 1].set_ylabel('ACF')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].set_title('Power Spectral Density', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Frequency')\n",
    "axes[1, 0].set_ylabel('PSD')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].set_title('Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/hurst_parameter_effects.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udcca Key Observations:\")\n",
    "print(\"\u2022 H < 0.5: Anti-persistent (oscillatory, mean-reverting)\")\n",
    "print(\"\u2022 H = 0.5: Standard random walk (no memory)\")\n",
    "print(\"\u2022 H > 0.5: Persistent (trending, long memory)\")\n",
    "print(\"\u2022 Higher H values show stronger long-range dependence\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fractional Brownian Motion (FBM) {#fbm}\n",
    "\n",
    "Fractional Brownian Motion is a self-similar Gaussian process with stationary increments. It's the foundation for many LRD models.\n",
    "\n",
    "### Key Properties:\n",
    "- **Self-similarity**: B_H(at) = a^H B_H(t)\n",
    "- **Gaussian increments**: All finite-dimensional distributions are Gaussian\n",
    "- **Stationary increments**: Increments are stationary but not independent\n",
    "- **Covariance**: E[B_H(s)B_H(t)] = 0.5(|s|^(2H) + |t|^(2H) - |s-t|^(2H))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate FBM data with different Hurst parameters\n",
    "print(\"\ud83d\udd0d Generating Fractional Brownian Motion data...\")\n",
    "\n",
    "H_values = [0.3, 0.5, 0.7, 0.9]\n",
    "fbm_data = {}\n",
    "n_samples = 2000\n",
    "\n",
    "for H in H_values:\n",
    "    fbm = FBMModel(H=H, sigma=1.0)\n",
    "    data = fbm.generate(n_samples, seed=42)\n",
    "    fbm_data[f'FBM_H={H}'] = data\n",
    "    \n",
    "    # Print basic statistics\n",
    "    print(f\"\\n\ud83d\udcc8 FBM with H = {H}:\")\n",
    "    print(f\"   Mean: {data.mean():.4f}\")\n",
    "    print(f\"   Std: {data.std():.4f}\")\n",
    "    print(f\"   Min: {data.min():.4f}\")\n",
    "    print(f\"   Max: {data.max():.4f}\")\n",
    "    print(f\"   Range: {data.max() - data.min():.4f}\")\n",
    "\n",
    "# Visualise FBM data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Time series plots\n",
    "for i, (name, data) in enumerate(fbm_data.items()):\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.plot(data[:500], linewidth=1.5, alpha=0.8)\n",
    "    ax.set_title(f'{name} (First 500 points)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/fbm_time_series.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Analyse theoretical properties\n",
    "print(\"\\n\ud83e\uddee Theoretical Properties Analysis:\")\n",
    "for name, data in fbm_data.items():\n",
    "    H = float(name.split('=')[1])\n",
    "    \n",
    "    # Calculate empirical properties\n",
    "    increments = np.diff(data)\n",
    "    \n",
    "    # Variance of increments (should be constant for FBM)\n",
    "    var_increments = np.var(increments)\n",
    "    \n",
    "    # Autocorrelation of increments\n",
    "    acf_increments = acf(increments, nlags=20, fft=True)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   Theoretical H: {H:.1f}\")\n",
    "    print(f\"   Variance of increments: {var_increments:.4f}\")\n",
    "    print(f\"   ACF(1): {acf_increments[1]:.4f}\")\n",
    "    print(f\"   ACF(5): {acf_increments[5]:.4f}\")\n",
    "    print(f\"   ACF(10): {acf_increments[10]:.4f}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparative Analysis {#comparison}\n",
    "\n",
    "Now let's compare all data models side by side to understand their different characteristics and use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comparative data from all models\n",
    "print(\"\ud83d\udd0d Generating comparative data from all models...\")\n",
    "\n",
    "# Use H=0.7 for all models where applicable\n",
    "H_target = 0.7\n",
    "n_samples = 1000\n",
    "\n",
    "comparative_data = {}\n",
    "\n",
    "# FBM\n",
    "fbm = FBMModel(H=H_target, sigma=1.0)\n",
    "comparative_data['FBM'] = fbm.generate(n_samples, seed=42)\n",
    "\n",
    "# FGN\n",
    "fgn = FGNModel(H=H_target, sigma=1.0)\n",
    "comparative_data['FGN'] = fgn.generate(n_samples, seed=42)\n",
    "\n",
    "# ARFIMA (d = H - 0.5 = 0.2)\n",
    "arfima = ARFIMAModel(d=0.2, ar_params=[0.3], ma_params=[0.2], sigma=1.0)\n",
    "comparative_data['ARFIMA'] = arfima.generate(n_samples, seed=42)\n",
    "\n",
    "# MRW\n",
    "mrw = MRWModel(H=H_target, lambda_param=0.2, sigma=1.0)\n",
    "comparative_data['MRW'] = mrw.generate(n_samples, seed=42)\n",
    "\n",
    "# Alpha-Stable (symmetric) - using more stable parameters\n",
    "alpha_stable = AlphaStableModel(alpha=1.8, beta=0.0, sigma=0.5, mu=0.0, method='cms')\n",
    "alpha_stable_data = alpha_stable.generate(n_samples, seed=42)\n",
    "\n",
    "# Check for NaN values and replace with finite values if needed\n",
    "if np.any(np.isnan(alpha_stable_data)) or np.any(np.isinf(alpha_stable_data)):\n",
    "    print(\"\u26a0\ufe0f Alpha-Stable model generated NaN/Inf values, using fallback parameters\")\n",
    "    alpha_stable = AlphaStableModel(alpha=1.9, beta=0.0, sigma=0.3, mu=0.0, method='cms')\n",
    "    alpha_stable_data = alpha_stable.generate(n_samples, seed=42)\n",
    "\n",
    "comparative_data['Alpha-Stable'] = alpha_stable_data\n",
    "\n",
    "# Create comprehensive comparison plot\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 18))\n",
    "\n",
    "# Define colors for consistency\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "model_names = list(comparative_data.keys())\n",
    "\n",
    "# Time series plots\n",
    "for i, (name, data) in enumerate(comparative_data.items()):\n",
    "    ax = axes[0, i]\n",
    "    ax.plot(data[:200], linewidth=1.5, alpha=0.8, color=colors[i], label=name)\n",
    "    ax.set_title(f'{name} (H\u22480.7)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "# Autocorrelation functions\n",
    "for i, (name, data) in enumerate(comparative_data.items()):\n",
    "    ax = axes[1, i]\n",
    "    acf_values = acf(data, nlags=30, fft=True)\n",
    "    ax.plot(acf_values, linewidth=2, alpha=0.8, color=colors[i], label=name)\n",
    "    ax.set_title(f'{name} ACF', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Lag')\n",
    "    ax.set_ylabel('ACF')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "# Distributions\n",
    "for i, (name, data) in enumerate(comparative_data.items()):\n",
    "    ax = axes[2, i]\n",
    "    ax.hist(data, bins=30, density=True, alpha=0.7, color=colors[i], label=name)\n",
    "    ax.set_title(f'{name} Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/comparative_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistical comparison table\n",
    "print(\"\\n\ud83d\udcca Statistical Comparison Table:\")\n",
    "comparison_stats = []\n",
    "\n",
    "for name, data in comparative_data.items():\n",
    "    # Clean data - remove NaN and infinite values\n",
    "    clean_data = data[np.isfinite(data)]\n",
    "    \n",
    "    if len(clean_data) == 0:\n",
    "        print(f\"\u26a0\ufe0f Warning: {name} contains no finite values\")\n",
    "        stats_dict = {\n",
    "            'Model': name,\n",
    "            'Mean': np.nan,\n",
    "            'Std': np.nan,\n",
    "            'Skewness': np.nan,\n",
    "            'Kurtosis': np.nan,\n",
    "            'Min': np.nan,\n",
    "            'Max': np.nan,\n",
    "            'Range': np.nan\n",
    "        }\n",
    "    else:\n",
    "        stats_dict = {\n",
    "            'Model': name,\n",
    "            'Mean': clean_data.mean(),\n",
    "            'Std': clean_data.std(),\n",
    "            'Skewness': stats.skew(clean_data) if len(clean_data) > 2 else np.nan,\n",
    "            'Kurtosis': stats.kurtosis(clean_data) if len(clean_data) > 3 else np.nan,\n",
    "            'Min': clean_data.min(),\n",
    "            'Max': clean_data.max(),\n",
    "            'Range': clean_data.max() - clean_data.min()\n",
    "        }\n",
    "    comparison_stats.append(stats_dict)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_stats)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Save comparison table\n",
    "comparison_df.to_csv('outputs/model_comparison_stats.csv', index=False)\n",
    "print(\"\\n\ud83d\udcbe Comparison statistics saved to outputs/model_comparison_stats.csv\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps {#summary}\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Data Model Diversity**: LRDBenchmark provides comprehensive coverage of LRD models:\n",
    "   - **FBM/FGN**: Gaussian processes with exact Hurst parameter control\n",
    "   - **ARFIMA**: Discrete-time models with fractional differencing\n",
    "   - **MRW**: Multifractal models for complex scaling behavior\n",
    "   - **Alpha-Stable**: Heavy-tailed models for extreme events\n",
    "\n",
    "2. **Model Selection Guidelines**:\n",
    "   - **FBM/FGN**: When you need exact Hurst parameter control and Gaussian properties\n",
    "   - **ARFIMA**: For discrete-time modeling with ARMA components\n",
    "   - **MRW**: For financial time series with volatility clustering\n",
    "   - **Alpha-Stable**: For modeling extreme events and heavy tails\n",
    "\n",
    "3. **Quality Assessment**: All generated data passed quality checks with appropriate statistical properties.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Estimation**: Use the generated data with various Hurst parameter estimators\n",
    "2. **Benchmarking**: Compare estimator performance across different models\n",
    "3. **Real-world Application**: Apply to actual time series data\n",
    "4. **Custom Models**: Extend the library with domain-specific models\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "- `outputs/hurst_parameter_effects.png`: Visual comparison of different H values\n",
    "- `outputs/fbm_time_series.png`: FBM time series examples\n",
    "- `outputs/comparative_analysis.png`: Side-by-side model comparison\n",
    "- `outputs/model_comparison_stats.csv`: Statistical comparison table\n",
    "\n",
    "### References\n",
    "\n",
    "1. Mandelbrot, B. B., & Van Ness, J. W. (1968). Fractional Brownian motions, fractional noises and applications. SIAM review, 10(4), 422-437.\n",
    "2. Hosking, J. R. (1981). Fractional differencing. Biometrika, 68(1), 165-176.\n",
    "3. Muzy, J. F., Bacry, E., & Arneodo, A. (1991). Wavelets and multifractal formalism for singular signals: Application to turbulence data. Physical review letters, 67(25), 3515.\n",
    "4. Samorodnitsky, G., & Taqqu, M. S. (1994). Stable non-Gaussian random processes: stochastic models with infinite variance. CRC press.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Notebook**: [02_estimation_and_validation.ipynb](02_estimation_and_validation.ipynb) - Learn how to estimate Hurst parameters using various estimators.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}