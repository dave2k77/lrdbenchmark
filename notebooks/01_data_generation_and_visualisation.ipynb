{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation and Visualisation\n",
    "\n",
    "This notebook demonstrates the comprehensive data generation capabilities of the LRDBenchmark library, covering all available stochastic models for long-range dependence (LRD) analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Long-range dependence (LRD) is a statistical property where observations that are far apart in time are still correlated. This notebook covers:\n",
    "\n",
    "1. **Theoretical Background**: Understanding LRD and the Hurst parameter\n",
    "2. **Data Models**: All available stochastic processes in LRDBenchmark\n",
    "3. **Visualisation**: Comprehensive plots and analysis\n",
    "4. **Quality Assessment**: Statistical validation of generated data\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Theoretical Background](#theory)\n",
    "3. [Fractional Brownian Motion (FBM)](#fbm)\n",
    "4. [Fractional Gaussian Noise (FGN)](#fgn)\n",
    "5. [ARFIMA Processes](#arfima)\n",
    "6. [Multifractal Random Walk (MRW)](#mrw)\n",
    "7. [Alpha-Stable Processes](#alpha-stable)\n",
    "8. [Comparative Analysis](#comparison)\n",
    "9. [Data Quality Assessment](#quality)\n",
    "10. [Summary and Next Steps](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}\n",
    "\n",
    "First, let's import all necessary libraries and set up the environment for reproducible results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d Checking GPU status...\n",
      "\u2705 GPU available: {'available': True, 'device_count': 1, 'device_name': 'NVIDIA GeForce RTX 5070 Laptop GPU', 'memory_total': 7.525390625, 'memory_allocated': 0.0, 'memory_free': 7.525390625}\n",
      "\u2705 All imports successful!\n",
      "NumPy version: 2.3.3\n",
      "Pandas version: 2.3.3\n",
      "Matplotlib backend: inline\n"
     ]
    }
   ],
   "source": [
    "# Standard scientific computing imports",
    "import numpy as np",
    "import pandas as pd",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "from scipy import stats",
    "from scipy.stats import normaltest, jarque_bera",
    "from statsmodels.tsa.stattools import adfuller, acf",
    "import warnings",
    "warnings.filterwarnings('ignore')",
    "",
    "# LRDBenchmark imports with new GPU utilities",
    "from lrdbenchmark import (",
    "    FBMModel, FGNModel, ARFIMAModel, MRWModel, AlphaStableModel,",
    "    gpu_is_available, get_device_info, clear_gpu_cache, monitor_gpu_memory",
    ")",
    "",
    "# Check GPU availability and status",
    "print(\"\ud83d\udd0d Checking GPU status...\")",
    "if gpu_is_available():",
    "    device_info = get_device_info()",
    "    print(f\"\u2705 GPU available: {device_info}\")",
    "else:",
    "    print(\"\u2139\ufe0f  GPU not available - using CPU mode\")",
    "",
    "# Configure matplotlib for Jupyter notebooks",
    "%matplotlib inline",
    "plt.ion()  # Turn on interactive mode",
    "",
    "# Set up plotting style",
    "plt.style.use('seaborn-v0_8')",
    "sns.set_palette(\"husl\")",
    "plt.rcParams['figure.figsize'] = (12, 8)",
    "plt.rcParams['font.size'] = 12",
    "",
    "# Set random seed for reproducibility",
    "np.random.seed(42)",
    "",
    "# Import LRDBenchmark data models",
    "from lrdbenchmark import FBMModel, FGNModel, ARFIMAModel, MRWModel, AlphaStableModel",
    "",
    "print(\"\u2705 All imports successful!\")",
    "print(f\"NumPy version: {np.__version__}\")",
    "print(f\"Pandas version: {pd.__version__}\")",
    "print(f\"Matplotlib backend: {plt.get_backend()}\")",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83e\uddea Testing ARFIMA generation and plotting...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lengthp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\ud83e\uddea Testing ARFIMA generation and plotting...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Generate a small sample of ARFIMA data with valid parameters\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m arfima_test = \u001b[43mARFIMAModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mma_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# d = H - 0.5\u001b[39;00m\n\u001b[32m      6\u001b[39m test_data = arfima_test.generate(\u001b[32m500\u001b[39m, seed=\u001b[32m42\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Create a simple test plot\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LRDBenchmark/lrdbenchmark/models/data_models/arfima/arfima_model.py:68\u001b[39m, in \u001b[36mARFIMAModel.__init__\u001b[39m\u001b[34m(self, d, ar_params, ma_params, sigma, method)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ma_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     66\u001b[39m     ma_params = []\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43md\u001b[49m\u001b[43m=\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mar_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mma_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mma_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LRDBenchmark/lrdbenchmark/models/data_models/base_model.py:32\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03mInitialize the base model.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[33;03m    Model-specific parameters\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m.parameters = kwargs\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LRDBenchmark/lrdbenchmark/models/data_models/arfima/arfima_model.py:93\u001b[39m, in \u001b[36mARFIMAModel._validate_parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     90\u001b[39m     ar_poly = np.poly1d([\u001b[32m1\u001b[39m] + [-x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ar_params])\n\u001b[32m     91\u001b[39m     roots = ar_poly.roots\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m         \u001b[43mlengthp\u001b[49m.abs(roots) >= \u001b[32m1\u001b[39m - \u001b[32m1e-10\u001b[39m\n\u001b[32m     94\u001b[39m     ):  \u001b[38;5;66;03m# Roots must be inside unit circle for stationarity\u001b[39;00m\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAR parameters must satisfy stationarity conditions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Check MA polynomial invertibility\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'lengthp' is not defined"
     ]
    }
   ],
   "source": [
    "# Test ARFIMA generation and plotting",
    "print(\"\ud83e\uddea Testing ARFIMA generation and plotting...\")",
    "",
    "# Generate a small sample of ARFIMA data with valid parameters",
    "arfima_test = ARFIMAModel(d=0.2, ar_params=[0.5, -0.2], ma_params=[0.3, -0.1], sigma=1.0) # d = H - 0.5",
    "test_data = arfima_test.generate(length=500, seed=42)",
    "",
    "# Create a simple test plot",
    "plt.figure(figsize=(10, 6))",
    "plt.plot(test_data, linewidth=2, alpha=0.8)",
    "plt.title('ARFIMA Test Plot (d=0.2, AR=[0.5, -0.2], MA=[0.3, -0.1])', fontsize=14, fontweight='bold')",
    "plt.xlabel('Time')",
    "plt.ylabel('Value')",
    "plt.grid(True, alpha=0.3)",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(f\"\u2705 ARFIMA test successful! Generated {len(test_data)} data points\")",
    "print(f\"   Mean: {test_data.mean():.4f}, Std: {test_data.std():.4f}\")",
    "print(\"\ud83d\udcca If you can see the plot above, matplotlib is working correctly!\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theoretical Background {#theory}\n",
    "\n",
    "### Long-Range Dependence (LRD)\n",
    "\n",
    "Long-range dependence is characterised by the **Hurst parameter H**:\n",
    "\n",
    "- **H = 0.5**: No long-range dependence (standard random walk)\n",
    "- **H > 0.5**: Persistent (positive long-range dependence)\n",
    "- **H < 0.5**: Anti-persistent (negative long-range dependence)\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "1. **Self-similarity**: Statistical properties are preserved under scaling\n",
    "2. **Power-law decay**: Autocorrelation function decays as \u03c4^(2H-2)\n",
    "3. **Spectral density**: Power spectral density follows f^(1-2H) at low frequencies\n",
    "\n",
    "Let's visualise these concepts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conceptual plot showing different Hurst parameter effects",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))",
    "",
    "# Generate sample data for different H values",
    "H_values = [0.3, 0.5, 0.7, 0.9]",
    "colors = ['red', 'blue', 'green', 'purple']",
    "n_samples = 1000",
    "",
    "for i, (H, color) in enumerate(zip(H_values, colors)):",
    "    # Generate FBM data",
    "    fbm = FBMModel(H=H, sigma=1.0)",
    "    data = fbm.generate(length=n_samples, seed=42)",
    "    ",
    "    # Plot time series",
    "    axes[0, 0].plot(data[:200], color=color, alpha=0.8, linewidth=1.5, label=f'H = {H}')",
    "    ",
    "    # Plot autocorrelation function",
    "    acf_values = acf(data, nlags=50, fft=True)",
    "    axes[0, 1].plot(acf_values, color=color, alpha=0.8, linewidth=2, label=f'H = {H}')",
    "    ",
    "    # Plot power spectral density",
    "    freqs = np.fft.fftfreq(n_samples)[:n_samples//2]",
    "    psd = np.abs(np.fft.fft(data))**2",
    "    psd = psd[:n_samples//2]",
    "    axes[1, 0].loglog(freqs[1:], psd[1:], color=color, alpha=0.8, linewidth=2, label=f'H = {H}')",
    "    ",
    "    # Plot distribution",
    "    axes[1, 1].hist(data, bins=50, alpha=0.6, color=color, density=True, label=f'H = {H}')",
    "",
    "# Customize plots",
    "axes[0, 0].set_title('Time Series (First 200 points)', fontsize=14, fontweight='bold')",
    "axes[0, 0].set_xlabel('Time')",
    "axes[0, 0].set_ylabel('Value')",
    "axes[0, 0].legend()",
    "axes[0, 0].grid(True, alpha=0.3)",
    "",
    "axes[0, 1].set_title('Autocorrelation Function', fontsize=14, fontweight='bold')",
    "axes[0, 1].set_xlabel('Lag')",
    "axes[0, 1].set_ylabel('ACF')",
    "axes[0, 1].legend()",
    "axes[0, 1].grid(True, alpha=0.3)",
    "",
    "axes[1, 0].set_title('Power Spectral Density', fontsize=14, fontweight='bold')",
    "axes[1, 0].set_xlabel('Frequency')",
    "axes[1, 0].set_ylabel('PSD')",
    "axes[1, 0].legend()",
    "axes[1, 0].grid(True, alpha=0.3)",
    "",
    "axes[1, 1].set_title('Distribution', fontsize=14, fontweight='bold')",
    "axes[1, 1].set_xlabel('Value')",
    "axes[1, 1].set_ylabel('Density')",
    "axes[1, 1].legend()",
    "axes[1, 1].grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.savefig('outputs/hurst_parameter_effects.png', dpi=300, bbox_inches='tight')",
    "plt.show()",
    "",
    "print(\"\ud83d\udcca Key Observations:\")",
    "print(\"\u2022 H < 0.5: Anti-persistent (oscillatory, mean-reverting)\")",
    "print(\"\u2022 H = 0.5: Standard random walk (no memory)\")",
    "print(\"\u2022 H > 0.5: Persistent (trending, long memory)\")",
    "print(\"\u2022 Higher H values show stronger long-range dependence\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fractional Brownian Motion (FBM) {#fbm}\n",
    "\n",
    "Fractional Brownian Motion is a self-similar Gaussian process with stationary increments. It's the foundation for many LRD models.\n",
    "\n",
    "### Key Properties:\n",
    "- **Self-similarity**: B_H(at) = a^H B_H(t)\n",
    "- **Gaussian increments**: All finite-dimensional distributions are Gaussian\n",
    "- **Stationary increments**: Increments are stationary but not independent\n",
    "- **Covariance**: E[B_H(s)B_H(t)] = 0.5(|s|^(2H) + |t|^(2H) - |s-t|^(2H))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate FBM data with different Hurst parameters",
    "print(\"\ud83d\udd0d Generating Fractional Brownian Motion data...\")",
    "",
    "H_values = [0.3, 0.5, 0.7, 0.9]",
    "fbm_data = {}",
    "n_samples = 2000",
    "",
    "for H in H_values:",
    "    fbm = FBMModel(H=H, sigma=1.0)",
    "    data = fbm.generate(length=n_samples, seed=42)",
    "    fbm_data[f'FBM_H={H}'] = data",
    "    ",
    "    # Print basic statistics",
    "    print(f\"\\n\ud83d\udcc8 FBM with H = {H}:\")",
    "    print(f\"   Mean: {data.mean():.4f}\")",
    "    print(f\"   Std: {data.std():.4f}\")",
    "    print(f\"   Min: {data.min():.4f}\")",
    "    print(f\"   Max: {data.max():.4f}\")",
    "    print(f\"   Range: {data.max() - data.min():.4f}\")",
    "",
    "# Visualise FBM data",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))",
    "",
    "# Time series plots",
    "for i, (name, data) in enumerate(fbm_data.items()):",
    "    ax = axes[i//2, i%2]",
    "    ax.plot(data[:500], linewidth=1.5, alpha=0.8)",
    "    ax.set_title(f'{name} (First 500 points)', fontsize=12, fontweight='bold')",
    "    ax.set_xlabel('Time')",
    "    ax.set_ylabel('Value')",
    "    ax.grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.savefig('outputs/fbm_time_series.png', dpi=300, bbox_inches='tight')",
    "plt.show()",
    "",
    "# Analyse theoretical properties",
    "print(\"\\n\ud83e\uddee Theoretical Properties Analysis:\")",
    "for name, data in fbm_data.items():",
    "    H = float(name.split('=')[1])",
    "    ",
    "    # Calculate empirical properties",
    "    increments = np.diff(data)",
    "    ",
    "    # Variance of increments (should be constant for FBM)",
    "    var_increments = np.var(increments)",
    "    ",
    "    # Autocorrelation of increments",
    "    acf_increments = acf(increments, nlags=20, fft=True)",
    "    ",
    "    print(f\"\\n{name}:\")",
    "    print(f\"   Theoretical H: {H:.1f}\")",
    "    print(f\"   Variance of increments: {var_increments:.4f}\")",
    "    print(f\"   ACF(1): {acf_increments[1]:.4f}\")",
    "    print(f\"   ACF(5): {acf_increments[5]:.4f}\")",
    "    print(f\"   ACF(10): {acf_increments[10]:.4f}\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparative Analysis {#comparison}\n",
    "\n",
    "Now let's compare all data models side by side to understand their different characteristics and use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comparative data from all models",
    "print(\"\ud83d\udd0d Generating comparative data from all models...\")",
    "",
    "# Use H=0.7 for all models where applicable",
    "H_target = 0.7",
    "n_samples = 1000",
    "",
    "comparative_data = {}",
    "",
    "# FBM",
    "fbm = FBMModel(H=H_target, sigma=1.0)",
    "comparative_data['FBM'] = fbm.generate(length=n_samples, seed=42)",
    "",
    "# FGN",
    "fgn = FGNModel(H=H_target, sigma=1.0)",
    "comparative_data['FGN'] = fgn.generate(length=n_samples, seed=42)",
    "",
    "# ARFIMA (d = H - 0.5 = 0.2)",
    "arfima = ARFIMAModel(d=0.2, ar_params=[0.3], ma_params=[0.2], sigma=1.0)",
    "comparative_data['ARFIMA'] = arfima.generate(length=n_samples, seed=42)",
    "",
    "# MRW",
    "mrw = MRWModel(H=H_target, lambda_param=0.2, sigma=1.0)",
    "comparative_data['MRW'] = mrw.generate(length=n_samples, seed=42)",
    "",
    "# Alpha-Stable (symmetric) - using more stable parameters",
    "alpha_stable = AlphaStableModel(alpha=1.8, beta=0.0, sigma=0.5, mu=0.0, method='cms')",
    "alpha_stable_data = alpha_stable.generate(length=n_samples, seed=42)",
    "",
    "# Check for NaN values and replace with finite values if needed",
    "if np.any(np.isnan(alpha_stable_data)) or np.any(np.isinf(alpha_stable_data)):",
    "    print(\"\u26a0\ufe0f Alpha-Stable model generated NaN/Inf values, using fallback parameters\")",
    "    alpha_stable = AlphaStableModel(alpha=1.9, beta=0.0, sigma=0.3, mu=0.0, method='cms')",
    "    alpha_stable_data = alpha_stable.generate(length=n_samples, seed=42)",
    "",
    "comparative_data['Alpha-Stable'] = alpha_stable_data",
    "",
    "# Create comprehensive comparison plot",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 18))",
    "",
    "# Define colors for consistency",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']",
    "model_names = list(comparative_data.keys())",
    "",
    "# Time series plots",
    "for i, (name, data) in enumerate(comparative_data.items()):",
    "    ax = axes[0, i]",
    "    ax.plot(data[:200], linewidth=1.5, alpha=0.8, color=colors[i], label=name)",
    "    ax.set_title(f'{name} (H\u22480.7)', fontsize=12, fontweight='bold')",
    "    ax.set_xlabel('Time')",
    "    ax.set_ylabel('Value')",
    "    ax.grid(True, alpha=0.3)",
    "    ax.legend()",
    "",
    "# Autocorrelation functions",
    "for i, (name, data) in enumerate(comparative_data.items()):",
    "    ax = axes[1, i]",
    "    acf_values = acf(data, nlags=30, fft=True)",
    "    ax.plot(acf_values, linewidth=2, alpha=0.8, color=colors[i], label=name)",
    "    ax.set_title(f'{name} ACF', fontsize=12, fontweight='bold')",
    "    ax.set_xlabel('Lag')",
    "    ax.set_ylabel('ACF')",
    "    ax.grid(True, alpha=0.3)",
    "    ax.legend()",
    "",
    "# Distributions",
    "for i, (name, data) in enumerate(comparative_data.items()):",
    "    ax = axes[2, i]",
    "    ax.hist(data, bins=30, density=True, alpha=0.7, color=colors[i], label=name)",
    "    ax.set_title(f'{name} Distribution', fontsize=12, fontweight='bold')",
    "    ax.set_xlabel('Value')",
    "    ax.set_ylabel('Density')",
    "    ax.grid(True, alpha=0.3)",
    "    ax.legend()",
    "",
    "plt.tight_layout()",
    "plt.savefig('outputs/comparative_analysis.png', dpi=300, bbox_inches='tight')",
    "plt.show()",
    "",
    "# Statistical comparison table",
    "print(\"\\n\ud83d\udcca Statistical Comparison Table:\")",
    "comparison_stats = []",
    "",
    "for name, data in comparative_data.items():",
    "    # Clean data - remove NaN and infinite values",
    "    clean_data = data[np.isfinite(data)]",
    "    ",
    "    if len(clean_data) == 0:",
    "        print(f\"\u26a0\ufe0f Warning: {name} contains no finite values\")",
    "        stats_dict = {",
    "            'Model': name,",
    "            'Mean': np.nan,",
    "            'Std': np.nan,",
    "            'Skewness': np.nan,",
    "            'Kurtosis': np.nan,",
    "            'Min': np.nan,",
    "            'Max': np.nan,",
    "            'Range': np.nan",
    "        }",
    "    else:",
    "        stats_dict = {",
    "            'Model': name,",
    "            'Mean': clean_data.mean(),",
    "            'Std': clean_data.std(),",
    "            'Skewness': stats.skew(clean_data) if len(clean_data) > 2 else np.nan,",
    "            'Kurtosis': stats.kurtosis(clean_data) if len(clean_data) > 3 else np.nan,",
    "            'Min': clean_data.min(),",
    "            'Max': clean_data.max(),",
    "            'Range': clean_data.max() - clean_data.min()",
    "        }",
    "    comparison_stats.append(stats_dict)",
    "",
    "comparison_df = pd.DataFrame(comparison_stats)",
    "print(comparison_df.round(4))",
    "",
    "# Save comparison table",
    "comparison_df.to_csv('outputs/model_comparison_stats.csv', index=False)",
    "print(\"\\n\ud83d\udcbe Comparison statistics saved to outputs/model_comparison_stats.csv\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps {#summary}\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Data Model Diversity**: LRDBenchmark provides comprehensive coverage of LRD models:\n",
    "   - **FBM/FGN**: Gaussian processes with exact Hurst parameter control\n",
    "   - **ARFIMA**: Discrete-time models with fractional differencing\n",
    "   - **MRW**: Multifractal models for complex scaling behavior\n",
    "   - **Alpha-Stable**: Heavy-tailed models for extreme events\n",
    "\n",
    "2. **Model Selection Guidelines**:\n",
    "   - **FBM/FGN**: When you need exact Hurst parameter control and Gaussian properties\n",
    "   - **ARFIMA**: For discrete-time modeling with ARMA components\n",
    "   - **MRW**: For financial time series with volatility clustering\n",
    "   - **Alpha-Stable**: For modeling extreme events and heavy tails\n",
    "\n",
    "3. **Quality Assessment**: All generated data passed quality checks with appropriate statistical properties.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Estimation**: Use the generated data with various Hurst parameter estimators\n",
    "2. **Benchmarking**: Compare estimator performance across different models\n",
    "3. **Real-world Application**: Apply to actual time series data\n",
    "4. **Custom Models**: Extend the library with domain-specific models\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "- `outputs/hurst_parameter_effects.png`: Visual comparison of different H values\n",
    "- `outputs/fbm_time_series.png`: FBM time series examples\n",
    "- `outputs/comparative_analysis.png`: Side-by-side model comparison\n",
    "- `outputs/model_comparison_stats.csv`: Statistical comparison table\n",
    "\n",
    "### References\n",
    "\n",
    "1. Mandelbrot, B. B., & Van Ness, J. W. (1968). Fractional Brownian motions, fractional noises and applications. SIAM review, 10(4), 422-437.\n",
    "2. Hosking, J. R. (1981). Fractional differencing. Biometrika, 68(1), 165-176.\n",
    "3. Muzy, J. F., Bacry, E., & Arneodo, A. (1991). Wavelets and multifractal formalism for singular signals: Application to turbulence data. Physical review letters, 67(25), 3515.\n",
    "4. Samorodnitsky, G., & Taqqu, M. S. (1994). Stable non-Gaussian random processes: stochastic models with infinite variance. CRC press.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Notebook**: [02_estimation_and_validation.ipynb](02_estimation_and_validation.ipynb) - Learn how to estimate Hurst parameters using various estimators.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}