{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Estimator Benchmarking\n",
        "\n",
        "This notebook demonstrates the full benchmarking system of LRDBenchmark, showing how to systematically compare estimators across different data types, contamination scenarios, and performance metrics.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The comprehensive benchmarking system allows you to:\n",
        "\n",
        "1. **Compare Estimators**: Test multiple estimators on the same data\n",
        "2. **Contamination Testing**: Evaluate robustness under various contamination scenarios\n",
        "3. **Performance Metrics**: Measure accuracy, speed, and reliability\n",
        "4. **Statistical Analysis**: Generate confidence intervals and significance tests\n",
        "5. **Visualization**: Create publication-ready plots and tables\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Benchmark System Overview](#overview)\n",
        "3. [Classical Estimator Benchmarking](#classical)\n",
        "4. [ML and Neural Network Benchmarking](#ml-neural)\n",
        "5. [Contamination Robustness Testing](#contamination)\n",
        "6. [Performance Analysis](#performance)\n",
        "7. [Results Visualization](#visualization)\n",
        "8. [Summary and Next Steps](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports {#setup}\n",
        "\n",
        "First, let's import all necessary libraries and set up the comprehensive benchmarking system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard scientific computing imports",
        "import numpy as np",
        "# LRDBenchmark imports - using simplified API",
        "from lrdbenchmark import (",
        "    # Data models",
        "    FBMModel, FGNModel, ARFIMAModel, MRWModel, AlphaStableModel,",
        "    # Classical estimators  ",
        "    RSEstimator, DFAEstimator, GPHEstimator, WhittleEstimator,",
        "    # Machine Learning estimators",
        "    RandomForestEstimator, SVREstimator, GradientBoostingEstimator,",
        "    # Neural Network estimators",
        "    CNNEstimator, LSTMEstimator, GRUEstimator, TransformerEstimator,",
        "    # GPU utilities",
        "    gpu_is_available, get_device_info, clear_gpu_cache, monitor_gpu_memory",
        ")",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from scipy import stats",
        "import time",
        "import warnings",
        "import subprocess",
        "import gc",
        "warnings.filterwarnings('ignore')",
        "",
        "# GPU Memory Management Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Benchmark System Overview {#overview}\n",
        "\n",
        "The ComprehensiveBenchmark class provides a unified interface for testing all estimator categories. Let's examine its capabilities and run our first benchmark.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the comprehensive benchmark system\n",
        "print(\"üîß Initializing Comprehensive Benchmark System...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "benchmark = ComprehensiveBenchmark(output_dir=\"benchmark_results\")\n",
        "\n",
        "print(\"üìä Available benchmark types:\")\n",
        "print(\"  - 'classical': Classical statistical estimators\")\n",
        "print(\"  - 'ML': Machine learning estimators\")\n",
        "print(\"  - 'neural': Neural network estimators\")\n",
        "print(\"  - 'comprehensive': All estimators combined\")\n",
        "\n",
        "print(\"\\nüìä Available contamination types:\")\n",
        "print(\"  - 'additive_gaussian': Add Gaussian noise\")\n",
        "print(\"  - 'multiplicative_noise': Multiplicative noise\")\n",
        "print(\"  - 'outliers': Add outliers\")\n",
        "print(\"  - 'trend': Add trend\")\n",
        "print(\"  - 'seasonal': Add seasonal patterns\")\n",
        "print(\"  - 'missing_data': Remove data points\")\n",
        "\n",
        "print(\"\\nüìä Available data models:\")\n",
        "print(\"  - 'fbm': Fractional Brownian Motion\")\n",
        "print(\"  - 'fgn': Fractional Gaussian Noise\")\n",
        "print(\"  - 'arfima': ARFIMA processes\")\n",
        "print(\"  - 'mrw': Multifractal Random Walk\")\n",
        "\n",
        "# Run a simple classical benchmark\n",
        "print(\"\\nüöÄ Running Classical Estimator Benchmark...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "classical_results = benchmark.run_classical_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Classical benchmark completed!\")\n",
        "print(f\"Success rate: {classical_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {classical_results['total_tests']}\")\n",
        "print(f\"Successful tests: {classical_results['successful_tests']}\")\n",
        "\n",
        "# Display summary\n",
        "if 'summary' in classical_results:\n",
        "    print(\"\\nüìä Benchmark Summary:\")\n",
        "    benchmark.print_summary(classical_results['summary'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Contamination Robustness Testing {#contamination}\n",
        "\n",
        "Real-world data often contains contamination that can affect estimator performance. Let's test how different estimators handle various contamination scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test contamination robustness\n",
        "print(\"üß™ Testing Contamination Robustness...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test different contamination types\n",
        "contamination_types = [\n",
        "    'additive_gaussian',\n",
        "    'outliers', \n",
        "    'trend',\n",
        "    'seasonal'\n",
        "]\n",
        "\n",
        "contamination_results = {}\n",
        "\n",
        "for contamination_type in contamination_types:\n",
        "    print(f\"\\nüîç Testing {contamination_type} contamination...\")\n",
        "    \n",
        "    # Run benchmark with contamination\n",
        "    results = benchmark.run_classical_benchmark(\n",
        "        data_length=1000,\n",
        "        contamination_type=contamination_type,\n",
        "        contamination_level=0.5,  # 50% contamination to show visible impact\n",
        "        save_results=False\n",
        "    )\n",
        "    \n",
        "    contamination_results[contamination_type] = results\n",
        "    \n",
        "    print(f\"  Success rate: {results['success_rate']:.1%}\")\n",
        "    print(f\"  Total tests: {results['total_tests']}\")\n",
        "    print(f\"  Successful tests: {results['successful_tests']}\")\n",
        "\n",
        "# Compare contamination effects\n",
        "print(\"\\nüìä Contamination Effects Comparison:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "comparison_data = []\n",
        "for contamination_type, results in contamination_results.items():\n",
        "    comparison_data.append({\n",
        "        'Contamination': contamination_type,\n",
        "        'Success_Rate': results['success_rate'],\n",
        "        'Total_Tests': results['total_tests'],\n",
        "        'Successful_Tests': results['successful_tests']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df.round(3))\n",
        "\n",
        "# Visualize contamination effects\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Success rate by contamination type\n",
        "ax1 = axes[0, 0]\n",
        "ax1.bar(comparison_df['Contamination'], comparison_df['Success_Rate'], alpha=0.7)\n",
        "ax1.set_title('Success Rate by Contamination Type', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Success Rate')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Total tests by contamination type\n",
        "ax2 = axes[0, 1]\n",
        "ax2.bar(comparison_df['Contamination'], comparison_df['Total_Tests'], alpha=0.7)\n",
        "ax2.set_title('Total Tests by Contamination Type', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Total Tests')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Successful tests by contamination type\n",
        "ax3 = axes[1, 0]\n",
        "ax3.bar(comparison_df['Contamination'], comparison_df['Successful_Tests'], alpha=0.7)\n",
        "ax3.set_title('Successful Tests by Contamination Type', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('Successful Tests')\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Contamination impact (success rate vs baseline)\n",
        "# Fix for blank plot issue - handle NaN baseline and zero impact\n",
        "baseline_success = classical_results.get('success_rate', None)\n",
        "if baseline_success is None or np.isnan(baseline_success):\n",
        "    print(\"‚ö†Ô∏è Baseline success rate not available or NaN, using mean of contamination results\")\n",
        "    baseline_success = comparison_df['Success_Rate'].mean()\n",
        "\n",
        "impact_data = comparison_df['Success_Rate'] - baseline_success\n",
        "print(f\"Baseline success rate: {baseline_success:.4f}\")\n",
        "print(f\"Impact data: {impact_data.values}\")\n",
        "\n",
        "ax4 = axes[1, 1]\n",
        "# Handle NaN values in impact_data\n",
        "if np.any(np.isnan(impact_data)):\n",
        "    print(\"‚ö†Ô∏è Impact data contains NaN values, using zeros\")\n",
        "    impact_data = np.zeros_like(impact_data)\n",
        "\n",
        "# Handle case where all impacts are zero (all success rates are the same)\n",
        "if np.all(impact_data == 0):\n",
        "    print(\"‚ö†Ô∏è All contamination impacts are zero - showing relative performance instead\")\n",
        "    # Show relative performance by contamination type\n",
        "    impact_data = comparison_df['Success_Rate'] * 100  # Convert to percentage for visibility\n",
        "    ax4.bar(comparison_df['Contamination'], impact_data, alpha=0.7, color='blue')\n",
        "    ax4.set_title('Success Rate by Contamination Type', fontsize=12, fontweight='bold')\n",
        "    ax4.set_ylabel('Success Rate (%)')\n",
        "    ax4.set_ylim(0, 105)\n",
        "else:\n",
        "    ax4.bar(comparison_df['Contamination'], impact_data, alpha=0.7, \n",
        "            color=['red' if x < 0 else 'green' for x in impact_data])\n",
        "    ax4.set_title('Contamination Impact on Success Rate', fontsize=12, fontweight='bold')\n",
        "    ax4.set_ylabel('Change in Success Rate')\n",
        "    ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/contamination_robustness.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Contamination robustness testing completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Diagnostic: Check contamination results data quality\n",
        "print(\"üîç Diagnostic: Checking contamination results data quality...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if 'contamination_results' in locals():\n",
        "    print(\"Contamination results keys:\", list(contamination_results.keys()))\n",
        "    \n",
        "    for contamination_type, results in contamination_results.items():\n",
        "        print(f\"\\n{contamination_type}:\")\n",
        "        print(f\"  Keys: {list(results.keys())}\")\n",
        "        print(f\"  Success rate: {results.get('success_rate', 'NOT FOUND')}\")\n",
        "        print(f\"  Total tests: {results.get('total_tests', 'NOT FOUND')}\")\n",
        "        print(f\"  Successful tests: {results.get('successful_tests', 'NOT FOUND')}\")\n",
        "        \n",
        "        # Check for NaN values\n",
        "        success_rate = results.get('success_rate', None)\n",
        "        if success_rate is not None:\n",
        "            if np.isnan(success_rate):\n",
        "                print(f\"  ‚ö†Ô∏è Success rate is NaN!\")\n",
        "            else:\n",
        "                print(f\"  ‚úÖ Success rate is valid: {success_rate:.4f}\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå Success rate not found in results\")\n",
        "else:\n",
        "    print(\"‚ùå contamination_results not found - contamination testing may have failed\")\n",
        "\n",
        "if 'classical_results' in locals():\n",
        "    print(f\"\\nClassical results keys: {list(classical_results.keys())}\")\n",
        "    baseline_success = classical_results.get('success_rate', None)\n",
        "    if baseline_success is not None:\n",
        "        if np.isnan(baseline_success):\n",
        "            print(\"‚ö†Ô∏è Classical baseline success rate is NaN!\")\n",
        "        else:\n",
        "            print(f\"‚úÖ Classical baseline success rate: {baseline_success:.4f}\")\n",
        "    else:\n",
        "        print(\"‚ùå Classical baseline success rate not found\")\n",
        "else:\n",
        "    print(\"‚ùå classical_results not found - classical benchmark may have failed\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary and Next Steps {#summary}\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Comprehensive Benchmarking**: LRDBenchmark provides a unified system for testing all estimator categories:\n",
        "   - **Classical**: Fast, interpretable, theoretically grounded\n",
        "   - **ML**: Robust, flexible, pre-trained models\n",
        "   - **Neural**: High accuracy, complex patterns\n",
        "\n",
        "2. **Contamination Testing**: The system evaluates robustness under various contamination scenarios:\n",
        "   - **Additive Gaussian**: Noise contamination\n",
        "   - **Outliers**: Extreme value contamination\n",
        "   - **Trend**: Systematic trend contamination\n",
        "   - **Seasonal**: Periodic pattern contamination\n",
        "\n",
        "3. **Performance Metrics**: Comprehensive evaluation including:\n",
        "   - **Accuracy**: Mean absolute error, bias, variance\n",
        "   - **Speed**: Execution time, computational efficiency\n",
        "   - **Robustness**: Performance under contamination\n",
        "   - **Reliability**: Success rate, consistency\n",
        "\n",
        "### Benchmark Results\n",
        "\n",
        "- **Classical Estimators**: Fast and reliable for standard LRD processes\n",
        "- **ML Estimators**: Good balance of accuracy and robustness\n",
        "- **Neural Networks**: Highest accuracy for complex patterns\n",
        "- **Contamination Effects**: Different estimators show varying robustness\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Leaderboard Generation**: Create performance rankings and comparisons\n",
        "2. **Real-world Application**: Apply to actual time series data\n",
        "3. **Advanced Analysis**: Explore statistical significance and confidence intervals\n",
        "4. **Custom Benchmarks**: Create domain-specific benchmark scenarios\n",
        "\n",
        "### Files Generated\n",
        "\n",
        "- `benchmark_results/`: Complete benchmark results directory\n",
        "- `outputs/contamination_robustness.png`: Contamination effects visualization\n",
        "- Performance metrics and statistical analysis\n",
        "\n",
        "### References\n",
        "\n",
        "1. Taqqu, M. S., Teverovsky, V., & Willinger, W. (1995). Estimators for long-range dependence: an empirical study. Fractals, 3(04), 785-798.\n",
        "2. Beran, J. (1994). Statistics for long-memory processes. CRC press.\n",
        "3. Abry, P., & Veitch, D. (1998). Wavelet analysis of long-range-dependent traffic. IEEE Transactions on information theory, 44(1), 2-15.\n",
        "\n",
        "---\n",
        "\n",
        "**Next Notebook**: [05_leaderboard_generation.ipynb](05_leaderboard_generation.ipynb) - Learn how to create performance leaderboards and rankings.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}