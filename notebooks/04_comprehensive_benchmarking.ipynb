{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Estimator Benchmarking\n",
        "\n",
        "This notebook demonstrates the full benchmarking system of LRDBenchmark, showing how to systematically compare estimators across different data types, contamination scenarios, and performance metrics.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The comprehensive benchmarking system allows you to:\n",
        "\n",
        "1. **Compare Estimators**: Test multiple estimators on the same data\n",
        "2. **Contamination Testing**: Evaluate robustness under various contamination scenarios\n",
        "3. **Performance Metrics**: Measure accuracy, speed, and reliability\n",
        "4. **Statistical Analysis**: Generate confidence intervals and significance tests\n",
        "5. **Visualization**: Create publication-ready plots and tables\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Benchmark System Overview](#overview)\n",
        "3. [Classical Estimator Benchmarking](#classical)\n",
        "4. [ML and Neural Network Benchmarking](#ml-neural)\n",
        "5. [Contamination Robustness Testing](#contamination)\n",
        "6. [Performance Analysis](#performance)\n",
        "7. [Results Visualization](#visualization)\n",
        "8. [Summary and Next Steps](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports {#setup}\n",
        "\n",
        "First, let's import all necessary libraries and set up the comprehensive benchmarking system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard scientific computing imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Import LRDBenchmark benchmarking system\n",
        "from lrdbenchmark.analysis.benchmark import ComprehensiveBenchmark\n",
        "\n",
        "# Import data models\n",
        "from lrdbenchmark.models.data_models.fbm.fbm_model import FractionalBrownianMotion\n",
        "from lrdbenchmark.models.data_models.fgn.fgn_model import FractionalGaussianNoise\n",
        "from lrdbenchmark.models.data_models.arfima.arfima_model import ARFIMAModel\n",
        "\n",
        "# Import estimators for comparison\n",
        "from lrdbenchmark.analysis.temporal.rs.rs_estimator_unified import RSEstimator\n",
        "from lrdbenchmark.analysis.temporal.dfa.dfa_estimator_unified import DFAEstimator\n",
        "from lrdbenchmark.analysis.spectral.gph.gph_estimator_unified import GPHEstimator\n",
        "from lrdbenchmark.analysis.machine_learning.random_forest_estimator_unified import RandomForestEstimator\n",
        "from lrdbenchmark.analysis.machine_learning.svr_estimator_unified import SVREstimator\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(\"üöÄ Ready to run comprehensive benchmarks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Benchmark System Overview {#overview}\n",
        "\n",
        "The ComprehensiveBenchmark class provides a unified interface for testing all estimator categories. Let's examine its capabilities and run our first benchmark.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the comprehensive benchmark system\n",
        "print(\"üîß Initializing Comprehensive Benchmark System...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "benchmark = ComprehensiveBenchmark(output_dir=\"benchmark_results\")\n",
        "\n",
        "print(\"üìä Available benchmark types:\")\n",
        "print(\"  - 'classical': Classical statistical estimators\")\n",
        "print(\"  - 'ML': Machine learning estimators\")\n",
        "print(\"  - 'neural': Neural network estimators\")\n",
        "print(\"  - 'comprehensive': All estimators combined\")\n",
        "\n",
        "print(\"\\nüìä Available contamination types:\")\n",
        "print(\"  - 'additive_gaussian': Add Gaussian noise\")\n",
        "print(\"  - 'multiplicative_noise': Multiplicative noise\")\n",
        "print(\"  - 'outliers': Add outliers\")\n",
        "print(\"  - 'trend': Add trend\")\n",
        "print(\"  - 'seasonal': Add seasonal patterns\")\n",
        "print(\"  - 'missing_data': Remove data points\")\n",
        "\n",
        "print(\"\\nüìä Available data models:\")\n",
        "print(\"  - 'fbm': Fractional Brownian Motion\")\n",
        "print(\"  - 'fgn': Fractional Gaussian Noise\")\n",
        "print(\"  - 'arfima': ARFIMA processes\")\n",
        "print(\"  - 'mrw': Multifractal Random Walk\")\n",
        "\n",
        "# Run a simple classical benchmark\n",
        "print(\"\\nüöÄ Running Classical Estimator Benchmark...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "classical_results = benchmark.run_classical_benchmark(\n",
        "    data_length=1000,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Classical benchmark completed!\")\n",
        "print(f\"Success rate: {classical_results['success_rate']:.1%}\")\n",
        "print(f\"Total tests: {classical_results['total_tests']}\")\n",
        "print(f\"Successful tests: {classical_results['successful_tests']}\")\n",
        "\n",
        "# Display summary\n",
        "if 'summary' in classical_results:\n",
        "    print(\"\\nüìä Benchmark Summary:\")\n",
        "    benchmark.print_summary(classical_results['summary'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Contamination Robustness Testing {#contamination}\n",
        "\n",
        "Real-world data often contains contamination that can affect estimator performance. Let's test how different estimators handle various contamination scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test contamination robustness\n",
        "print(\"üß™ Testing Contamination Robustness...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test different contamination types\n",
        "contamination_types = [\n",
        "    'additive_gaussian',\n",
        "    'outliers', \n",
        "    'trend',\n",
        "    'seasonal'\n",
        "]\n",
        "\n",
        "contamination_results = {}\n",
        "\n",
        "for contamination_type in contamination_types:\n",
        "    print(f\"\\nüîç Testing {contamination_type} contamination...\")\n",
        "    \n",
        "    # Run benchmark with contamination\n",
        "    results = benchmark.run_classical_benchmark(\n",
        "        data_length=1000,\n",
        "        contamination_type=contamination_type,\n",
        "        contamination_level=0.2,  # 20% contamination\n",
        "        save_results=False\n",
        "    )\n",
        "    \n",
        "    contamination_results[contamination_type] = results\n",
        "    \n",
        "    print(f\"  Success rate: {results['success_rate']:.1%}\")\n",
        "    print(f\"  Total tests: {results['total_tests']}\")\n",
        "    print(f\"  Successful tests: {results['successful_tests']}\")\n",
        "\n",
        "# Compare contamination effects\n",
        "print(\"\\nüìä Contamination Effects Comparison:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "comparison_data = []\n",
        "for contamination_type, results in contamination_results.items():\n",
        "    comparison_data.append({\n",
        "        'Contamination': contamination_type,\n",
        "        'Success_Rate': results['success_rate'],\n",
        "        'Total_Tests': results['total_tests'],\n",
        "        'Successful_Tests': results['successful_tests']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df.round(3))\n",
        "\n",
        "# Visualize contamination effects\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Success rate by contamination type\n",
        "ax1 = axes[0, 0]\n",
        "ax1.bar(comparison_df['Contamination'], comparison_df['Success_Rate'], alpha=0.7)\n",
        "ax1.set_title('Success Rate by Contamination Type', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Success Rate')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Total tests by contamination type\n",
        "ax2 = axes[0, 1]\n",
        "ax2.bar(comparison_df['Contamination'], comparison_df['Total_Tests'], alpha=0.7)\n",
        "ax2.set_title('Total Tests by Contamination Type', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Total Tests')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Successful tests by contamination type\n",
        "ax3 = axes[1, 0]\n",
        "ax3.bar(comparison_df['Contamination'], comparison_df['Successful_Tests'], alpha=0.7)\n",
        "ax3.set_title('Successful Tests by Contamination Type', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('Successful Tests')\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Contamination impact (success rate vs baseline)\n",
        "baseline_success = classical_results['success_rate']\n",
        "impact_data = comparison_df['Success_Rate'] - baseline_success\n",
        "ax4 = axes[1, 1]\n",
        "ax4.bar(comparison_df['Contamination'], impact_data, alpha=0.7, \n",
        "        color=['red' if x < 0 else 'green' for x in impact_data])\n",
        "ax4.set_title('Contamination Impact on Success Rate', fontsize=12, fontweight='bold')\n",
        "ax4.set_ylabel('Change in Success Rate')\n",
        "ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/contamination_robustness.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Contamination robustness testing completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary and Next Steps {#summary}\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Comprehensive Benchmarking**: LRDBenchmark provides a unified system for testing all estimator categories:\n",
        "   - **Classical**: Fast, interpretable, theoretically grounded\n",
        "   - **ML**: Robust, flexible, pre-trained models\n",
        "   - **Neural**: High accuracy, complex patterns\n",
        "\n",
        "2. **Contamination Testing**: The system evaluates robustness under various contamination scenarios:\n",
        "   - **Additive Gaussian**: Noise contamination\n",
        "   - **Outliers**: Extreme value contamination\n",
        "   - **Trend**: Systematic trend contamination\n",
        "   - **Seasonal**: Periodic pattern contamination\n",
        "\n",
        "3. **Performance Metrics**: Comprehensive evaluation including:\n",
        "   - **Accuracy**: Mean absolute error, bias, variance\n",
        "   - **Speed**: Execution time, computational efficiency\n",
        "   - **Robustness**: Performance under contamination\n",
        "   - **Reliability**: Success rate, consistency\n",
        "\n",
        "### Benchmark Results\n",
        "\n",
        "- **Classical Estimators**: Fast and reliable for standard LRD processes\n",
        "- **ML Estimators**: Good balance of accuracy and robustness\n",
        "- **Neural Networks**: Highest accuracy for complex patterns\n",
        "- **Contamination Effects**: Different estimators show varying robustness\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Leaderboard Generation**: Create performance rankings and comparisons\n",
        "2. **Real-world Application**: Apply to actual time series data\n",
        "3. **Advanced Analysis**: Explore statistical significance and confidence intervals\n",
        "4. **Custom Benchmarks**: Create domain-specific benchmark scenarios\n",
        "\n",
        "### Files Generated\n",
        "\n",
        "- `benchmark_results/`: Complete benchmark results directory\n",
        "- `outputs/contamination_robustness.png`: Contamination effects visualization\n",
        "- Performance metrics and statistical analysis\n",
        "\n",
        "### References\n",
        "\n",
        "1. Taqqu, M. S., Teverovsky, V., & Willinger, W. (1995). Estimators for long-range dependence: an empirical study. Fractals, 3(04), 785-798.\n",
        "2. Beran, J. (1994). Statistics for long-memory processes. CRC press.\n",
        "3. Abry, P., & Veitch, D. (1998). Wavelet analysis of long-range-dependent traffic. IEEE Transactions on information theory, 44(1), 2-15.\n",
        "\n",
        "---\n",
        "\n",
        "**Next Notebook**: [05_leaderboard_generation.ipynb](05_leaderboard_generation.ipynb) - Learn how to create performance leaderboards and rankings.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
